{"cells":[{"cell_type":"markdown","source":["### **Model Training/Evaluation/Selection**"],"metadata":{"id":"NjucrDih8Mwk"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"_Ci_yN9ez4Z6","executionInfo":{"status":"ok","timestamp":1714228076889,"user_tz":240,"elapsed":486,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YjW1fle5Ib1C","executionInfo":{"status":"ok","timestamp":1714228078913,"user_tz":240,"elapsed":1230,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"}}},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/data/cleaned_data.csv\")"]},{"cell_type":"code","source":[],"metadata":{"id":"YPS-wWQn-KTG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trees"],"metadata":{"id":"yJzvmoFM-LKa"}},{"cell_type":"markdown","source":["Random Forest Classifier\n"],"metadata":{"id":"XJPOaq9P-SMl"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":851,"status":"ok","timestamp":1714228082106,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"PX4xCwnnZfT7","outputId":"63bfa15a-d594-4736-92b6-36403e8782c6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.89625"]},"metadata":{},"execution_count":5}],"source":["#Let's perform a super simple and easy Random Forest Classifier.\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Selecting the features and target\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kwMxP50apCr"},"outputs":[],"source":["#I bet I can get that accuracy to 95%. Let's do some feature engineering."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713439633020,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"nyaV97RybZru","outputId":"b27aa24b-6ade-49c5-b11c-6f9b6ed3b7bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 1 0 0 1]\n"]}],"source":["#Let's just look at what it's doing. In the first five rows, it got a false negative (wrongly predicted a good apple as a bad apple).\n","#More false negatives could mean wasting money that shouldn't be wasted. False positives could mean customers get bad apples, which of course could hurt the brand, and cost lots of money in the long run.\n","#If we have to choose between the two, throwing out a few good apples would probably be preferable to selling the same number of bad apples to customers.\n","print(model.predict(X_train.iloc[0:5]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713439633020,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"GEe5Bo83b0HN","outputId":"8f81e6df-a4d4-412d-c3e8-b1c0ca7933cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["False Positives: 45\n","False Negatives: 38\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","#Let's calculate false positives vs false negatives.\n","\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","false_positive = conf_matrix[0][1]\n","false_negative = conf_matrix[1][0]\n","\n","print(f\"False Positives: {false_positive}\")\n","print(f\"False Negatives: {false_negative}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ux6aVsGWeSYn"},"outputs":[],"source":["#Ok, so there's not a wild imbalance in terms of false positives vs false negatives. That's probably good.\n","#Let's try to find the most unpredictable feature, and see if we can get higher accuracy be getting rid of it.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713439633021,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"tVG7Q3E5eM8G","outputId":"f2e14778-4a5e-497c-90c4-9209950c5e4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n","Size         1.000000 -0.170702  -0.324680     0.169868  -0.018892 -0.134773   \n","Weight      -0.170702  1.000000  -0.154246    -0.095882  -0.092263 -0.243824   \n","Sweetness   -0.324680 -0.154246   1.000000    -0.037552   0.095882 -0.273800   \n","Crunchiness  0.169868 -0.095882  -0.037552     1.000000  -0.259607 -0.201982   \n","Juiciness   -0.018892 -0.092263   0.095882    -0.259607   1.000000 -0.097144   \n","Ripeness    -0.134773 -0.243824  -0.273800    -0.201982  -0.097144  1.000000   \n","Acidity      0.196218  0.016414   0.085999     0.069943   0.248714 -0.202669   \n","\n","              Acidity  \n","Size         0.196218  \n","Weight       0.016414  \n","Sweetness    0.085999  \n","Crunchiness  0.069943  \n","Juiciness    0.248714  \n","Ripeness    -0.202669  \n","Acidity      1.000000  \n"]}],"source":["#Hypotheses: Size and weight are probably positively correlated.\n","#I think acidity and ripeness are inversely correlated. The riper it is, the less acidic.\n","#Let's see what the data says.\n","\n","correlation_matrix = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']].corr()\n","print(correlation_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1713439633273,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"8m6n39BAiuYU","outputId":"a6c59605-507f-4a32-9908-f8416f96465e"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n","Size         1.000000 -0.170702  -0.324680     0.169868  -0.018892 -0.134773   \n","Weight      -0.170702  1.000000  -0.154246    -0.095882  -0.092263 -0.243824   \n","Sweetness   -0.324680 -0.154246   1.000000    -0.037552   0.095882 -0.273800   \n","Crunchiness  0.169868 -0.095882  -0.037552     1.000000  -0.259607 -0.201982   \n","Juiciness   -0.018892 -0.092263   0.095882    -0.259607   1.000000 -0.097144   \n","Ripeness    -0.134773 -0.243824  -0.273800    -0.201982  -0.097144  1.000000   \n","Acidity      0.196218  0.016414   0.085999     0.069943   0.248714 -0.202669   \n","Good         0.244007  0.001421   0.250998    -0.012376   0.260223 -0.264315   \n","\n","              Acidity      Good  \n","Size         0.196218  0.244007  \n","Weight       0.016414  0.001421  \n","Sweetness    0.085999  0.250998  \n","Crunchiness  0.069943 -0.012376  \n","Juiciness    0.248714  0.260223  \n","Ripeness    -0.202669 -0.264315  \n","Acidity      1.000000 -0.007697  \n","Good        -0.007697  1.000000  \n"]}],"source":["\n","correlation_matrix = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity', 'Good']].corr()\n","print(correlation_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1713439633273,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"Jn6Sl2vjg7sq","outputId":"e13fb1cb-9a70-4e42-a05c-7472e2131b1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size         Sweetness    0.324680\n","Ripeness     Sweetness    0.273800\n","Crunchiness  Juiciness    0.259607\n","Acidity      Juiciness    0.248714\n","Ripeness     Weight       0.243824\n","Acidity      Ripeness     0.202669\n","Crunchiness  Ripeness     0.201982\n","Acidity      Size         0.196218\n","Size         Weight       0.170702\n","Crunchiness  Size         0.169868\n","dtype: float64\n"]}],"source":["# Calculate the correlation matrix and flatten it to a series\n","corr_matrix = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']].corr().abs()\n","corr_pairs = corr_matrix.unstack()\n","\n","# Sort by absolute value\n","sorted_pairs = corr_pairs.sort_values(ascending=False)\n","\n","# Remove self-correlations\n","no_self_corr = sorted_pairs[sorted_pairs.index.get_level_values(0) != sorted_pairs.index.get_level_values(1)]\n","\n","# Filter out duplicate pairs\n","unique_pairs = no_self_corr[no_self_corr.index.get_level_values(0) < no_self_corr.index.get_level_values(1)]\n","\n","# Display the highest correlations without duplicates\n","print(unique_pairs.head(10))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713439633273,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"7bf3tZW-hfko","outputId":"201bec62-a115-44ac-cc97-2f00426198c4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n             Acidity      Good\\nSize         0.196218  0.244007\\nWeight       0.016414  0.001421\\nSweetness    0.085999  0.250998\\nCrunchiness  0.069943 -0.012376\\nJuiciness    0.248714  0.260223\\nRipeness    -0.202669 -0.264315\\nAcidity      1.000000 -0.007697\\nGood        -0.007697  1.000000 '"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["#For my next iteration of random forest classifier, I'm just going to home in on the highest absolute valued correlations with the target.\n","#The four biggest correlation features are Size, Sweetness, Juiciness, and Ripeness.\n","\n","'''\n","             Acidity      Good\n","Size         0.196218  0.244007\n","Weight       0.016414  0.001421\n","Sweetness    0.085999  0.250998\n","Crunchiness  0.069943 -0.012376\n","Juiciness    0.248714  0.260223\n","Ripeness    -0.202669 -0.264315\n","Acidity      1.000000 -0.007697\n","Good        -0.007697  1.000000 '''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1713439633581,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"95SGAOCwj588","outputId":"ca1b5025-cf9f-48bd-896c-3638ce846290"},"outputs":[{"data":{"text/plain":["0.83"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["#Trying again, throwing out the lower correlation features.\n","# Selecting the features and target\n","features = data[['Size', 'Sweetness', 'Juiciness', 'Ripeness']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1713439634284,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"9g7Gbx4DkUH_","outputId":"b37daf27-d91a-4eec-b772-c5794407c130"},"outputs":[{"data":{"text/plain":["0.83"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["#0.83, so that didn't work.\n","#Let's try some more.\n","features = data[['Size', 'Sweetness', 'Juiciness', 'Ripeness']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1713439634896,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"48dhSPSwkboJ","outputId":"3def87ab-32cb-4b00-e868-95ebd0adc53b"},"outputs":[{"data":{"text/plain":["0.83"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["#Juiciness and Ripeness are very strongly correlated to the target, but not very strongly correlated to each other.\n","#To my intuition, this would mean that they convey a lot of information about the target, and there's not a lot of overlapping information.\n","features = data[['Juiciness', 'Ripeness']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","test_accuracy = accuracy_score(y_test, y_pred)\n","\n","accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3lb90xVlUlt"},"outputs":[],"source":["#That didn't work at all! 0.6475."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":765,"status":"ok","timestamp":1713439635660,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"E5-oCB1glaOJ","outputId":"4e8d43a1-2096-4e91-9c4c-baccfbb38e9b"},"outputs":[{"data":{"text/plain":["0.89625"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pyj170nije3z"},"outputs":[],"source":["#If this is a binary classifier, I need to change that. There are really three stages of an apple's life cycle: pre-ripe (bad), ripe (good), post-ripe (good). Binary classification won't work.\n","#It's not a binary classifier.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3785,"status":"ok","timestamp":1713439639443,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"duGu5eSlm3oM","outputId":"8ff90fd6-c2b9-4da1-961b-5055b3cc6829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Trees: 50\n","Train Accuracy: 0.9996875\n","Test Accuracy: 0.89\n","Number of Trees: 100\n","Train Accuracy: 1.0\n","Test Accuracy: 0.89625\n","Number of Trees: 150\n","Train Accuracy: 1.0\n","Test Accuracy: 0.90375\n","Number of Trees: 200\n","Train Accuracy: 1.0\n","Test Accuracy: 0.90625\n"]}],"source":["#Things to try: Messing around with number of trees. Default is 100.\n","#Print out both training and test accuracy to evaluate over and underfitting.\n","for n in [50, 100, 150, 200]:\n","    features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","    target = data['Good']\n","\n","    # Split the data into training and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","    # Initialize the model\n","    model = RandomForestClassifier(n_estimators=n, random_state=42)\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Predict on the test set\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","    # Calculate accuracy\n","    train_accuracy = accuracy_score(y_train, y_train_pred)\n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","\n","    print(f\"Number of Trees: {n}\")\n","    print(f\"Train Accuracy: {train_accuracy}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"executionInfo":{"elapsed":16799,"status":"error","timestamp":1713439656240,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"NZArugXQoHQ9","outputId":"1ab42951-cc20-4428-eb77-853fa3c5fa4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Trees: 200\n","Train Accuracy: 1.0\n","Test Accuracy: 0.90625\n","Number of Trees: 300\n","Train Accuracy: 1.0\n","Test Accuracy: 0.91125\n","Number of Trees: 400\n","Train Accuracy: 1.0\n","Test Accuracy: 0.9125\n","Number of Trees: 500\n","Train Accuracy: 1.0\n","Test Accuracy: 0.91375\n","Number of Trees: 600\n","Train Accuracy: 1.0\n","Test Accuracy: 0.9125\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-372b4a58c424>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#Seems to actually improve with more trees. Let's see when that starts to taper off.\n","for n in [200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n","    features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","    target = data['Good']\n","\n","    # Split the data into training and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","    # Initialize the model\n","    model = RandomForestClassifier(n_estimators=n, random_state=42)\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Predict on the test set\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","    # Calculate accuracy\n","    train_accuracy = accuracy_score(y_train, y_train_pred)\n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","\n","    print(f\"Number of Trees: {n}\")\n","    print(f\"Train Accuracy: {train_accuracy}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Ts6eG4gorIc"},"outputs":[],"source":["#Ok great. We got 500 trees. 0.91375\n","#Let's try to get to 0.95.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9fPsD8isIU2"},"outputs":[],"source":["#I'm gonna mess around with some binning.\n","data['bucketed_Ripeness'] = pd.cut(data['Ripeness'], bins=3, labels=[0,1,2])\n","#I have a feeling this might not be great. But let's see."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NS0o5oduseF4"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rH8vf5TXsj4o"},"outputs":[],"source":["#Things to try: Messing around with number of trees. Default is 100.\n","#Print out both training and test accuracy to evaluate over and underfitting.\n","for n in [50, 100, 150, 200]:\n","    features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'bucketed_Ripeness', 'Acidity']]\n","    target = data['Good']\n","\n","    # Split the data into training and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","    # Initialize the model\n","    model = RandomForestClassifier(n_estimators=n, random_state=42)\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Predict on the test set\n","    y_train_pred = model.predict(X_train)\n","    y_test_pred = model.predict(X_test)\n","\n","    # Calculate accuracy\n","    train_accuracy = accuracy_score(y_train, y_train_pred)\n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","\n","    print(f\"Number of Trees: {n}\")\n","    print(f\"Train Accuracy: {train_accuracy}\")\n","    print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dGzA4Zn6CPrV"},"outputs":[],"source":["#Let's try more buckets.\n","data['bucketed_Ripeness'] = pd.cut(data['Ripeness'], bins=10, labels=[i for i in range(10)])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIS9e3S2Ckdi"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vq8qGh5CpMv"},"outputs":[],"source":["#Things to try: Messing around with number of trees. Default is 100.\n","#Print out both training and test accuracy to evaluate over and underfitting.\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'bucketed_Ripeness', 'Acidity']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(n_estimators=500, random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","train_accuracy = accuracy_score(y_train, y_train_pred)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","\n","print(f\"Number of Trees: {n}\")\n","print(f\"Train Accuracy: {train_accuracy}\")\n","print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLSpZwM-Cxl0"},"outputs":[],"source":["data['bucketed_Ripeness'] = pd.cut(data['Ripeness'], bins=2, labels=[0,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdEDy94JC3gy"},"outputs":[],"source":["#Things to try: Messing around with number of trees. Default is 100.\n","#Print out both training and test accuracy to evaluate over and underfitting.\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'bucketed_Ripeness', 'Acidity']]\n","target = data['Good']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = RandomForestClassifier(n_estimators=500, random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)\n","\n","# Calculate accuracy\n","train_accuracy = accuracy_score(y_train, y_train_pred)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","\n","print(f\"Number of Trees: {n}\")\n","print(f\"Train Accuracy: {train_accuracy}\")\n","print(f\"Test Accuracy: {test_accuracy}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"zagnT-ID-hJh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["XGBoost Tree"],"metadata":{"id":"Af5S_F7K-k8_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2824,"status":"ok","timestamp":1713558649185,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"8fFKbXk5s4ky","outputId":"2637fd78-8d9f-4de5-f13f-4ac41b6bb82c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 90.25%\n"]}],"source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","\n","# Convert the dataset into an optimized data structure called Dmatrix that XGBoost supports\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","# Define the parameters for the XGBoost model\n","params = {\n","    'objective': 'multi:softmax',  # Change to 'multi:softmax' for multiclass and also set num_class\n","    'max_depth': 100,  # Depth of each tree\n","    'min_child_weight': 1,  # Minimum number of instances needed in each node\n","    'subsample': 0.8,  # Subsample ratio of the training instances\n","    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n","    'eta': 0.3,  # Learning rate\n","    'seed': 42,  # Random seed\n","    'num_class': 2\n","}\n","\n","# Specify the number of training rounds\n","num_round = 100\n","\n","# Train the XGBoost model\n","bst = xgb.train(params, dtrain, num_round)\n","\n","# Make predictions\n","preds = bst.predict(dtest)\n","predictions = [round(value) for value in preds]\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Accuracy: {accuracy * 100.0}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":177,"status":"ok","timestamp":1713558663954,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"o20Az6MCuW1S","outputId":"8f2912f5-bf99-4d4b-beb7-dafe47e1d182"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 89.25%\n"]}],"source":["#Oh interesting. Xgboost didn't even do better.\n","params = {\n","    'objective': 'binary:logistic',  # Change to 'multi:softmax' for multiclass and also set num_class\n","    'max_depth': 6,\n","    'min_child_weight': 1,  # Minimum number of instances needed in each node\n","    'subsample': 0.8,  # Subsample ratio of the training instances\n","    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n","    'eta': 0.3,  # Learning rate\n","    'seed': 43,  # Random seed\n","}\n","\n","# Specify the number of training rounds\n","num_round = 100\n","\n","# Train the XGBoost model\n","bst = xgb.train(params, dtrain, num_round)\n","\n","# Make predictions\n","preds = bst.predict(dtest)\n","predictions = [round(value) for value in preds]\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Accuracy: {accuracy * 100.0}%\")"]},{"cell_type":"markdown","source":["MLP Classifier"],"metadata":{"id":"4artGJRe-ren"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":22503,"status":"error","timestamp":1713814349719,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"_ZL04E3Nu_0k","outputId":"b3153155-6476-47ad-d779-e12e68b56011"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 1ms/step\n"]},{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous targets","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a92d71232111>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model accuracy: {accuracy: f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"source":["#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100), learning_rate_init=0.001, max_iter=2000, alpha=0.0002, activation='relu', solver='adam', random_state=42)\n","\n","# Fit the model\n","mlp.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":341,"status":"error","timestamp":1713814408937,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"q1_5OjBGTDdv","outputId":"905566d3-b2ea-454a-86dc-b4100f807c79"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 1ms/step\n"]},{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous targets","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-e64fb481a0bb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model accuracy: {accuracy: f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"source":["predictions = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1713814478779,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"k8KjGxySTY1r","outputId":"9377fbd5-2b26-4e62-c6cf-3b2555578b55"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[9.99998808e-01]\n"," [1.06516991e-05]\n"," [7.76875995e-21]\n"," [1.00000000e+00]\n"," [9.12206644e-24]\n"," [1.00000000e+00]\n"," [2.05586007e-10]\n"," [4.53626329e-12]\n"," [1.00000000e+00]\n"," [9.99996424e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.28091530e-28]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.06826441e-18]\n"," [1.59083834e-06]\n"," [2.27826096e-14]\n"," [9.68161107e-17]\n"," [1.21594490e-09]\n"," [7.41243191e-15]\n"," [5.86390859e-18]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.69544063e-15]\n"," [4.54243631e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.15146250e-12]\n"," [1.00000000e+00]\n"," [2.65328538e-07]\n"," [1.12097035e-34]\n"," [0.00000000e+00]\n"," [2.66652917e-15]\n"," [1.00000000e+00]\n"," [3.27351563e-13]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.25143713e-16]\n"," [9.99999523e-01]\n"," [4.43295593e-16]\n"," [9.44529355e-01]\n"," [1.92599917e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.41850067e-14]\n"," [2.39785553e-11]\n"," [1.00000000e+00]\n"," [9.99999881e-01]\n"," [6.10954823e-22]\n"," [1.14753129e-06]\n"," [1.00000000e+00]\n"," [2.02259392e-21]\n"," [5.69671467e-14]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [4.11472338e-34]\n"," [4.26216624e-19]\n"," [1.00000000e+00]\n"," [9.99998927e-01]\n"," [1.00000000e+00]\n"," [1.09669607e-08]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.57964106e-14]\n"," [1.00000000e+00]\n"," [9.99997854e-01]\n"," [1.37557014e-27]\n"," [1.00000000e+00]\n"," [1.65148409e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.99951242e-19]\n"," [1.38162455e-25]\n"," [1.00000000e+00]\n"," [2.02567896e-17]\n"," [1.00000000e+00]\n"," [4.76616010e-18]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.65477853e-20]\n"," [1.26185344e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.89899404e-18]\n"," [1.31220879e-14]\n"," [4.75567106e-22]\n"," [8.92399088e-23]\n"," [1.00000000e+00]\n"," [2.10439712e-02]\n"," [1.00000000e+00]\n"," [3.84711053e-19]\n"," [4.20575681e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.27993152e-22]\n"," [1.24526303e-19]\n"," [9.99990225e-01]\n"," [2.95957037e-09]\n"," [9.99641418e-01]\n"," [6.75950360e-23]\n"," [1.44208192e-32]\n"," [7.78209773e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.63973606e-15]\n"," [8.58053795e-14]\n"," [1.14696029e-23]\n"," [1.82861708e-14]\n"," [3.40031922e-30]\n"," [5.08176135e-19]\n"," [3.12117328e-25]\n"," [1.00000000e+00]\n"," [1.35683522e-11]\n"," [7.17545939e-19]\n"," [1.00000000e+00]\n"," [1.51858165e-25]\n"," [5.23354582e-10]\n"," [1.00000000e+00]\n"," [9.99999523e-01]\n"," [1.07145134e-25]\n"," [1.25325240e-38]\n"," [1.00000000e+00]\n"," [3.57354862e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.61858463e-01]\n"," [1.00000000e+00]\n"," [8.31226836e-16]\n"," [9.41128276e-22]\n"," [9.94386106e-22]\n"," [1.00000000e+00]\n"," [8.60783070e-14]\n"," [1.00000000e+00]\n"," [9.13348090e-33]\n"," [9.99999166e-01]\n"," [2.93877259e-29]\n"," [1.00000000e+00]\n"," [2.66071522e-24]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.19450239e-34]\n"," [1.00000000e+00]\n"," [4.18439380e-38]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.56866558e-16]\n"," [4.12271236e-23]\n"," [1.00000000e+00]\n"," [2.84237313e-23]\n"," [1.01602570e-17]\n"," [8.78482663e-32]\n"," [1.00000000e+00]\n"," [1.29170303e-24]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.46545355e-21]\n"," [5.79162857e-13]\n"," [1.00000000e+00]\n"," [1.23580060e-06]\n"," [1.00000000e+00]\n"," [2.92589375e-09]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [4.72333526e-11]\n"," [3.54086795e-11]\n"," [1.00000000e+00]\n"," [1.39926830e-29]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [4.13961288e-06]\n"," [1.00000000e+00]\n"," [2.38183944e-17]\n"," [3.68154680e-08]\n"," [8.57099873e-22]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [3.53678875e-20]\n"," [1.92346861e-28]\n"," [1.63973703e-14]\n"," [1.00000000e+00]\n"," [2.63768343e-17]\n"," [1.17454577e-14]\n"," [4.06262779e-20]\n"," [3.33007279e-07]\n"," [1.00000000e+00]\n"," [2.61439203e-25]\n"," [1.00000000e+00]\n"," [3.76409843e-37]\n"," [1.00000000e+00]\n"," [4.07996120e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.29330691e-22]\n"," [2.10191094e-16]\n"," [1.00000000e+00]\n"," [3.53822874e-11]\n"," [3.79775784e-24]\n"," [1.80097243e-35]\n"," [1.88139836e-07]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.58999927e-20]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.09444658e-13]\n"," [4.12856221e-10]\n"," [1.00000000e+00]\n"," [1.56473909e-31]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.86070347e-26]\n"," [1.98951932e-22]\n"," [8.89644088e-12]\n"," [1.00000000e+00]\n"," [5.48295904e-15]\n"," [2.47160326e-19]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.91166128e-05]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99868512e-01]\n"," [1.00000000e+00]\n"," [1.26755653e-30]\n"," [4.68413256e-17]\n"," [7.63285295e-25]\n"," [1.00000000e+00]\n"," [4.91982858e-14]\n"," [1.80402579e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.15074092e-33]\n"," [1.89867271e-23]\n"," [1.48806135e-19]\n"," [9.99997854e-01]\n"," [1.00000000e+00]\n"," [2.63221656e-16]\n"," [9.99997973e-01]\n"," [2.48123397e-04]\n"," [1.00000000e+00]\n"," [1.66676707e-25]\n"," [1.00000000e+00]\n"," [3.05247241e-22]\n"," [5.67831263e-19]\n"," [9.45661034e-33]\n"," [1.55324001e-20]\n"," [1.00000000e+00]\n"," [3.56379683e-11]\n"," [1.00000000e+00]\n"," [1.90035791e-26]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.24208642e-16]\n"," [7.22451135e-12]\n"," [3.36755871e-14]\n"," [1.00000000e+00]\n"," [5.05100443e-22]\n"," [1.63074138e-11]\n"," [3.18605840e-27]\n"," [1.00000000e+00]\n"," [2.03627698e-10]\n"," [1.00000000e+00]\n"," [2.03410977e-07]\n"," [2.49539676e-15]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.41508445e-18]\n"," [2.39255176e-22]\n"," [1.00000000e+00]\n"," [9.39177717e-21]\n"," [1.00000000e+00]\n"," [8.34900248e-24]\n"," [0.00000000e+00]\n"," [6.07476466e-20]\n"," [5.65581829e-38]\n"," [9.99997854e-01]\n"," [1.00000000e+00]\n"," [1.45596902e-22]\n"," [7.31446154e-14]\n"," [1.00000000e+00]\n"," [1.37495310e-24]\n"," [1.00000000e+00]\n"," [9.99999404e-01]\n"," [1.00000000e+00]\n"," [1.21293190e-27]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [8.10918573e-17]\n"," [1.00000000e+00]\n"," [2.35046791e-11]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.94814412e-13]\n"," [2.60321089e-29]\n"," [4.78970129e-21]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99999881e-01]\n"," [1.00000000e+00]\n"," [8.55572450e-19]\n"," [1.00000000e+00]\n"," [3.72117642e-10]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.08482745e-11]\n"," [9.45343651e-33]\n"," [2.16278306e-24]\n"," [8.39645153e-08]\n"," [3.91212262e-27]\n"," [3.96147552e-13]\n"," [3.10285910e-23]\n"," [1.62591351e-28]\n"," [3.42543899e-07]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.91041900e-32]\n"," [1.72128960e-11]\n"," [2.01295139e-19]\n"," [1.86610356e-36]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.96534163e-24]\n"," [7.97309227e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.76227324e-19]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.22284517e-21]\n"," [1.96747251e-16]\n"," [2.23180425e-08]\n"," [1.00000000e+00]\n"," [5.64957829e-03]\n"," [6.90758881e-08]\n"," [1.00000000e+00]\n"," [2.47555772e-06]\n"," [1.19694924e-36]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99999881e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.73593297e-07]\n"," [1.89012583e-13]\n"," [8.75110352e-19]\n"," [9.99996185e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [3.92730217e-18]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.41498527e-36]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.36551507e-23]\n"," [1.07517042e-30]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99999642e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.10473889e-06]\n"," [9.62564082e-31]\n"," [1.99428895e-17]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.46769923e-06]\n"," [5.64632585e-33]\n"," [1.63081485e-20]\n"," [9.75998896e-27]\n"," [1.00000000e+00]\n"," [2.44897130e-15]\n"," [1.00000000e+00]\n"," [6.59333523e-07]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.77882981e-20]\n"," [2.75072761e-19]\n"," [1.24182315e-20]\n"," [6.72455087e-07]\n"," [1.00000000e+00]\n"," [7.52781050e-15]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.52321992e-25]\n"," [1.00000000e+00]\n"," [5.24839834e-06]\n"," [9.99999166e-01]\n"," [8.75410579e-27]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.07990186e-22]\n"," [2.56826764e-26]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [6.74902929e-12]\n"," [1.82136497e-23]\n"," [3.14747496e-19]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [4.90859076e-10]\n"," [1.00000000e+00]\n"," [9.99999762e-01]\n"," [1.79661919e-23]\n"," [1.00000000e+00]\n"," [1.30203800e-16]\n"," [0.00000000e+00]\n"," [2.34542832e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.36773019e-22]\n"," [1.31598584e-22]\n"," [1.00000000e+00]\n"," [9.99890685e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.99940257e-06]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.79427397e-08]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99999523e-01]\n"," [1.76888582e-09]\n"," [6.63703641e-12]\n"," [1.48554688e-14]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.09150773e-13]\n"," [1.00000000e+00]\n"," [2.49206093e-20]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.72121807e-15]\n"," [1.68973674e-18]\n"," [3.36239496e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.75645816e-01]\n"," [0.00000000e+00]\n"," [1.71988500e-11]\n"," [1.00000000e+00]\n"," [9.99994993e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.08439743e-19]\n"," [1.96218163e-30]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [3.24990713e-16]\n"," [1.00000000e+00]\n"," [6.81375484e-34]\n"," [1.00000000e+00]\n"," [4.27486806e-26]\n"," [1.12248743e-15]\n"," [9.99999881e-01]\n"," [4.27772189e-19]\n"," [2.21255331e-38]\n"," [1.00000000e+00]\n"," [3.23444745e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.38164896e-04]\n"," [1.03953724e-24]\n"," [9.99992371e-01]\n"," [7.95789549e-24]\n"," [8.86373115e-13]\n"," [1.00000000e+00]\n"," [2.88007451e-10]\n"," [1.00000000e+00]\n"," [8.80452232e-24]\n"," [1.25659413e-15]\n"," [1.00000000e+00]\n"," [9.44547549e-17]\n"," [1.00000000e+00]\n"," [5.59058444e-09]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.26058707e-22]\n"," [1.00000000e+00]\n"," [6.79300254e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.16412401e-32]\n"," [5.85134317e-13]\n"," [2.30039756e-08]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.05642551e-13]\n"," [1.00000000e+00]\n"," [7.57979023e-31]\n"," [1.00000000e+00]\n"," [5.94549499e-17]\n"," [5.78470881e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.27693546e-23]\n"," [2.89564127e-07]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.90228040e-27]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.88007269e-30]\n"," [9.48436555e-16]\n"," [1.00000000e+00]\n"," [3.58329658e-07]\n"," [9.59358801e-19]\n"," [1.00000000e+00]\n"," [5.12132488e-19]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [7.98375529e-28]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.71850769e-16]\n"," [1.00000000e+00]\n"," [5.68059811e-23]\n"," [2.09446557e-10]\n"," [1.71719942e-16]\n"," [1.30196325e-24]\n"," [1.84441351e-08]\n"," [1.00000000e+00]\n"," [4.40475101e-10]\n"," [5.20281674e-07]\n"," [1.00000000e+00]\n"," [3.61329697e-18]\n"," [1.00000000e+00]\n"," [1.44031833e-23]\n"," [1.00000000e+00]\n"," [9.99996662e-01]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.26604661e-07]\n"," [1.00000000e+00]\n"," [5.63711621e-25]\n"," [1.00000000e+00]\n"," [1.22832612e-11]\n"," [1.00000000e+00]\n"," [3.10873301e-17]\n"," [1.67916610e-07]\n"," [1.46092943e-10]\n"," [1.00000000e+00]\n"," [1.83513881e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.04342749e-15]\n"," [8.88079475e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.59413572e-13]\n"," [1.00000000e+00]\n"," [4.41030437e-07]\n"," [1.00000000e+00]\n"," [7.22787576e-19]\n"," [2.14123739e-21]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.60900359e-16]\n"," [1.00000000e+00]\n"," [2.03889599e-18]\n"," [1.55734664e-19]\n"," [2.30143600e-17]\n"," [1.00000000e+00]\n"," [8.05695675e-16]\n"," [3.53850369e-12]\n"," [1.00000000e+00]\n"," [7.46327188e-16]\n"," [6.52246251e-22]\n"," [9.99999762e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [1.29520366e-28]\n"," [9.99996305e-01]\n"," [1.00000000e+00]\n"," [1.58324511e-07]\n"," [1.33201937e-25]\n"," [4.80516252e-11]\n"," [3.16272281e-20]\n"," [9.98892009e-01]\n"," [3.68085131e-02]\n"," [3.44697280e-13]\n"," [7.10816011e-21]\n"," [1.00000000e+00]\n"," [1.25868938e-32]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.17199589e-27]\n"," [1.46864913e-05]\n"," [1.03112334e-27]\n"," [4.45623529e-12]\n"," [1.00000000e+00]\n"," [2.45062911e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99999762e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [3.69514407e-20]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99997854e-01]\n"," [4.27928296e-14]\n"," [3.01320377e-16]\n"," [1.57233045e-18]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.30091780e-17]\n"," [4.95282829e-18]\n"," [2.96385133e-17]\n"," [1.26395865e-31]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.68808210e-01]\n"," [9.99993682e-01]\n"," [1.80636848e-18]\n"," [2.09580843e-25]\n"," [1.29296447e-25]\n"," [3.32858736e-17]\n"," [1.00000000e+00]\n"," [2.37805737e-14]\n"," [2.93210732e-23]\n"," [6.86155349e-30]\n"," [1.00000000e+00]\n"," [4.25850063e-38]\n"," [1.35592097e-06]\n"," [8.70171611e-16]\n"," [1.00000000e+00]\n"," [1.04327634e-30]\n"," [9.60214520e-21]\n"," [4.13330261e-19]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [4.04912303e-19]\n"," [1.00000000e+00]\n"," [4.81660041e-04]\n"," [1.00000000e+00]\n"," [1.47174860e-16]\n"," [1.00000000e+00]\n"," [1.06350951e-20]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [8.64582517e-10]\n"," [2.22971433e-35]\n"," [1.54753931e-27]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [3.60975724e-25]\n"," [1.26660320e-13]\n"," [1.54056268e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.56368630e-19]\n"," [1.00000000e+00]\n"," [9.99999881e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [8.64642932e-15]\n"," [7.15398402e-17]\n"," [6.97795812e-08]\n"," [7.90264798e-11]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.56590420e-15]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.26679568e-18]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [1.00000000e+00]\n"," [3.34595546e-11]\n"," [1.40060084e-25]\n"," [1.00000000e+00]\n"," [1.90875741e-14]\n"," [9.59450963e-10]\n"," [9.98646796e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.33083150e-16]\n"," [3.33189258e-38]\n"," [1.59710439e-07]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.39336476e-09]\n"," [1.08654274e-06]\n"," [9.99997377e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.57265969e-19]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.12123525e-05]\n"," [1.87610220e-22]\n"," [1.00000000e+00]\n"," [1.25484860e-18]\n"," [1.00000000e+00]\n"," [1.18236705e-23]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [5.72846261e-26]\n"," [2.40563895e-06]\n"," [9.99810755e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.42830019e-12]\n"," [1.63911622e-20]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.49283623e-16]\n"," [1.00000000e+00]\n"," [2.90589255e-14]\n"," [2.71871796e-11]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.24891167e-12]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.55516712e-35]\n"," [3.67086754e-27]\n"," [1.00000000e+00]\n"," [8.26110913e-19]\n"," [2.96093569e-17]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [2.73046761e-26]\n"," [2.09814587e-16]\n"," [3.57101111e-25]\n"," [9.48690120e-23]\n"," [3.05135522e-14]\n"," [7.46241556e-13]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.34480092e-25]\n"," [1.00000000e+00]\n"," [3.25881239e-10]\n"," [1.82647554e-19]\n"," [7.64445700e-16]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.00000000e+00]]\n"]}],"source":["print(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21337,"status":"ok","timestamp":1713643365531,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"EfxbTMDDF6Vt","outputId":"e1be1add-2de1-466d-eec7-af4bfe13b157"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model accuracy:  0.958750\n"]}],"source":["#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100), learning_rate_init=0.001, max_iter=2000, alpha=0.0002, activation='relu', solver='adam', random_state=42)\n","\n","# Fit the model\n","mlp.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1713643234149,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"T0If5UPJGGje","outputId":"d9aacdbf-c6dc-4915-9e8c-d98e34088285"},"outputs":[{"data":{"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n","\n","Data structure also contains labeled axes (rows and columns).\n","Arithmetic operations align on both row and column labels. Can be\n","thought of as a dict-like container for Series objects. The primary\n","pandas data structure.\n","\n","Parameters\n","----------\n","data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n","    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n","    data is a dict, column order follows insertion-order. If a dict contains Series\n","    which have an index defined, it is aligned by its index. This alignment also\n","    occurs if data is a Series or a DataFrame itself. Alignment is done on\n","    Series/DataFrame inputs.\n","\n","    If data is a list of dicts, column order follows insertion-order.\n","\n","index : Index or array-like\n","    Index to use for resulting frame. Will default to RangeIndex if\n","    no indexing information part of input data and no index provided.\n","columns : Index or array-like\n","    Column labels to use for resulting frame when data does not have them,\n","    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n","    will perform column selection instead.\n","dtype : dtype, default None\n","    Data type to force. Only a single dtype is allowed. If None, infer.\n","copy : bool or None, default None\n","    Copy data from inputs.\n","    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n","    or 2d ndarray input, the default of None behaves like ``copy=False``.\n","    If data is a dict containing one or more Series (possibly of different dtypes),\n","    ``copy=False`` will ensure that these inputs are not copied.\n","\n","    .. versionchanged:: 1.3.0\n","\n","See Also\n","--------\n","DataFrame.from_records : Constructor from tuples, also record arrays.\n","DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n","read_csv : Read a comma-separated values (csv) file into DataFrame.\n","read_table : Read general delimited file into DataFrame.\n","read_clipboard : Read text from clipboard into DataFrame.\n","\n","Notes\n","-----\n","Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n","\n","Examples\n","--------\n","Constructing DataFrame from a dictionary.\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n","&gt;&gt;&gt; df = pd.DataFrame(data=d)\n","&gt;&gt;&gt; df\n","   col1  col2\n","0     1     3\n","1     2     4\n","\n","Notice that the inferred dtype is int64.\n","\n","&gt;&gt;&gt; df.dtypes\n","col1    int64\n","col2    int64\n","dtype: object\n","\n","To enforce a single dtype:\n","\n","&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n","&gt;&gt;&gt; df.dtypes\n","col1    int8\n","col2    int8\n","dtype: object\n","\n","Constructing DataFrame from a dictionary including Series:\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n","&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n","   col1  col2\n","0     0   NaN\n","1     1   NaN\n","2     2   2.0\n","3     3   3.0\n","\n","Constructing DataFrame from numpy ndarray:\n","\n","&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n","...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n","&gt;&gt;&gt; df2\n","   a  b  c\n","0  1  2  3\n","1  4  5  6\n","2  7  8  9\n","\n","Constructing DataFrame from a numpy ndarray that has labeled columns:\n","\n","&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n","...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n","&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n","...\n","&gt;&gt;&gt; df3\n","   c  a\n","0  3  1\n","1  6  4\n","2  9  7\n","\n","Constructing DataFrame from dataclass:\n","\n","&gt;&gt;&gt; from dataclasses import make_dataclass\n","&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n","&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n","   x  y\n","0  0  0\n","1  0  3\n","2  2  3\n","\n","Constructing DataFrame from Series/DataFrame:\n","\n","&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df\n","   0\n","a  1\n","c  3\n","\n","&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n","&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df2\n","   x\n","a  1\n","c  3</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 490);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"],"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1153,"status":"ok","timestamp":1713642119742,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"V0zu-EYeB5Tq","outputId":"dcd1b51e-b648-40a2-a566-3fc49c338f3c"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","cm = confusion_matrix(y_test, predictions)\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1713642162072,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"F7M6S6u_CCWS","outputId":"0f679f50-e33d-4a62-cc93-01dc9b77b581"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.95      0.96       401\n","           1       0.95      0.96      0.96       399\n","\n","    accuracy                           0.96       800\n","   macro avg       0.96      0.96      0.96       800\n","weighted avg       0.96      0.96      0.96       800\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, predictions))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1713642178063,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"yw5_YQ2iCHWM","outputId":"5b20da5b-9ffa-4fe2-e501-c8c74cb5cf39"},"outputs":[{"name":"stdout","output_type":"stream","text":["          Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n","70    0.610132 -3.460819   1.336759     0.387452  -0.136781  2.988646   \n","803  -1.071853 -1.496799  -0.303023     1.425078   2.183076  1.532804   \n","1822  0.622759 -4.196353   0.847013     0.431259  -0.302134  3.726932   \n","1992 -2.585616 -0.045807   0.870952    -0.136893  -0.037032  1.071864   \n","33   -0.588796 -1.121987   2.324295     0.311931   5.148739 -3.351988   \n","\n","       Acidity  predicted  actual  \n","70   -2.044769          1       0  \n","803   1.433817          0       1  \n","1822 -1.188430          1       0  \n","1992  1.500015          0       1  \n","33    5.560109          1       0  \n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-5-ea3ecbc74afb>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors['predicted'] = predictions[(predictions != y_test)]\n","<ipython-input-5-ea3ecbc74afb>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors['actual'] = y_test[(predictions != y_test)]\n"]}],"source":["import pandas as pd\n","\n","# Assuming X_test and y_test are in pandas DataFrame and Series\n","errors = X_test[(predictions != y_test)]\n","errors['predicted'] = predictions[(predictions != y_test)]\n","errors['actual'] = y_test[(predictions != y_test)]\n","\n","print(errors.head())  # Display first few error cases\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1713643095437,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"PiXeagvWFbFK","outputId":"97297cfe-f695-4555-ef78-5c2f116e1b13"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"errors[errors['predicted'] == 1]\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5761421272281737,\n        \"min\": -3.615632905,\n        \"max\": 2.849105469,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.610132436,\n          0.080970577,\n          -2.937618954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6684639050571564,\n        \"min\": -4.196352643,\n        \"max\": 3.010306362,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -3.460818667,\n          0.31142236,\n          -0.707787835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sweetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3444321028671853,\n        \"min\": -4.854861307,\n        \"max\": 2.862508115,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1.336759306,\n          2.10226489,\n          1.111767952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Crunchiness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0205460092244896,\n        \"min\": -0.998495945,\n        \"max\": 2.860930855,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.387451504,\n          1.284844839,\n          0.697300735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Juiciness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.325931444331205,\n        \"min\": -2.694129994,\n        \"max\": 5.464513258,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -0.136781229,\n          1.434369092,\n          0.991532995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ripeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9919487799986242,\n        \"min\": -3.74036848,\n        \"max\": 3.726932143,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          2.988645551,\n          -3.74036848,\n          0.388504227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.356492806312614,\n        \"min\": -2.926853781,\n        \"max\": 5.560108693,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -2.044768947,\n          1.05090811,\n          0.848923139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-453eebb9-323b-4d54-83e7-0d49ef3c076a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Size</th>\n","      <th>Weight</th>\n","      <th>Sweetness</th>\n","      <th>Crunchiness</th>\n","      <th>Juiciness</th>\n","      <th>Ripeness</th>\n","      <th>Acidity</th>\n","      <th>predicted</th>\n","      <th>actual</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>70</th>\n","      <td>0.610132</td>\n","      <td>-3.460819</td>\n","      <td>1.336759</td>\n","      <td>0.387452</td>\n","      <td>-0.136781</td>\n","      <td>2.988646</td>\n","      <td>-2.044769</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1822</th>\n","      <td>0.622759</td>\n","      <td>-4.196353</td>\n","      <td>0.847013</td>\n","      <td>0.431259</td>\n","      <td>-0.302134</td>\n","      <td>3.726932</td>\n","      <td>-1.188430</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>-0.588796</td>\n","      <td>-1.121987</td>\n","      <td>2.324295</td>\n","      <td>0.311931</td>\n","      <td>5.148739</td>\n","      <td>-3.351988</td>\n","      <td>5.560109</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3194</th>\n","      <td>0.026097</td>\n","      <td>3.010306</td>\n","      <td>1.712530</td>\n","      <td>1.754225</td>\n","      <td>0.468184</td>\n","      <td>-2.160814</td>\n","      <td>4.902217</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1731</th>\n","      <td>1.416978</td>\n","      <td>-0.450989</td>\n","      <td>-2.499578</td>\n","      <td>1.900472</td>\n","      <td>1.729655</td>\n","      <td>2.024357</td>\n","      <td>-2.657512</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>0.080971</td>\n","      <td>0.311422</td>\n","      <td>2.102265</td>\n","      <td>1.284845</td>\n","      <td>1.434369</td>\n","      <td>-3.740368</td>\n","      <td>1.050908</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2758</th>\n","      <td>-3.615633</td>\n","      <td>-0.425489</td>\n","      <td>1.209044</td>\n","      <td>0.515604</td>\n","      <td>1.166596</td>\n","      <td>-1.149619</td>\n","      <td>-2.789929</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3225</th>\n","      <td>2.849105</td>\n","      <td>-0.810499</td>\n","      <td>-1.769152</td>\n","      <td>0.863339</td>\n","      <td>1.332378</td>\n","      <td>0.049158</td>\n","      <td>1.185050</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2053</th>\n","      <td>0.302576</td>\n","      <td>-2.011767</td>\n","      <td>1.900143</td>\n","      <td>0.533090</td>\n","      <td>1.703285</td>\n","      <td>1.261360</td>\n","      <td>-0.449605</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2256</th>\n","      <td>0.481871</td>\n","      <td>2.273680</td>\n","      <td>-1.456168</td>\n","      <td>2.452204</td>\n","      <td>0.046173</td>\n","      <td>-1.234474</td>\n","      <td>-1.005574</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3693</th>\n","      <td>2.120291</td>\n","      <td>-1.063668</td>\n","      <td>1.514874</td>\n","      <td>0.452447</td>\n","      <td>2.316000</td>\n","      <td>-0.230588</td>\n","      <td>-0.155482</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>-2.937619</td>\n","      <td>-0.707788</td>\n","      <td>1.111768</td>\n","      <td>0.697301</td>\n","      <td>0.991533</td>\n","      <td>0.388504</td>\n","      <td>0.848923</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2622</th>\n","      <td>-1.365908</td>\n","      <td>-0.462259</td>\n","      <td>-4.854861</td>\n","      <td>1.963363</td>\n","      <td>-2.614131</td>\n","      <td>0.343434</td>\n","      <td>-2.926854</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2907</th>\n","      <td>1.102256</td>\n","      <td>-0.278648</td>\n","      <td>-2.752787</td>\n","      <td>2.235502</td>\n","      <td>-2.300817</td>\n","      <td>0.454884</td>\n","      <td>0.532010</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>-1.317609</td>\n","      <td>-1.805642</td>\n","      <td>2.862508</td>\n","      <td>-0.458130</td>\n","      <td>2.058753</td>\n","      <td>2.308896</td>\n","      <td>-0.287477</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3185</th>\n","      <td>-0.703671</td>\n","      <td>-0.870704</td>\n","      <td>0.060564</td>\n","      <td>1.070550</td>\n","      <td>-1.846313</td>\n","      <td>-1.293248</td>\n","      <td>1.215772</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2603</th>\n","      <td>0.555371</td>\n","      <td>-1.114110</td>\n","      <td>-1.171770</td>\n","      <td>-0.998496</td>\n","      <td>5.464513</td>\n","      <td>-1.226260</td>\n","      <td>2.652944</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1940</th>\n","      <td>1.131627</td>\n","      <td>0.920815</td>\n","      <td>-4.106682</td>\n","      <td>2.093651</td>\n","      <td>-1.951436</td>\n","      <td>0.943219</td>\n","      <td>-0.815660</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3784</th>\n","      <td>-0.260338</td>\n","      <td>-1.105664</td>\n","      <td>-2.636020</td>\n","      <td>2.860931</td>\n","      <td>-2.694130</td>\n","      <td>-0.499616</td>\n","      <td>-1.492677</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-453eebb9-323b-4d54-83e7-0d49ef3c076a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-453eebb9-323b-4d54-83e7-0d49ef3c076a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-453eebb9-323b-4d54-83e7-0d49ef3c076a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f08f4fef-19bf-42ca-8c10-f9d579c3395d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f08f4fef-19bf-42ca-8c10-f9d579c3395d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f08f4fef-19bf-42ca-8c10-f9d579c3395d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["          Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n","70    0.610132 -3.460819   1.336759     0.387452  -0.136781  2.988646   \n","1822  0.622759 -4.196353   0.847013     0.431259  -0.302134  3.726932   \n","33   -0.588796 -1.121987   2.324295     0.311931   5.148739 -3.351988   \n","3194  0.026097  3.010306   1.712530     1.754225   0.468184 -2.160814   \n","1731  1.416978 -0.450989  -2.499578     1.900472   1.729655  2.024357   \n","598   0.080971  0.311422   2.102265     1.284845   1.434369 -3.740368   \n","2758 -3.615633 -0.425489   1.209044     0.515604   1.166596 -1.149619   \n","3225  2.849105 -0.810499  -1.769152     0.863339   1.332378  0.049158   \n","2053  0.302576 -2.011767   1.900143     0.533090   1.703285  1.261360   \n","2256  0.481871  2.273680  -1.456168     2.452204   0.046173 -1.234474   \n","3693  2.120291 -1.063668   1.514874     0.452447   2.316000 -0.230588   \n","194  -2.937619 -0.707788   1.111768     0.697301   0.991533  0.388504   \n","2622 -1.365908 -0.462259  -4.854861     1.963363  -2.614131  0.343434   \n","2907  1.102256 -0.278648  -2.752787     2.235502  -2.300817  0.454884   \n","411  -1.317609 -1.805642   2.862508    -0.458130   2.058753  2.308896   \n","3185 -0.703671 -0.870704   0.060564     1.070550  -1.846313 -1.293248   \n","2603  0.555371 -1.114110  -1.171770    -0.998496   5.464513 -1.226260   \n","1940  1.131627  0.920815  -4.106682     2.093651  -1.951436  0.943219   \n","3784 -0.260338 -1.105664  -2.636020     2.860931  -2.694130 -0.499616   \n","\n","       Acidity  predicted  actual  \n","70   -2.044769          1       0  \n","1822 -1.188430          1       0  \n","33    5.560109          1       0  \n","3194  4.902217          1       0  \n","1731 -2.657512          1       0  \n","598   1.050908          1       0  \n","2758 -2.789929          1       0  \n","3225  1.185050          1       0  \n","2053 -0.449605          1       0  \n","2256 -1.005574          1       0  \n","3693 -0.155482          1       0  \n","194   0.848923          1       0  \n","2622 -2.926854          1       0  \n","2907  0.532010          1       0  \n","411  -0.287477          1       0  \n","3185  1.215772          1       0  \n","2603  2.652944          1       0  \n","1940 -0.815660          1       0  \n","3784 -1.492677          1       0  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"elapsed":4,"status":"error","timestamp":1713642317114,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"7OOEZ5CgCb-Z","outputId":"6aa63913-9d5a-4e2d-a81d-7fe49452ff05"},"outputs":[{"ename":"RuntimeError","evalue":"No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5db7d03d09d2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Columns in Weight Matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mcolorbar\u001b[0;34m(mappable, cax, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mmappable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmappable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             raise RuntimeError('No mappable was found to use for colorbar '\n\u001b[0m\u001b[1;32m   2134\u001b[0m                                \u001b[0;34m'creation. First define a mappable such as '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m                                \u001b[0;34m'an image (with imshow) or a contour set ('\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf)."]},{"data":{"image/png":"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\n","text/plain":["<Figure size 1000x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#Visualization of first layer weights. Probably not super valuable.\n","fig, ax = plt.subplots(figsize=(10, 8))\n","ax.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n","plt.title('Heatmap of the First Layer Weights')\n","plt.xlabel('Columns in Weight Matrix')\n","plt.ylabel('Input Features')\n","plt.colorbar()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OShJUItMCqfW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hs5ZD89IxCW1","outputId":"466cf12e-be11-47f5-9869-ce92a313bb3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["50\n","Model accuracy: 0.93\n","100\n","Model accuracy: 0.96\n","150\n","Model accuracy: 0.95\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["200\n","Model accuracy: 0.95\n","250\n","Model accuracy: 0.95\n","300\n","Model accuracy: 0.96\n","350\n","Model accuracy: 0.95\n","400\n","Model accuracy: 0.95\n","450\n","Model accuracy: 0.95\n","500\n","Model accuracy: 0.95\n","550\n","Model accuracy: 0.95\n","600\n","Model accuracy: 0.95\n","650\n","Model accuracy: 0.95\n","700\n","Model accuracy: 0.95\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["750\n","Model accuracy: 0.96\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["800\n","Model accuracy: 0.91\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["850\n","Model accuracy: 0.95\n"]}],"source":["#Let's try some hyperparameter tuning\n","#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","for x in range(50, 1000, 50):\n","  # Initialize MLPClassifier\n","  # This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","  mlp = MLPClassifier(hidden_layer_sizes=(x,), max_iter=2000, activation='relu', solver='adam', random_state=42)\n","\n","  # Fit the model\n","  mlp.fit(X_train_scaled, y_train)\n","\n","  # Make predictions\n","  predictions = mlp.predict(X_test_scaled)\n","\n","  # Evaluate the model\n","  print(x)\n","  accuracy = accuracy_score(y_test, predictions)\n","  print(f\"Model accuracy: {accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vW-lY9VHNrl1"},"outputs":[],"source":["#Let's try some hyperparameter tuning\n","#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","for x in range(1000, 5000, 250):\n","  # Initialize MLPClassifier\n","  # This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","  mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=x, activation='relu', solver='adam', random_state=42)\n","\n","  # Fit the model\n","  mlp.fit(X_train_scaled, y_train)\n","\n","  # Make predictions\n","  predictions = mlp.predict(X_test_scaled)\n","\n","  # Evaluate the model\n","  print(x)\n","  accuracy = accuracy_score(y_test, predictions)\n","  print(f\"Model accuracy: {accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxrVhKaeErlD"},"outputs":[],"source":["#It seems like max_iter and hidden_layer_sizes are basically optimized.\n","#I want to see what happens if I take out some outliers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tW50WCqpFgYd"},"outputs":[],"source":["#Let's mess around with getting rid of outliers.\n","import pandas as pd\n","from scipy.stats import zscore\n","\n","df = data\n","\n","z_scores = df.apply(zscore)\n","\n","# Filter rows where any feature's Z-score is greater than 3\n","filtered_df = df[(z_scores.abs() <= 2.5).all(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ics3nO01G8zd"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZrBbKIrFmS4"},"outputs":[],"source":["filtered_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TN00Xe_uGs3L"},"outputs":[],"source":["features = filtered_df[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = filtered_df['Good']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16440,"status":"ok","timestamp":1713559119337,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"cgo5S9lNHki5","outputId":"26714af1-82e6-4b5d-8cdc-30c218da1cd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model accuracy:  0.932500\n"]}],"source":["#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train = scaler.fit_transform(X_train)\n","X_train = poly.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_test = poly.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100,), alpha=0.0001, max_iter=2000, activation='relu', solver='adam', random_state=42)\n","\n","# Fit the model\n","mlp.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0m5GFb3IG_T"},"outputs":[],"source":["#Tried with a variety of z scores outlier elimination. Nothing really worked.\n","#experimented with solver, activation, max_iter, and hidden_layer_sizes values. Can't seem to find anything to beat it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSqMHiUlIOqD"},"outputs":[],"source":["parameter_space = {\n","    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n","    'activation': 'relu',\n","    'solver': 'adam',\n","    'alpha': [0.0001, 0.05],\n","    'learning_rate': ['constant','adaptive'],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUOuhHuJKL7U"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoIourLLKCoM"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n","clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcJWy3kUKZjm"},"outputs":[],"source":["means = clf.cv_results_['mean_test_score']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuInWmvOLuMe"},"outputs":[],"source":["# All results\n","means = clf.cv_results_['mean_test_score']\n","stds = clf.cv_results_['std_test_score']\n","for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFdolS5zQw0B"},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100,), alpha=0.0002, max_iter=2000, activation='relu', solver='adam', random_state=42)\n","\n","# Fit the model\n","mlp.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZWDJqTWQ8Ww"},"outputs":[],"source":["#MinMax Scaling doesn't seem to work at all. Neither did Robust Scaling, which makes sense.\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","\n","# Initialize PCA - Let's start with using 5 components\n","pca = PCA(n_components=7)\n","\n","# Combine the scaler and PCA in a pipeline\n","preprocessing_pipeline = Pipeline([\n","    ('scaler', scaler),\n","    ('pca', pca)\n","])\n","\n","# Apply the preprocessing pipeline to training and test data\n","X_train_prepared = preprocessing_pipeline.fit_transform(X_train)\n","X_test_prepared = preprocessing_pipeline.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100,), alpha=0.0002, max_iter=2000, activation='relu', solver='adam', random_state=42)\n","\n","# Fit the model\n","mlp.fit(X_train_prepared, y_train)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_prepared)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"markdown","source":["Polynomial Features didn't yield much success.\n","\n","Below, I ran my seemingly lucky model with 10 different seeds.\n","\n","Was it just a lucky model? Looks like it."],"metadata":{"id":"wLwpAxF6--1C"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170079,"status":"ok","timestamp":1713559501169,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"1H0bTY4VWnYs","outputId":"13f44360-6ebb-410b-e41d-2fcac7b00bb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model accuracy:  0.958750\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["Model accuracy:  0.907500\n","Model accuracy:  0.952500\n","Model accuracy:  0.941250\n","Model accuracy:  0.941250\n","Model accuracy:  0.956250\n","Model accuracy:  0.943750\n","Model accuracy:  0.937500\n","Model accuracy:  0.950000\n","Model accuracy:  0.956250\n"]}],"source":["#This gives great results. Messing around with max_iter is important.\n","#Maybe randomforestclassifier caps out around 91% or something.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize MLPClassifier\n","for x in range(10):\n","    mlp = MLPClassifier(hidden_layer_sizes=(100), alpha=0.0002, max_iter=2000, activation='relu', solver='adam', random_state=42 + x)\n","\n","    # Fit the model\n","    mlp.fit(X_train_scaled, y_train)\n","\n","    # Make predictions\n","    predictions = mlp.predict(X_test_scaled)\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(f\"Model accuracy: {accuracy: f}\")\n","\n","#Maybe everything is meaningless and my life is a lie. Maybe we spend our lives chasing imaginary stories and false patterns.\n","#Maybe part of the trick of life is deluding yourself into thinking you're moving somewhere, when we're all just tilting at windmills.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"spWecD-Y_XR0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sequential Models Using Tensorflow Keras"],"metadata":{"id":"yNOjl1PB_YE5"}},{"cell_type":"markdown","source":["Started Small"],"metadata":{"id":"dqUvNtFu_es_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148924,"status":"ok","timestamp":1713817302136,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"vbgnmDDy_zQ3","outputId":"72a5328f-e637-44fa-894b-7f5b93f8b94c"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 2ms/step - loss: 4.2672 - accuracy: 0.7275\n"]},{"data":{"text/plain":["[4.267166614532471, 0.7275000214576721]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","# Create the model\n","model = tf.keras.Sequential([\n","                      tf.keras.layers.Dense(128, activation='relu'),\n","                  tf.keras.layers.Dense(512, activation='relu'),\n","                 tf.keras.layers.Dense(512, activation='relu'),\n","                  tf.keras.layers.Dense(1, activation='sigmoid')\n"," ])\n","# Compile the model\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"Adam\",\n","              metrics=[\"accuracy\"])\n","# Fit the model\n","history = model.fit(X_train,\n","                    y_train,\n","                    epochs=500,\n","                    validation_data=(X_test, y_test),\n","                    verbose=0)\n","model.evaluate(X_test_scaled, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":8224,"status":"error","timestamp":1713471732438,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"8icO0nLNDKba","outputId":"b7eec347-7e19-4dac-c161-e7121527c6c4"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-1510160d430d>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m history = model.fit(X_train_scaled,\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.regularizers import l2\n","\n","\n","# Create the model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"Adam\",\n","              metrics=[\"accuracy\"])\n","\n","# Fit the model\n","history = model.fit(X_train_scaled,\n","                    y_train,\n","                    epochs=2000,\n","                    validation_data=(X_test_scaled, y_test),\n","                    verbose=0)\n","model.evaluate(X_test_scaled, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108032,"status":"ok","timestamp":1713443467108,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"_YDbiVgZF2B6","outputId":"3be2a4d3-a5a4-460b-b46d-bf1839f1141a"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.9337\n"]},{"data":{"text/plain":["[0.31878870725631714, 0.9337499737739563]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.regularizers import l2\n","\n","class DataAugmentationLayer(tf.keras.layers.Layer):\n","    def __init__(self, noise_level=0.1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.noise_level = noise_level\n","\n","    def call(self, inputs, training=None):\n","        if training:\n","            noise = tf.random.normal(shape=tf.shape(inputs), mean=0.0, stddev=self.noise_level)\n","            return inputs + noise\n","        return inputs\n","# Create the model\n","model = tf.keras.Sequential([\n","        DataAugmentationLayer(noise_level=0.05),\n","    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","         tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"Adam\",\n","              metrics=[\"accuracy\"])\n","\n","# Fit the model\n","history = model.fit(X_train_scaled,\n","                    y_train,\n","                    epochs=300,\n","                    validation_data=(X_test_scaled, y_test),\n","                    verbose=0)\n","model.evaluate(X_test_scaled, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1713440463440,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"s0Vh6bkjARkf","outputId":"4e0fe028-6514-4953-ed1f-daeb473a8914"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9400\n"]},{"data":{"text/plain":["[0.28336623311042786, 0.9399999976158142]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(X_test_scaled, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28604,"status":"ok","timestamp":1713471249432,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"N0ExyI4WBskg","outputId":"63287b04-06d5-4f5c-ff8a-2b5d60aa8d5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model accuracy:  0.950000\n"]}],"source":["#data augmentation\n","#Obvious note for a noob: If it performs at 28% accuracy on the training data, it's not trained.\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n","import numpy as np\n","from sklearn.utils import shuffle\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize MLPClassifier\n","# This is a basic setup. You might need to tune the hyperparameters like hidden_layer_sizes, learning_rate_init, etc.\n","mlp = MLPClassifier(hidden_layer_sizes=(100), alpha=0.0002, max_iter=4000, activation='relu', solver='adam', random_state=42)\n","\n","\n","def augment_data(X, method='noise', noise_level=0.01, jitter_factor=0.01):\n","    if method == 'noise':\n","        noise = noise_level * np.random.randn(*X.shape)\n","        return X + noise\n","    elif method == 'jitter':\n","        jitter = np.random.uniform(-jitter_factor, jitter_factor, X.shape)\n","        return X + jitter * X\n","    elif method == 'scaling_shifting':\n","        scaling_factor = np.random.uniform(0.9, 1.1, X.shape[1])\n","        shifting_factor = np.random.uniform(-0.1, 0.1, X.shape[1])\n","        return X * scaling_factor + shifting_factor\n","    else:\n","        return X\n","\n","# Augment data\n","X_train_augmented = augment_data(X_train_scaled, method='scaling_and_shifting')\n","\n","X_train_augmented = np.vstack([X_train_scaled, X_train_augmented])\n","\n","y_train_augmented = np.hstack([y_train, y_train])  # Duplicate y_train\n","\n","# Shuffle the augmented dataset\n","X_train_augmented, y_train_augmented = shuffle(X_train_augmented, y_train_augmented)\n","\n","# Fit model on augmented data\n","mlp.fit(X_train_augmented, y_train_augmented)\n","\n","# Make predictions\n","predictions = mlp.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy: f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1713471138229,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"JXRXSI_ANBk5","outputId":"bbd35206-91dd-4dbe-fec0-94cdcbf1f65f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"X_train\",\n  \"rows\": 3200,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.928901894142339,\n        \"min\": -7.151703059,\n        \"max\": 6.406366899,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          0.040472361,\n          2.450959845,\n          -1.336614769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6004735363937839,\n        \"min\": -7.149847675,\n        \"max\": 5.79071359,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          -1.633222097,\n          -0.564177407,\n          -0.953664344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sweetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9542006166953934,\n        \"min\": -6.894485494,\n        \"max\": 6.374915513,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          0.315512495,\n          -1.635040727,\n          -0.335851672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Crunchiness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.409082690269296,\n        \"min\": -6.055057805,\n        \"max\": 7.619851801,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          -0.601401774,\n          0.942399869,\n          1.314613381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Juiciness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9340884974957246,\n        \"min\": -5.961897048,\n        \"max\": 7.364402864,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          3.664472666,\n          -2.08731667,\n          0.885873038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ripeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8721575104320314,\n        \"min\": -5.864598918,\n        \"max\": 7.237836684,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          -1.831720401,\n          1.214321691,\n          1.376948966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.103839144431454,\n        \"min\": -7.010538475,\n        \"max\": 7.404736238,\n        \"num_unique_values\": 3200,\n        \"samples\": [\n          3.404747277,\n          1.294323927,\n          0.643951904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"X_train"},"text/html":["\n","  <div id=\"df-bbcab1fc-181a-4385-8209-9a0374a13fbc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Size</th>\n","      <th>Weight</th>\n","      <th>Sweetness</th>\n","      <th>Crunchiness</th>\n","      <th>Juiciness</th>\n","      <th>Ripeness</th>\n","      <th>Acidity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3994</th>\n","      <td>1.482508</td>\n","      <td>-2.581181</td>\n","      <td>-0.306888</td>\n","      <td>1.527877</td>\n","      <td>1.056361</td>\n","      <td>2.560829</td>\n","      <td>-1.229255</td>\n","    </tr>\n","    <tr>\n","      <th>423</th>\n","      <td>-0.166097</td>\n","      <td>0.385633</td>\n","      <td>-1.102875</td>\n","      <td>0.473802</td>\n","      <td>0.325483</td>\n","      <td>0.983244</td>\n","      <td>-2.171938</td>\n","    </tr>\n","    <tr>\n","      <th>2991</th>\n","      <td>-2.508892</td>\n","      <td>-2.843436</td>\n","      <td>-0.848363</td>\n","      <td>-0.483352</td>\n","      <td>-0.095337</td>\n","      <td>5.111046</td>\n","      <td>-1.805348</td>\n","    </tr>\n","    <tr>\n","      <th>1221</th>\n","      <td>-1.380463</td>\n","      <td>-0.521432</td>\n","      <td>3.335713</td>\n","      <td>0.143991</td>\n","      <td>2.513751</td>\n","      <td>-0.466679</td>\n","      <td>-0.030533</td>\n","    </tr>\n","    <tr>\n","      <th>506</th>\n","      <td>-2.073640</td>\n","      <td>-1.212834</td>\n","      <td>-0.818440</td>\n","      <td>3.808835</td>\n","      <td>1.013863</td>\n","      <td>0.748661</td>\n","      <td>0.026134</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbcab1fc-181a-4385-8209-9a0374a13fbc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bbcab1fc-181a-4385-8209-9a0374a13fbc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bbcab1fc-181a-4385-8209-9a0374a13fbc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-284d282e-471a-42e6-aeb6-9ad1926fa681\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-284d282e-471a-42e6-aeb6-9ad1926fa681')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-284d282e-471a-42e6-aeb6-9ad1926fa681 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["          Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n","3994  1.482508 -2.581181  -0.306888     1.527877   1.056361  2.560829   \n","423  -0.166097  0.385633  -1.102875     0.473802   0.325483  0.983244   \n","2991 -2.508892 -2.843436  -0.848363    -0.483352  -0.095337  5.111046   \n","1221 -1.380463 -0.521432   3.335713     0.143991   2.513751 -0.466679   \n","506  -2.073640 -1.212834  -0.818440     3.808835   1.013863  0.748661   \n","\n","       Acidity  \n","3994 -1.229255  \n","423  -2.171938  \n","2991 -1.805348  \n","1221 -0.030533  \n","506   0.026134  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["X_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713443733266,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"pe4BInEwNEQN","outputId":"24eeafff-d7b4-4a5c-f4bb-1475ac239ad9"},"outputs":[{"data":{"text/plain":["(6400, 7)"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["X_train_augmented.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713469946350,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"vzdoXwXLxDmx","outputId":"6b7742dd-2cf3-4ebe-9c1b-4ed8e3330197"},"outputs":[{"data":{"text/plain":["(800, 7)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MedzVJw5RFdc"},"outputs":[],"source":["#in the above, the results are not reproducible because i'm not using a numpy random seed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6183,"status":"ok","timestamp":1713472385311,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"ivvDkge56Xqe","outputId":"57c0ee8c-e73c-4bee-e831-5b6598cb710c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"]}],"source":["!pip install xgboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQ21JI4C6rCH"},"outputs":[],"source":["#Imma try xgbclassifier.\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"elapsed":5661,"status":"ok","timestamp":1713560170575,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"unlqMDS26y1K","outputId":"0cd20a5d-f4d5-4eaf-e13f-e0a9bbd6e213"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=50, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=1000, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=50, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=1000, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=50, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=1000, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["from xgboost import XGBClassifier\n","\n","# Create an instance of the XGBClassifier\n","model = XGBClassifier(\n","    objective='binary:logistic',  # Use 'multi:softmax' for multiclass and set `num_class`\n","    n_estimators=1000,  # Number of trees\n","    learning_rate=0.01,  # Step size shrinkage\n","    max_depth=50,\n","    seed=42  # Random seed for reproducibility\n",")\n","\n","# Fit the model on the training data\n","model.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713560170576,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"qJ5kVpKL66g4","outputId":"15be561b-ee15-4c03-a828-c9a9cff76d25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.91375\n","Confusion Matrix:\n"," [[364  37]\n"," [ 32 367]]\n"]}],"source":["from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Predictions on test data\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the predictions\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B1NGiWgwKREe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRRwm-5JKRX2"},"outputs":[],"source":["#Let's grab that original data, without the buckets.\n","import pandas as pd\n","#Let's perform a super simple and easy Random Forest Classifier.\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/data/cleaned_data.csv\")\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rlhAl2bZGd3v"},"outputs":[],"source":["#Obstacles: I accidentally used the wrong data at some point. It was iris data.\n","#I also accidentally messed up my data because jupyter notebooks kind of make that easy. And I didn't realize that. So I was working with data that just didn't work very well.\n","#When doing gridsearchcv, I should've used list comprehension to make the list. Instead, I manually typed it out and made a typo."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1792,"status":"ok","timestamp":1713559502959,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"DSEQoK-O7riP","outputId":"5b349d69-9633-42e1-8829-76dce0fe25b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 5 candidates, totalling 25 fits\n","[CV 1/5; 1/5] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 1/5; 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.869 total time=   0.0s\n","[CV 2/5; 1/5] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 2/5; 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.856 total time=   0.0s\n","[CV 3/5; 1/5] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 3/5; 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.856 total time=   0.0s\n","[CV 4/5; 1/5] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 4/5; 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.872 total time=   0.0s\n","[CV 5/5; 1/5] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 5/5; 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.880 total time=   0.0s\n","[CV 1/5; 2/5] START C=0.5, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 1/5; 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n","[CV 2/5; 2/5] START C=0.5, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 2/5; 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.858 total time=   0.1s\n","[CV 3/5; 2/5] START C=0.5, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 3/5; 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.861 total time=   0.1s\n","[CV 4/5; 2/5] START C=0.5, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 4/5; 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.867 total time=   0.1s\n","[CV 5/5; 2/5] START C=0.5, max_iter=1000, penalty=l1, solver=liblinear..........\n","[CV 5/5; 2/5] END C=0.5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.884 total time=   0.1s\n","[CV 1/5; 3/5] START C=1, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 1/5; 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.859 total time=   0.1s\n","[CV 2/5; 3/5] START C=1, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 2/5; 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.859 total time=   0.1s\n","[CV 3/5; 3/5] START C=1, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 3/5; 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.861 total time=   0.1s\n","[CV 4/5; 3/5] START C=1, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 4/5; 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.867 total time=   0.1s\n","[CV 5/5; 3/5] START C=1, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 5/5; 3/5] END C=1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.884 total time=   0.1s\n","[CV 1/5; 4/5] START C=5, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 1/5; 4/5] END C=5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.861 total time=   0.1s\n","[CV 2/5; 4/5] START C=5, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 2/5; 4/5] END C=5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.859 total time=   0.1s\n","[CV 3/5; 4/5] START C=5, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 3/5; 4/5] END C=5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.858 total time=   0.1s\n","[CV 4/5; 4/5] START C=5, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 4/5; 4/5] END C=5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.866 total time=   0.1s\n","[CV 5/5; 4/5] START C=5, max_iter=1000, penalty=l1, solver=liblinear............\n","[CV 5/5; 4/5] END C=5, max_iter=1000, penalty=l1, solver=liblinear;, score=0.883 total time=   0.1s\n","[CV 1/5; 5/5] START C=10, max_iter=1000, penalty=l1, solver=liblinear...........\n","[CV 1/5; 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.861 total time=   0.1s\n","[CV 2/5; 5/5] START C=10, max_iter=1000, penalty=l1, solver=liblinear...........\n","[CV 2/5; 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.859 total time=   0.1s\n","[CV 3/5; 5/5] START C=10, max_iter=1000, penalty=l1, solver=liblinear...........\n","[CV 3/5; 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.858 total time=   0.1s\n","[CV 4/5; 5/5] START C=10, max_iter=1000, penalty=l1, solver=liblinear...........\n","[CV 4/5; 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.866 total time=   0.1s\n","[CV 5/5; 5/5] START C=10, max_iter=1000, penalty=l1, solver=liblinear...........\n","[CV 5/5; 5/5] END C=10, max_iter=1000, penalty=l1, solver=liblinear;, score=0.881 total time=   0.1s\n","Best hyperparameters: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n","Accuracy: 0.88125\n","Confusion matrix: \n","[[358  43]\n"," [ 52 347]]\n","ROC AUC score: 0.9460496628103926\n"]}],"source":["#ugh\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n","\n","\n","# Preprocess the numerical features by scaling them and adding polynomial features\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test)\n","\n","# Define the hyperparameter grid for logistic regression\n","'''param_grid = {'C': [0.1, 0.5, 1, 5, 10],\n","              'penalty': ['l1', 'l2'],\n","              'solver': ['liblinear', 'saga'],\n","              'max_iter': [i for i in range(500, 5000, 10000)]}'''\n","\n","param_grid = {'C': [0.1, 0.5, 1, 5, 10],\n","              'penalty': ['l1'],\n","              'solver': ['liblinear'],\n","              'max_iter': [1000]}\n","\n","# Perform grid search to find the best hyperparameters\n","grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=10)\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Train a logistic regression model with the best hyperparameters\n","best_model = grid_search.best_estimator_\n","best_model.fit(X_train_scaled, y_train)\n","\n","# Predict on the testing set\n","y_pred = best_model.predict(X_test_scaled)\n","y_prob = best_model.predict_proba(X_test_scaled)[:,1]\n","\n","# Evaluate the model performance\n","accuracy = accuracy_score(y_test, y_pred)\n","confusion = confusion_matrix(y_test, y_pred)\n","roc_auc = roc_auc_score(y_test, y_prob)\n","\n","print(f'Best hyperparameters: {grid_search.best_params_}')\n","print(f'Accuracy: {accuracy}')\n","print(f'Confusion matrix: \\n{confusion}')\n","print(f'ROC AUC score: {roc_auc}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C0fmfNpF0eC","outputId":"14d9ecd2-452f-4ca3-bb25-e39f7ec8283f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 30 candidates, totalling 90 fits\n","[CV 1/3; 1/30] START alpha=5e-05, max_iter=100..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 1/30] END ...alpha=5e-05, max_iter=100;, score=0.894 total time=   1.3s\n","[CV 2/3; 1/30] START alpha=5e-05, max_iter=100..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 1/30] END ...alpha=5e-05, max_iter=100;, score=0.926 total time=   1.2s\n","[CV 3/3; 1/30] START alpha=5e-05, max_iter=100..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 1/30] END ...alpha=5e-05, max_iter=100;, score=0.925 total time=   1.2s\n","[CV 1/3; 2/30] START alpha=5e-05, max_iter=250..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 2/30] END ...alpha=5e-05, max_iter=250;, score=0.909 total time=   2.9s\n","[CV 2/3; 2/30] START alpha=5e-05, max_iter=250..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 2/30] END ...alpha=5e-05, max_iter=250;, score=0.934 total time=   3.0s\n","[CV 3/3; 2/30] START alpha=5e-05, max_iter=250..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 2/30] END ...alpha=5e-05, max_iter=250;, score=0.936 total time=   3.6s\n","[CV 1/3; 3/30] START alpha=5e-05, max_iter=400..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 3/30] END ...alpha=5e-05, max_iter=400;, score=0.899 total time=   4.8s\n","[CV 2/3; 3/30] START alpha=5e-05, max_iter=400..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 3/30] END ...alpha=5e-05, max_iter=400;, score=0.934 total time=   4.6s\n","[CV 3/3; 3/30] START alpha=5e-05, max_iter=400..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 3/30] END ...alpha=5e-05, max_iter=400;, score=0.931 total time=   5.9s\n","[CV 1/3; 4/30] START alpha=5e-05, max_iter=550..................................\n","[CV 1/3; 4/30] END ...alpha=5e-05, max_iter=550;, score=0.899 total time=   5.9s\n","[CV 2/3; 4/30] START alpha=5e-05, max_iter=550..................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (550) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 4/30] END ...alpha=5e-05, max_iter=550;, score=0.932 total time=   7.4s\n","[CV 3/3; 4/30] START alpha=5e-05, max_iter=550..................................\n","[CV 3/3; 4/30] END ...alpha=5e-05, max_iter=550;, score=0.932 total time=   6.3s\n","[CV 1/3; 5/30] START alpha=5e-05, max_iter=700..................................\n","[CV 1/3; 5/30] END ...alpha=5e-05, max_iter=700;, score=0.899 total time=   7.1s\n","[CV 2/3; 5/30] START alpha=5e-05, max_iter=700..................................\n","[CV 2/3; 5/30] END ...alpha=5e-05, max_iter=700;, score=0.932 total time=   9.5s\n","[CV 3/3; 5/30] START alpha=5e-05, max_iter=700..................................\n","[CV 3/3; 5/30] END ...alpha=5e-05, max_iter=700;, score=0.932 total time=   7.6s\n","[CV 1/3; 6/30] START alpha=5e-05, max_iter=850..................................\n","[CV 1/3; 6/30] END ...alpha=5e-05, max_iter=850;, score=0.899 total time=   6.2s\n","[CV 2/3; 6/30] START alpha=5e-05, max_iter=850..................................\n","[CV 2/3; 6/30] END ...alpha=5e-05, max_iter=850;, score=0.932 total time=   7.6s\n","[CV 3/3; 6/30] START alpha=5e-05, max_iter=850..................................\n","[CV 3/3; 6/30] END ...alpha=5e-05, max_iter=850;, score=0.932 total time=   7.0s\n","[CV 1/3; 7/30] START alpha=0.0001, max_iter=100.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 7/30] END ..alpha=0.0001, max_iter=100;, score=0.895 total time=   1.5s\n","[CV 2/3; 7/30] START alpha=0.0001, max_iter=100.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 7/30] END ..alpha=0.0001, max_iter=100;, score=0.925 total time=   1.2s\n","[CV 3/3; 7/30] START alpha=0.0001, max_iter=100.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 7/30] END ..alpha=0.0001, max_iter=100;, score=0.923 total time=   1.2s\n","[CV 1/3; 8/30] START alpha=0.0001, max_iter=250.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 8/30] END ..alpha=0.0001, max_iter=250;, score=0.907 total time=   3.0s\n","[CV 2/3; 8/30] START alpha=0.0001, max_iter=250.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 8/30] END ..alpha=0.0001, max_iter=250;, score=0.935 total time=   2.9s\n","[CV 3/3; 8/30] START alpha=0.0001, max_iter=250.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 8/30] END ..alpha=0.0001, max_iter=250;, score=0.934 total time=   3.3s\n","[CV 1/3; 9/30] START alpha=0.0001, max_iter=400.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 9/30] END ..alpha=0.0001, max_iter=400;, score=0.901 total time=   5.4s\n","[CV 2/3; 9/30] START alpha=0.0001, max_iter=400.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 9/30] END ..alpha=0.0001, max_iter=400;, score=0.934 total time=   4.7s\n","[CV 3/3; 9/30] START alpha=0.0001, max_iter=400.................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 9/30] END ..alpha=0.0001, max_iter=400;, score=0.932 total time=   7.4s\n","[CV 1/3; 10/30] START alpha=0.0001, max_iter=550................................\n","[CV 1/3; 10/30] END .alpha=0.0001, max_iter=550;, score=0.902 total time=   7.7s\n","[CV 2/3; 10/30] START alpha=0.0001, max_iter=550................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (550) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 10/30] END .alpha=0.0001, max_iter=550;, score=0.931 total time=   7.5s\n","[CV 3/3; 10/30] START alpha=0.0001, max_iter=550................................\n","[CV 3/3; 10/30] END .alpha=0.0001, max_iter=550;, score=0.932 total time=   6.3s\n","[CV 1/3; 11/30] START alpha=0.0001, max_iter=700................................\n","[CV 1/3; 11/30] END .alpha=0.0001, max_iter=700;, score=0.902 total time=   7.5s\n","[CV 2/3; 11/30] START alpha=0.0001, max_iter=700................................\n","[CV 2/3; 11/30] END .alpha=0.0001, max_iter=700;, score=0.930 total time=   7.4s\n","[CV 3/3; 11/30] START alpha=0.0001, max_iter=700................................\n","[CV 3/3; 11/30] END .alpha=0.0001, max_iter=700;, score=0.932 total time=   7.0s\n","[CV 1/3; 12/30] START alpha=0.0001, max_iter=850................................\n","[CV 1/3; 12/30] END .alpha=0.0001, max_iter=850;, score=0.902 total time=   7.3s\n","[CV 2/3; 12/30] START alpha=0.0001, max_iter=850................................\n","[CV 2/3; 12/30] END .alpha=0.0001, max_iter=850;, score=0.930 total time=   7.6s\n","[CV 3/3; 12/30] START alpha=0.0001, max_iter=850................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 12/30] END .alpha=0.0001, max_iter=850;, score=0.935 total time=   5.8s\n","[CV 1/3; 13/30] START alpha=0.00015000000000000001, max_iter=100................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 13/30] END alpha=0.00015000000000000001, max_iter=100;, score=0.893 total time=   1.2s\n","[CV 2/3; 13/30] START alpha=0.00015000000000000001, max_iter=100................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3; 13/30] END alpha=0.00015000000000000001, max_iter=100;, score=0.873 total time=   0.2s\n","[CV 3/3; 13/30] START alpha=0.00015000000000000001, max_iter=100................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3; 13/30] END alpha=0.00015000000000000001, max_iter=100;, score=0.923 total time=   1.2s\n","[CV 1/3; 14/30] START alpha=0.00015000000000000001, max_iter=250................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3; 14/30] END alpha=0.00015000000000000001, max_iter=250;, score=0.909 total time=   2.4s\n","[CV 2/3; 14/30] START alpha=0.00015000000000000001, max_iter=250................\n"]}],"source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'alpha': [i * pow(10, -5) for i in range(5, 30, 5)],\n","    'max_iter': [i for i in range(100, 1000, 150)],\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(alpha=0.0001, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=3, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182632,"status":"ok","timestamp":1713530858516,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"ZoyoZJjnYmmw","outputId":"da4f2a47-46fb-446b-9233-9de5b743db2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","[CV 1/3; 1/8] START max_iter=1000...............................................\n","[CV 1/3; 1/8] END ................max_iter=1000;, score=0.899 total time=   6.5s\n","[CV 2/3; 1/8] START max_iter=1000...............................................\n","[CV 2/3; 1/8] END ................max_iter=1000;, score=0.932 total time=   8.1s\n","[CV 3/3; 1/8] START max_iter=1000...............................................\n","[CV 3/3; 1/8] END ................max_iter=1000;, score=0.932 total time=   6.3s\n","[CV 1/3; 2/8] START max_iter=1500...............................................\n","[CV 1/3; 2/8] END ................max_iter=1500;, score=0.899 total time=   6.7s\n","[CV 2/3; 2/8] START max_iter=1500...............................................\n","[CV 2/3; 2/8] END ................max_iter=1500;, score=0.932 total time=   7.2s\n","[CV 3/3; 2/8] START max_iter=1500...............................................\n","[CV 3/3; 2/8] END ................max_iter=1500;, score=0.932 total time=   7.5s\n","[CV 1/3; 3/8] START max_iter=2000...............................................\n","[CV 1/3; 3/8] END ................max_iter=2000;, score=0.899 total time=   5.9s\n","[CV 2/3; 3/8] START max_iter=2000...............................................\n","[CV 2/3; 3/8] END ................max_iter=2000;, score=0.932 total time=   8.2s\n","[CV 3/3; 3/8] START max_iter=2000...............................................\n","[CV 3/3; 3/8] END ................max_iter=2000;, score=0.932 total time=   6.3s\n","[CV 1/3; 4/8] START max_iter=2500...............................................\n","[CV 1/3; 4/8] END ................max_iter=2500;, score=0.899 total time=   6.7s\n","[CV 2/3; 4/8] START max_iter=2500...............................................\n","[CV 2/3; 4/8] END ................max_iter=2500;, score=0.932 total time=   7.3s\n","[CV 3/3; 4/8] START max_iter=2500...............................................\n","[CV 3/3; 4/8] END ................max_iter=2500;, score=0.932 total time=   7.1s\n","[CV 1/3; 5/8] START max_iter=3000...............................................\n","[CV 1/3; 5/8] END ................max_iter=3000;, score=0.899 total time=   6.0s\n","[CV 2/3; 5/8] START max_iter=3000...............................................\n","[CV 2/3; 5/8] END ................max_iter=3000;, score=0.932 total time=   8.1s\n","[CV 3/3; 5/8] START max_iter=3000...............................................\n","[CV 3/3; 5/8] END ................max_iter=3000;, score=0.932 total time=   7.3s\n","[CV 1/3; 6/8] START max_iter=3500...............................................\n","[CV 1/3; 6/8] END ................max_iter=3500;, score=0.899 total time=   6.4s\n","[CV 2/3; 6/8] START max_iter=3500...............................................\n","[CV 2/3; 6/8] END ................max_iter=3500;, score=0.932 total time=   8.1s\n","[CV 3/3; 6/8] START max_iter=3500...............................................\n","[CV 3/3; 6/8] END ................max_iter=3500;, score=0.932 total time=   6.3s\n","[CV 1/3; 7/8] START max_iter=4000...............................................\n","[CV 1/3; 7/8] END ................max_iter=4000;, score=0.899 total time=   7.1s\n","[CV 2/3; 7/8] START max_iter=4000...............................................\n","[CV 2/3; 7/8] END ................max_iter=4000;, score=0.932 total time=   7.5s\n","[CV 3/3; 7/8] START max_iter=4000...............................................\n","[CV 3/3; 7/8] END ................max_iter=4000;, score=0.932 total time=   7.4s\n","[CV 1/3; 8/8] START max_iter=4500...............................................\n","[CV 1/3; 8/8] END ................max_iter=4500;, score=0.899 total time=   5.9s\n","[CV 2/3; 8/8] START max_iter=4500...............................................\n","[CV 2/3; 8/8] END ................max_iter=4500;, score=0.932 total time=   8.3s\n","[CV 3/3; 8/8] START max_iter=4500...............................................\n","[CV 3/3; 8/8] END ................max_iter=4500;, score=0.932 total time=   7.1s\n","Best parameters: {'max_iter': 1000}\n","Best score:  0.9209410989647348\n","Model accuracy: 0.9325\n"]}],"source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [i for i in range(1000, 5000, 500)]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(alpha=0.00005, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=3, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efb1n8ekZgOM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406790,"status":"ok","timestamp":1713531441795,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"7kaevCJYZgi_","outputId":"aee1c314-db7f-4f2c-b1a5-add2b7fa78e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 8 candidates, totalling 40 fits\n","[CV 1/5; 1/8] START max_iter=1000...............................................\n","[CV 1/5; 1/8] END ................max_iter=1000;, score=0.898 total time=  13.2s\n","[CV 2/5; 1/8] START max_iter=1000...............................................\n","[CV 2/5; 1/8] END ................max_iter=1000;, score=0.923 total time=   9.8s\n","[CV 3/5; 1/8] START max_iter=1000...............................................\n","[CV 3/5; 1/8] END ................max_iter=1000;, score=0.925 total time=  10.1s\n","[CV 4/5; 1/8] START max_iter=1000...............................................\n","[CV 4/5; 1/8] END ................max_iter=1000;, score=0.923 total time=   9.9s\n","[CV 5/5; 1/8] START max_iter=1000...............................................\n","[CV 5/5; 1/8] END ................max_iter=1000;, score=0.934 total time=   9.7s\n","[CV 1/5; 2/8] START max_iter=1500...............................................\n","[CV 1/5; 2/8] END ................max_iter=1500;, score=0.898 total time=   9.3s\n","[CV 2/5; 2/8] START max_iter=1500...............................................\n","[CV 2/5; 2/8] END ................max_iter=1500;, score=0.923 total time=  10.1s\n","[CV 3/5; 2/8] START max_iter=1500...............................................\n","[CV 3/5; 2/8] END ................max_iter=1500;, score=0.925 total time=   9.0s\n","[CV 4/5; 2/8] START max_iter=1500...............................................\n","[CV 4/5; 2/8] END ................max_iter=1500;, score=0.923 total time=   9.5s\n","[CV 5/5; 2/8] START max_iter=1500...............................................\n","[CV 5/5; 2/8] END ................max_iter=1500;, score=0.934 total time=  10.6s\n","[CV 1/5; 3/8] START max_iter=2000...............................................\n","[CV 1/5; 3/8] END ................max_iter=2000;, score=0.898 total time=   8.5s\n","[CV 2/5; 3/8] START max_iter=2000...............................................\n","[CV 2/5; 3/8] END ................max_iter=2000;, score=0.923 total time=   9.8s\n","[CV 3/5; 3/8] START max_iter=2000...............................................\n","[CV 3/5; 3/8] END ................max_iter=2000;, score=0.925 total time=  11.3s\n","[CV 4/5; 3/8] START max_iter=2000...............................................\n","[CV 4/5; 3/8] END ................max_iter=2000;, score=0.923 total time=   9.1s\n","[CV 5/5; 3/8] START max_iter=2000...............................................\n","[CV 5/5; 3/8] END ................max_iter=2000;, score=0.934 total time=   9.6s\n","[CV 1/5; 4/8] START max_iter=2500...............................................\n","[CV 1/5; 4/8] END ................max_iter=2500;, score=0.898 total time=   8.8s\n","[CV 2/5; 4/8] START max_iter=2500...............................................\n","[CV 2/5; 4/8] END ................max_iter=2500;, score=0.923 total time=   9.8s\n","[CV 3/5; 4/8] START max_iter=2500...............................................\n","[CV 3/5; 4/8] END ................max_iter=2500;, score=0.925 total time=   9.8s\n","[CV 4/5; 4/8] START max_iter=2500...............................................\n","[CV 4/5; 4/8] END ................max_iter=2500;, score=0.923 total time=   8.6s\n","[CV 5/5; 4/8] START max_iter=2500...............................................\n","[CV 5/5; 4/8] END ................max_iter=2500;, score=0.934 total time=  10.2s\n","[CV 1/5; 5/8] START max_iter=3000...............................................\n","[CV 1/5; 5/8] END ................max_iter=3000;, score=0.898 total time=   9.3s\n","[CV 2/5; 5/8] START max_iter=3000...............................................\n","[CV 2/5; 5/8] END ................max_iter=3000;, score=0.923 total time=   9.0s\n","[CV 3/5; 5/8] START max_iter=3000...............................................\n","[CV 3/5; 5/8] END ................max_iter=3000;, score=0.925 total time=  10.3s\n","[CV 4/5; 5/8] START max_iter=3000...............................................\n","[CV 4/5; 5/8] END ................max_iter=3000;, score=0.923 total time=   9.4s\n","[CV 5/5; 5/8] START max_iter=3000...............................................\n","[CV 5/5; 5/8] END ................max_iter=3000;, score=0.934 total time=  10.4s\n","[CV 1/5; 6/8] START max_iter=3500...............................................\n","[CV 1/5; 6/8] END ................max_iter=3500;, score=0.898 total time=   8.8s\n","[CV 2/5; 6/8] START max_iter=3500...............................................\n","[CV 2/5; 6/8] END ................max_iter=3500;, score=0.923 total time=  10.3s\n","[CV 3/5; 6/8] START max_iter=3500...............................................\n","[CV 3/5; 6/8] END ................max_iter=3500;, score=0.925 total time=  11.7s\n","[CV 4/5; 6/8] START max_iter=3500...............................................\n","[CV 4/5; 6/8] END ................max_iter=3500;, score=0.923 total time=   8.6s\n","[CV 5/5; 6/8] START max_iter=3500...............................................\n","[CV 5/5; 6/8] END ................max_iter=3500;, score=0.934 total time=  10.4s\n","[CV 1/5; 7/8] START max_iter=4000...............................................\n","[CV 1/5; 7/8] END ................max_iter=4000;, score=0.898 total time=   9.6s\n","[CV 2/5; 7/8] START max_iter=4000...............................................\n","[CV 2/5; 7/8] END ................max_iter=4000;, score=0.923 total time=   9.8s\n","[CV 3/5; 7/8] START max_iter=4000...............................................\n","[CV 3/5; 7/8] END ................max_iter=4000;, score=0.925 total time=   9.4s\n","[CV 4/5; 7/8] START max_iter=4000...............................................\n","[CV 4/5; 7/8] END ................max_iter=4000;, score=0.923 total time=   9.6s\n","[CV 5/5; 7/8] START max_iter=4000...............................................\n","[CV 5/5; 7/8] END ................max_iter=4000;, score=0.934 total time=  11.0s\n","[CV 1/5; 8/8] START max_iter=4500...............................................\n","[CV 1/5; 8/8] END ................max_iter=4500;, score=0.898 total time=   9.1s\n","[CV 2/5; 8/8] START max_iter=4500...............................................\n","[CV 2/5; 8/8] END ................max_iter=4500;, score=0.923 total time=   9.6s\n","[CV 3/5; 8/8] START max_iter=4500...............................................\n","[CV 3/5; 8/8] END ................max_iter=4500;, score=0.925 total time=  10.7s\n","[CV 4/5; 8/8] START max_iter=4500...............................................\n","[CV 4/5; 8/8] END ................max_iter=4500;, score=0.923 total time=   9.5s\n","[CV 5/5; 8/8] START max_iter=4500...............................................\n","[CV 5/5; 8/8] END ................max_iter=4500;, score=0.934 total time=  10.2s\n","Best parameters: {'max_iter': 1000}\n","Best score:  0.9209375\n","Model accuracy: 0.9325\n"]}],"source":["#same thing, trying with cv = 5.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [i for i in range(1000, 5000, 500)]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(alpha=0.00005, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsMGIODWcLf1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377390,"status":"ok","timestamp":1713531980644,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"lg_QIOOrcNX2","outputId":"3a2ffe83-751e-4418-e03a-331f0b1e163b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 8 candidates, totalling 40 fits\n","[CV 1/5; 1/8] START max_iter=1000...............................................\n","[CV 1/5; 1/8] END ................max_iter=1000;, score=0.900 total time=   9.3s\n","[CV 2/5; 1/8] START max_iter=1000...............................................\n","[CV 2/5; 1/8] END ................max_iter=1000;, score=0.917 total time=   9.2s\n","[CV 3/5; 1/8] START max_iter=1000...............................................\n","[CV 3/5; 1/8] END ................max_iter=1000;, score=0.925 total time=   8.9s\n","[CV 4/5; 1/8] START max_iter=1000...............................................\n","[CV 4/5; 1/8] END ................max_iter=1000;, score=0.930 total time=   9.3s\n","[CV 5/5; 1/8] START max_iter=1000...............................................\n","[CV 5/5; 1/8] END ................max_iter=1000;, score=0.933 total time=   9.3s\n","[CV 1/5; 2/8] START max_iter=1500...............................................\n","[CV 1/5; 2/8] END ................max_iter=1500;, score=0.900 total time=   8.8s\n","[CV 2/5; 2/8] START max_iter=1500...............................................\n","[CV 2/5; 2/8] END ................max_iter=1500;, score=0.917 total time=  10.1s\n","[CV 3/5; 2/8] START max_iter=1500...............................................\n","[CV 3/5; 2/8] END ................max_iter=1500;, score=0.925 total time=  10.0s\n","[CV 4/5; 2/8] START max_iter=1500...............................................\n","[CV 4/5; 2/8] END ................max_iter=1500;, score=0.930 total time=   8.3s\n","[CV 5/5; 2/8] START max_iter=1500...............................................\n","[CV 5/5; 2/8] END ................max_iter=1500;, score=0.933 total time=   9.8s\n","[CV 1/5; 3/8] START max_iter=2000...............................................\n","[CV 1/5; 3/8] END ................max_iter=2000;, score=0.900 total time=   9.4s\n","[CV 2/5; 3/8] START max_iter=2000...............................................\n","[CV 2/5; 3/8] END ................max_iter=2000;, score=0.917 total time=   8.8s\n","[CV 3/5; 3/8] START max_iter=2000...............................................\n","[CV 3/5; 3/8] END ................max_iter=2000;, score=0.925 total time=   9.0s\n","[CV 4/5; 3/8] START max_iter=2000...............................................\n","[CV 4/5; 3/8] END ................max_iter=2000;, score=0.930 total time=   9.1s\n","[CV 5/5; 3/8] START max_iter=2000...............................................\n","[CV 5/5; 3/8] END ................max_iter=2000;, score=0.933 total time=   8.8s\n","[CV 1/5; 4/8] START max_iter=2500...............................................\n","[CV 1/5; 4/8] END ................max_iter=2500;, score=0.900 total time=   9.3s\n","[CV 2/5; 4/8] START max_iter=2500...............................................\n","[CV 2/5; 4/8] END ................max_iter=2500;, score=0.917 total time=  10.1s\n","[CV 3/5; 4/8] START max_iter=2500...............................................\n","[CV 3/5; 4/8] END ................max_iter=2500;, score=0.925 total time=   8.0s\n","[CV 4/5; 4/8] START max_iter=2500...............................................\n","[CV 4/5; 4/8] END ................max_iter=2500;, score=0.930 total time=  10.7s\n","[CV 5/5; 4/8] START max_iter=2500...............................................\n","[CV 5/5; 4/8] END ................max_iter=2500;, score=0.933 total time=   9.6s\n","[CV 1/5; 5/8] START max_iter=3000...............................................\n","[CV 1/5; 5/8] END ................max_iter=3000;, score=0.900 total time=   9.2s\n","[CV 2/5; 5/8] START max_iter=3000...............................................\n","[CV 2/5; 5/8] END ................max_iter=3000;, score=0.917 total time=   9.6s\n","[CV 3/5; 5/8] START max_iter=3000...............................................\n","[CV 3/5; 5/8] END ................max_iter=3000;, score=0.925 total time=   8.9s\n","[CV 4/5; 5/8] START max_iter=3000...............................................\n","[CV 4/5; 5/8] END ................max_iter=3000;, score=0.930 total time=   8.9s\n","[CV 5/5; 5/8] START max_iter=3000...............................................\n","[CV 5/5; 5/8] END ................max_iter=3000;, score=0.933 total time=   9.1s\n","[CV 1/5; 6/8] START max_iter=3500...............................................\n","[CV 1/5; 6/8] END ................max_iter=3500;, score=0.900 total time=   9.2s\n","[CV 2/5; 6/8] START max_iter=3500...............................................\n","[CV 2/5; 6/8] END ................max_iter=3500;, score=0.917 total time=   9.1s\n","[CV 3/5; 6/8] START max_iter=3500...............................................\n","[CV 3/5; 6/8] END ................max_iter=3500;, score=0.925 total time=   8.1s\n","[CV 4/5; 6/8] START max_iter=3500...............................................\n","[CV 4/5; 6/8] END ................max_iter=3500;, score=0.930 total time=   8.9s\n","[CV 5/5; 6/8] START max_iter=3500...............................................\n","[CV 5/5; 6/8] END ................max_iter=3500;, score=0.933 total time=   9.4s\n","[CV 1/5; 7/8] START max_iter=4000...............................................\n","[CV 1/5; 7/8] END ................max_iter=4000;, score=0.900 total time=   8.5s\n","[CV 2/5; 7/8] START max_iter=4000...............................................\n","[CV 2/5; 7/8] END ................max_iter=4000;, score=0.917 total time=   9.6s\n","[CV 3/5; 7/8] START max_iter=4000...............................................\n","[CV 3/5; 7/8] END ................max_iter=4000;, score=0.925 total time=   8.5s\n","[CV 4/5; 7/8] START max_iter=4000...............................................\n","[CV 4/5; 7/8] END ................max_iter=4000;, score=0.930 total time=   8.8s\n","[CV 5/5; 7/8] START max_iter=4000...............................................\n","[CV 5/5; 7/8] END ................max_iter=4000;, score=0.933 total time=   9.2s\n","[CV 1/5; 8/8] START max_iter=4500...............................................\n","[CV 1/5; 8/8] END ................max_iter=4500;, score=0.900 total time=   9.1s\n","[CV 2/5; 8/8] START max_iter=4500...............................................\n","[CV 2/5; 8/8] END ................max_iter=4500;, score=0.917 total time=   9.1s\n","[CV 3/5; 8/8] START max_iter=4500...............................................\n","[CV 3/5; 8/8] END ................max_iter=4500;, score=0.925 total time=   8.6s\n","[CV 4/5; 8/8] START max_iter=4500...............................................\n","[CV 4/5; 8/8] END ................max_iter=4500;, score=0.930 total time=   8.6s\n","[CV 5/5; 8/8] START max_iter=4500...............................................\n","[CV 5/5; 8/8] END ................max_iter=4500;, score=0.933 total time=   9.7s\n","Best parameters: {'max_iter': 1000}\n","Best score:  0.9209375\n","Model accuracy: 0.9313\n"]}],"source":["#same thing, trying with cv = 5.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [i for i in range(1000, 5000, 500)]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(alpha=0.0003, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300500,"status":"ok","timestamp":1713532315771,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"TIR3Y-Vxdy4V","outputId":"85228dd5-b646-4ede-cd41-53c42e1ebb65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 9 candidates, totalling 45 fits\n","[CV 1/5; 1/9] START max_iter=100................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 1/9] END .................max_iter=100;, score=0.911 total time=   1.8s\n","[CV 2/5; 1/9] START max_iter=100................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 1/9] END .................max_iter=100;, score=0.914 total time=   1.7s\n","[CV 3/5; 1/9] START max_iter=100................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 1/9] END .................max_iter=100;, score=0.930 total time=   1.4s\n","[CV 4/5; 1/9] START max_iter=100................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 1/9] END .................max_iter=100;, score=0.927 total time=   1.8s\n","[CV 5/5; 1/9] START max_iter=100................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 1/9] END .................max_iter=100;, score=0.928 total time=   1.6s\n","[CV 1/5; 2/9] START max_iter=200................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 2/9] END .................max_iter=200;, score=0.912 total time=   3.1s\n","[CV 2/5; 2/9] START max_iter=200................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 2/9] END .................max_iter=200;, score=0.922 total time=   2.8s\n","[CV 3/5; 2/9] START max_iter=200................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 2/9] END .................max_iter=200;, score=0.938 total time=   2.8s\n","[CV 4/5; 2/9] START max_iter=200................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 2/9] END .................max_iter=200;, score=0.928 total time=   3.1s\n","[CV 5/5; 2/9] START max_iter=200................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 2/9] END .................max_iter=200;, score=0.934 total time=   3.4s\n","[CV 1/5; 3/9] START max_iter=300................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 3/9] END .................max_iter=300;, score=0.916 total time=   4.3s\n","[CV 2/5; 3/9] START max_iter=300................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 3/9] END .................max_iter=300;, score=0.920 total time=   4.3s\n","[CV 3/5; 3/9] START max_iter=300................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 3/9] END .................max_iter=300;, score=0.939 total time=   5.4s\n","[CV 4/5; 3/9] START max_iter=300................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 3/9] END .................max_iter=300;, score=0.928 total time=   4.3s\n","[CV 5/5; 3/9] START max_iter=300................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 3/9] END .................max_iter=300;, score=0.941 total time=   4.2s\n","[CV 1/5; 4/9] START max_iter=400................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 4/9] END .................max_iter=400;, score=0.906 total time=   6.5s\n","[CV 2/5; 4/9] START max_iter=400................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 4/9] END .................max_iter=400;, score=0.916 total time=   5.8s\n","[CV 3/5; 4/9] START max_iter=400................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 4/9] END .................max_iter=400;, score=0.933 total time=   6.4s\n","[CV 4/5; 4/9] START max_iter=400................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 4/9] END .................max_iter=400;, score=0.925 total time=   5.7s\n","[CV 5/5; 4/9] START max_iter=400................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 4/9] END .................max_iter=400;, score=0.933 total time=   6.7s\n","[CV 1/5; 5/9] START max_iter=500................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 5/9] END .................max_iter=500;, score=0.905 total time=   7.2s\n","[CV 2/5; 5/9] START max_iter=500................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 5/9] END .................max_iter=500;, score=0.919 total time=   7.9s\n","[CV 3/5; 5/9] START max_iter=500................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 5/9] END .................max_iter=500;, score=0.928 total time=   7.0s\n","[CV 4/5; 5/9] START max_iter=500................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 5/9] END .................max_iter=500;, score=0.933 total time=   8.3s\n","[CV 5/5; 5/9] START max_iter=500................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 5/9] END .................max_iter=500;, score=0.933 total time=   7.1s\n","[CV 1/5; 6/9] START max_iter=600................................................\n","[CV 1/5; 6/9] END .................max_iter=600;, score=0.900 total time=   8.5s\n","[CV 2/5; 6/9] START max_iter=600................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 6/9] END .................max_iter=600;, score=0.917 total time=   9.0s\n","[CV 3/5; 6/9] START max_iter=600................................................\n","[CV 3/5; 6/9] END .................max_iter=600;, score=0.925 total time=   7.8s\n","[CV 4/5; 6/9] START max_iter=600................................................\n","[CV 4/5; 6/9] END .................max_iter=600;, score=0.930 total time=   9.2s\n","[CV 5/5; 6/9] START max_iter=600................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 6/9] END .................max_iter=600;, score=0.934 total time=   9.4s\n","[CV 1/5; 7/9] START max_iter=700................................................\n","[CV 1/5; 7/9] END .................max_iter=700;, score=0.900 total time=   8.3s\n","[CV 2/5; 7/9] START max_iter=700................................................\n","[CV 2/5; 7/9] END .................max_iter=700;, score=0.917 total time=   9.3s\n","[CV 3/5; 7/9] START max_iter=700................................................\n","[CV 3/5; 7/9] END .................max_iter=700;, score=0.925 total time=   9.3s\n","[CV 4/5; 7/9] START max_iter=700................................................\n","[CV 4/5; 7/9] END .................max_iter=700;, score=0.930 total time=   8.2s\n","[CV 5/5; 7/9] START max_iter=700................................................\n","[CV 5/5; 7/9] END .................max_iter=700;, score=0.933 total time=  10.0s\n","[CV 1/5; 8/9] START max_iter=800................................................\n","[CV 1/5; 8/9] END .................max_iter=800;, score=0.900 total time=  10.0s\n","[CV 2/5; 8/9] START max_iter=800................................................\n","[CV 2/5; 8/9] END .................max_iter=800;, score=0.917 total time=   9.7s\n","[CV 3/5; 8/9] START max_iter=800................................................\n","[CV 3/5; 8/9] END .................max_iter=800;, score=0.925 total time=   8.3s\n","[CV 4/5; 8/9] START max_iter=800................................................\n","[CV 4/5; 8/9] END .................max_iter=800;, score=0.930 total time=   8.9s\n","[CV 5/5; 8/9] START max_iter=800................................................\n","[CV 5/5; 8/9] END .................max_iter=800;, score=0.933 total time=   9.2s\n","[CV 1/5; 9/9] START max_iter=900................................................\n","[CV 1/5; 9/9] END .................max_iter=900;, score=0.900 total time=   8.9s\n","[CV 2/5; 9/9] START max_iter=900................................................\n","[CV 2/5; 9/9] END .................max_iter=900;, score=0.917 total time=   9.7s\n","[CV 3/5; 9/9] START max_iter=900................................................\n","[CV 3/5; 9/9] END .................max_iter=900;, score=0.925 total time=   8.1s\n","[CV 4/5; 9/9] START max_iter=900................................................\n","[CV 4/5; 9/9] END .................max_iter=900;, score=0.930 total time=   8.8s\n","[CV 5/5; 9/9] START max_iter=900................................................\n","[CV 5/5; 9/9] END .................max_iter=900;, score=0.933 total time=   9.7s\n","Best parameters: {'max_iter': 300}\n","Best score:  0.92875\n","Model accuracy: 0.9363\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["#same thing, trying with cv = 5.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [i for i in range(100, 1000, 100)]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(alpha=0.0003, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119207,"status":"ok","timestamp":1713561279034,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"pLo7fTD2BUiq","outputId":"ad1de5d3-d771-4d35-d7ff-f5c1b8af10f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 5 candidates, totalling 25 fits\n","[CV 1/5; 1/5] START alpha=0.0001................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 1/5] END .................alpha=0.0001;, score=0.914 total time=   5.6s\n","[CV 2/5; 1/5] START alpha=0.0001................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 1/5] END .................alpha=0.0001;, score=0.923 total time=   4.3s\n","[CV 3/5; 1/5] START alpha=0.0001................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 1/5] END .................alpha=0.0001;, score=0.938 total time=   4.1s\n","[CV 4/5; 1/5] START alpha=0.0001................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 1/5] END .................alpha=0.0001;, score=0.923 total time=   4.7s\n","[CV 5/5; 1/5] START alpha=0.0001................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 1/5] END .................alpha=0.0001;, score=0.941 total time=   4.2s\n","[CV 1/5; 2/5] START alpha=0.0002................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 2/5] END .................alpha=0.0002;, score=0.909 total time=   4.2s\n","[CV 2/5; 2/5] START alpha=0.0002................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 2/5] END .................alpha=0.0002;, score=0.922 total time=   4.9s\n","[CV 3/5; 2/5] START alpha=0.0002................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 2/5] END .................alpha=0.0002;, score=0.936 total time=   4.3s\n","[CV 4/5; 2/5] START alpha=0.0002................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 2/5] END .................alpha=0.0002;, score=0.927 total time=   4.2s\n","[CV 5/5; 2/5] START alpha=0.0002................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 2/5] END .................alpha=0.0002;, score=0.939 total time=   4.6s\n","[CV 1/5; 3/5] START alpha=0.0003................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 3/5] END .................alpha=0.0003;, score=0.916 total time=   4.6s\n","[CV 2/5; 3/5] START alpha=0.0003................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 3/5] END .................alpha=0.0003;, score=0.920 total time=   4.3s\n","[CV 3/5; 3/5] START alpha=0.0003................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 3/5] END .................alpha=0.0003;, score=0.939 total time=   5.0s\n","[CV 4/5; 3/5] START alpha=0.0003................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 3/5] END .................alpha=0.0003;, score=0.928 total time=   4.6s\n","[CV 5/5; 3/5] START alpha=0.0003................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 3/5] END .................alpha=0.0003;, score=0.941 total time=   4.2s\n","[CV 1/5; 4/5] START alpha=0.0004................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 4/5] END .................alpha=0.0004;, score=0.912 total time=   4.7s\n","[CV 2/5; 4/5] START alpha=0.0004................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 4/5] END .................alpha=0.0004;, score=0.920 total time=   4.6s\n","[CV 3/5; 4/5] START alpha=0.0004................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 4/5] END .................alpha=0.0004;, score=0.938 total time=   4.1s\n","[CV 4/5; 4/5] START alpha=0.0004................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 4/5] END .................alpha=0.0004;, score=0.925 total time=   4.9s\n","[CV 5/5; 4/5] START alpha=0.0004................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 4/5] END .................alpha=0.0004;, score=0.939 total time=   4.6s\n","[CV 1/5; 5/5] START alpha=0.0005................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5; 5/5] END .................alpha=0.0005;, score=0.912 total time=   4.6s\n","[CV 2/5; 5/5] START alpha=0.0005................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5; 5/5] END .................alpha=0.0005;, score=0.920 total time=   4.9s\n","[CV 3/5; 5/5] START alpha=0.0005................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5; 5/5] END .................alpha=0.0005;, score=0.941 total time=   4.2s\n","[CV 4/5; 5/5] START alpha=0.0005................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5; 5/5] END .................alpha=0.0005;, score=0.920 total time=   4.1s\n","[CV 5/5; 5/5] START alpha=0.0005................................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5; 5/5] END .................alpha=0.0005;, score=0.939 total time=   5.5s\n","Best parameters: {'alpha': 0.0003}\n","Best score:  0.92875\n","Model accuracy: 0.9363\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["#same thing, trying with cv = 5.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","poly = PolynomialFeatures(degree=2)\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_train_scaled = poly.fit_transform(X_train_scaled)\n","X_test_scaled = scaler.transform(X_test)\n","X_test_scaled = poly.transform(X_test_scaled)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(max_iter=300, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9C3MRpoCto4","outputId":"c525b816-91ae-4b55-821c-050eb7f1659e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 2 folds for each of 100 candidates, totalling 200 fits\n","[CV 1/2; 1/100] START random_state=0............................................\n","[CV 1/2; 1/100] END .............random_state=0;, score=0.914 total time=  11.9s\n","[CV 2/2; 1/100] START random_state=0............................................\n","[CV 2/2; 1/100] END .............random_state=0;, score=0.939 total time=  12.9s\n","[CV 1/2; 2/100] START random_state=1............................................\n","[CV 1/2; 2/100] END .............random_state=1;, score=0.915 total time=  12.2s\n","[CV 2/2; 2/100] START random_state=1............................................\n","[CV 2/2; 2/100] END .............random_state=1;, score=0.924 total time=  14.8s\n","[CV 1/2; 3/100] START random_state=2............................................\n","[CV 1/2; 3/100] END .............random_state=2;, score=0.922 total time=  13.0s\n","[CV 2/2; 3/100] START random_state=2............................................\n","[CV 2/2; 3/100] END .............random_state=2;, score=0.928 total time=  12.3s\n","[CV 1/2; 4/100] START random_state=3............................................\n","[CV 1/2; 4/100] END .............random_state=3;, score=0.912 total time=  12.3s\n","[CV 2/2; 4/100] START random_state=3............................................\n","[CV 2/2; 4/100] END .............random_state=3;, score=0.934 total time=  15.2s\n","[CV 1/2; 5/100] START random_state=4............................................\n","[CV 1/2; 5/100] END .............random_state=4;, score=0.917 total time=  11.1s\n","[CV 2/2; 5/100] START random_state=4............................................\n","[CV 2/2; 5/100] END .............random_state=4;, score=0.914 total time=  13.4s\n","[CV 1/2; 6/100] START random_state=5............................................\n","[CV 1/2; 6/100] END .............random_state=5;, score=0.912 total time=  13.5s\n","[CV 2/2; 6/100] START random_state=5............................................\n","[CV 2/2; 6/100] END .............random_state=5;, score=0.923 total time=  14.5s\n","[CV 1/2; 7/100] START random_state=6............................................\n","[CV 1/2; 7/100] END .............random_state=6;, score=0.911 total time=  12.0s\n","[CV 2/2; 7/100] START random_state=6............................................\n","[CV 2/2; 7/100] END .............random_state=6;, score=0.943 total time=  15.2s\n","[CV 1/2; 8/100] START random_state=7............................................\n","[CV 1/2; 8/100] END .............random_state=7;, score=0.917 total time=  13.2s\n","[CV 2/2; 8/100] START random_state=7............................................\n","[CV 2/2; 8/100] END .............random_state=7;, score=0.920 total time=  13.5s\n","[CV 1/2; 9/100] START random_state=8............................................\n","[CV 1/2; 9/100] END .............random_state=8;, score=0.919 total time=  11.9s\n","[CV 2/2; 9/100] START random_state=8............................................\n","[CV 2/2; 9/100] END .............random_state=8;, score=0.915 total time=  15.0s\n","[CV 1/2; 10/100] START random_state=9...........................................\n","[CV 1/2; 10/100] END ............random_state=9;, score=0.917 total time=  11.4s\n","[CV 2/2; 10/100] START random_state=9...........................................\n","[CV 2/2; 10/100] END ............random_state=9;, score=0.931 total time=  14.8s\n","[CV 1/2; 11/100] START random_state=10..........................................\n","[CV 1/2; 11/100] END ...........random_state=10;, score=0.909 total time=  12.7s\n","[CV 2/2; 11/100] START random_state=10..........................................\n","[CV 2/2; 11/100] END ...........random_state=10;, score=0.937 total time=  15.0s\n","[CV 1/2; 12/100] START random_state=11..........................................\n","[CV 1/2; 12/100] END ...........random_state=11;, score=0.919 total time=  12.3s\n","[CV 2/2; 12/100] START random_state=11..........................................\n","[CV 2/2; 12/100] END ...........random_state=11;, score=0.941 total time=  12.5s\n","[CV 1/2; 13/100] START random_state=12..........................................\n","[CV 1/2; 13/100] END ...........random_state=12;, score=0.912 total time=  11.0s\n","[CV 2/2; 13/100] START random_state=12..........................................\n","[CV 2/2; 13/100] END ...........random_state=12;, score=0.922 total time=  13.6s\n","[CV 1/2; 14/100] START random_state=13..........................................\n","[CV 1/2; 14/100] END ...........random_state=13;, score=0.924 total time=   8.8s\n","[CV 2/2; 14/100] START random_state=13..........................................\n","[CV 2/2; 14/100] END ...........random_state=13;, score=0.923 total time=  11.6s\n","[CV 1/2; 15/100] START random_state=14..........................................\n","[CV 1/2; 15/100] END ...........random_state=14;, score=0.918 total time=  12.9s\n","[CV 2/2; 15/100] START random_state=14..........................................\n","[CV 2/2; 15/100] END ...........random_state=14;, score=0.937 total time=  14.3s\n","[CV 1/2; 16/100] START random_state=15..........................................\n","[CV 1/2; 16/100] END ...........random_state=15;, score=0.922 total time=  12.0s\n","[CV 2/2; 16/100] START random_state=15..........................................\n","[CV 2/2; 16/100] END ...........random_state=15;, score=0.944 total time=  13.7s\n","[CV 1/2; 17/100] START random_state=16..........................................\n","[CV 1/2; 17/100] END ...........random_state=16;, score=0.916 total time=  12.7s\n","[CV 2/2; 17/100] START random_state=16..........................................\n","[CV 2/2; 17/100] END ...........random_state=16;, score=0.928 total time=  12.5s\n","[CV 1/2; 18/100] START random_state=17..........................................\n","[CV 1/2; 18/100] END ...........random_state=17;, score=0.916 total time=  10.4s\n","[CV 2/2; 18/100] START random_state=17..........................................\n","[CV 2/2; 18/100] END ...........random_state=17;, score=0.924 total time=  14.9s\n","[CV 1/2; 19/100] START random_state=18..........................................\n","[CV 1/2; 19/100] END ...........random_state=18;, score=0.918 total time=  12.8s\n","[CV 2/2; 19/100] START random_state=18..........................................\n","[CV 2/2; 19/100] END ...........random_state=18;, score=0.934 total time=  15.9s\n","[CV 1/2; 20/100] START random_state=19..........................................\n","[CV 1/2; 20/100] END ...........random_state=19;, score=0.917 total time=  10.0s\n","[CV 2/2; 20/100] START random_state=19..........................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2; 20/100] END ...........random_state=19;, score=0.922 total time=   7.9s\n","[CV 1/2; 21/100] START random_state=20..........................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2; 21/100] END ...........random_state=20;, score=0.876 total time=   2.2s\n","[CV 2/2; 21/100] START random_state=20..........................................\n","[CV 2/2; 21/100] END ...........random_state=20;, score=0.839 total time=   0.2s\n","[CV 1/2; 22/100] START random_state=21..........................................\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2; 22/100] END ...........random_state=21;, score=0.882 total time=   1.6s\n","[CV 2/2; 22/100] START random_state=21..........................................\n"]}],"source":["#turns out there's not much of a point to this.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'random_state': [i for i in range(100)]\n","}\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(max_iter=2000, alpha=0.0002, hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=2, verbose=10)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdWeLaZKJ4c1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633704,"status":"ok","timestamp":1713647008777,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"NdlWXVLWJ4-E","outputId":"5896feaa-b8f0-45b8-d591-c111cf0a5e93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 12 candidates, totalling 60 fits\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.928 total time=  17.3s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.939 total time=  14.8s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.941 total time=  11.7s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.944 total time=  13.1s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.947 total time=  16.6s\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.927 total time=   8.5s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.927 total time=   8.2s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.941 total time=   6.1s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.939 total time=   7.2s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.933 total time=   8.7s\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.925 total time=   7.1s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.927 total time=   6.2s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.933 total time=   4.8s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.947 total time=   6.4s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.930 total time=   5.1s\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.925 total time=  15.1s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.938 total time=  14.3s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.941 total time=  15.9s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.944 total time=  12.9s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.944 total time=  17.1s\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.925 total time=   7.8s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.928 total time=   8.0s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.941 total time=   6.0s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.942 total time=  10.5s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.931 total time=   7.5s\n","[CV 1/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.917 total time=   7.2s\n","[CV 2/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.930 total time=   6.1s\n","[CV 3/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.934 total time=   5.1s\n","[CV 4/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.942 total time=   5.6s\n","[CV 5/5] END alpha=0.0002, beta_1=0.9, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.936 total time=   7.2s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.927 total time=  17.2s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.928 total time=  20.0s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.944 total time=  13.2s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.945 total time=  16.3s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.001, max_iter=2000;, score=0.934 total time=  14.6s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.916 total time=   9.4s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.933 total time=  12.5s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.945 total time=   8.4s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.948 total time=  10.0s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.002, max_iter=2000;, score=0.947 total time=   9.7s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.920 total time=   6.6s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.931 total time=   5.2s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.941 total time=   5.5s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.947 total time=   6.2s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.999, learning_rate_init=0.003, max_iter=2000;, score=0.934 total time=   5.2s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.923 total time=  16.8s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.934 total time=  14.6s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.938 total time=  20.0s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.956 total time=  15.3s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.001, max_iter=2000;, score=0.936 total time=  14.0s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.925 total time=  11.4s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.930 total time=  12.2s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.931 total time=   9.1s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.944 total time=   9.9s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.002, max_iter=2000;, score=0.944 total time=  10.0s\n","[CV 1/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.923 total time=   5.4s\n","[CV 2/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.934 total time=   7.7s\n","[CV 3/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.942 total time=   6.2s\n","[CV 4/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.952 total time=   4.9s\n","[CV 5/5] END alpha=0.0002, beta_1=0.95, beta_2=0.9995, learning_rate_init=0.003, max_iter=2000;, score=0.928 total time=   7.4s\n","Best parameters: {'alpha': 0.0002, 'beta_1': 0.9, 'beta_2': 0.999, 'learning_rate_init': 0.001, 'max_iter': 2000}\n","Best score:  0.9396875\n","Model accuracy: 0.9587\n"]}],"source":["#turns out there's not much of a point to this.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [2000],\n","    'alpha': [0.0002],\n","    'learning_rate_init': [0.001, 0.002, 0.003],\n","    'beta_1': [0.9, 0.95],  # Slightly narrow range around a typical value\n","    'beta_2': [0.999, 0.9995]  # Reduced levels for beta_2\n","}\n","\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=3)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4962014,"status":"ok","timestamp":1713786630907,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"Kv2KrOp7DPCm","outputId":"a9158a94-eb87-4eea-80e1-9f531ebe300f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0001, max_iter=500;, score=0.919 total time=  16.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0001, max_iter=500;, score=0.923 total time=   8.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0001, max_iter=500;, score=0.930 total time=   7.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0001, max_iter=500;, score=0.936 total time=   7.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0001, max_iter=500;, score=0.936 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0001, max_iter=1000;, score=0.925 total time=  14.3s\n","[CV 2/5] END .......alpha=0.0001, max_iter=1000;, score=0.928 total time=   9.8s\n","[CV 3/5] END .......alpha=0.0001, max_iter=1000;, score=0.944 total time=  12.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .......alpha=0.0001, max_iter=1000;, score=0.942 total time=  14.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0001, max_iter=1000;, score=0.941 total time=  15.0s\n","[CV 1/5] END .......alpha=0.0001, max_iter=1500;, score=0.925 total time=  15.7s\n","[CV 2/5] END .......alpha=0.0001, max_iter=1500;, score=0.928 total time=  10.2s\n","[CV 3/5] END .......alpha=0.0001, max_iter=1500;, score=0.944 total time=  13.1s\n","[CV 4/5] END .......alpha=0.0001, max_iter=1500;, score=0.950 total time=  15.1s\n","[CV 5/5] END .......alpha=0.0001, max_iter=1500;, score=0.941 total time=  18.2s\n","[CV 1/5] END .......alpha=0.0001, max_iter=2000;, score=0.925 total time=  15.2s\n","[CV 2/5] END .......alpha=0.0001, max_iter=2000;, score=0.928 total time=  10.0s\n","[CV 3/5] END .......alpha=0.0001, max_iter=2000;, score=0.944 total time=  13.5s\n","[CV 4/5] END .......alpha=0.0001, max_iter=2000;, score=0.950 total time=  14.7s\n","[CV 5/5] END .......alpha=0.0001, max_iter=2000;, score=0.941 total time=  18.4s\n","[CV 1/5] END .......alpha=0.0001, max_iter=2500;, score=0.925 total time=  15.3s\n","[CV 2/5] END .......alpha=0.0001, max_iter=2500;, score=0.928 total time=  10.4s\n","[CV 3/5] END .......alpha=0.0001, max_iter=2500;, score=0.944 total time=  13.2s\n","[CV 4/5] END .......alpha=0.0001, max_iter=2500;, score=0.950 total time=  14.6s\n","[CV 5/5] END .......alpha=0.0001, max_iter=2500;, score=0.941 total time=  18.0s\n","[CV 1/5] END .......alpha=0.0001, max_iter=3000;, score=0.925 total time=  15.0s\n","[CV 2/5] END .......alpha=0.0001, max_iter=3000;, score=0.928 total time=  10.4s\n","[CV 3/5] END .......alpha=0.0001, max_iter=3000;, score=0.944 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0001, max_iter=3000;, score=0.950 total time=  14.4s\n","[CV 5/5] END .......alpha=0.0001, max_iter=3000;, score=0.941 total time=  18.1s\n","[CV 1/5] END .......alpha=0.0001, max_iter=3500;, score=0.925 total time=  15.6s\n","[CV 2/5] END .......alpha=0.0001, max_iter=3500;, score=0.928 total time=   9.9s\n","[CV 3/5] END .......alpha=0.0001, max_iter=3500;, score=0.944 total time=  12.8s\n","[CV 4/5] END .......alpha=0.0001, max_iter=3500;, score=0.950 total time=  14.8s\n","[CV 5/5] END .......alpha=0.0001, max_iter=3500;, score=0.941 total time=  18.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0002, max_iter=500;, score=0.917 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0002, max_iter=500;, score=0.919 total time=   7.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0002, max_iter=500;, score=0.930 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0002, max_iter=500;, score=0.934 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0002, max_iter=500;, score=0.934 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0002, max_iter=1000;, score=0.927 total time=  14.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0002, max_iter=1000;, score=0.934 total time=  13.8s\n","[CV 3/5] END .......alpha=0.0002, max_iter=1000;, score=0.941 total time=  13.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .......alpha=0.0002, max_iter=1000;, score=0.945 total time=  14.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0002, max_iter=1000;, score=0.938 total time=  14.1s\n","[CV 1/5] END .......alpha=0.0002, max_iter=1500;, score=0.928 total time=  16.8s\n","[CV 2/5] END .......alpha=0.0002, max_iter=1500;, score=0.939 total time=  15.9s\n","[CV 3/5] END .......alpha=0.0002, max_iter=1500;, score=0.941 total time=  13.5s\n","[CV 4/5] END .......alpha=0.0002, max_iter=1500;, score=0.944 total time=  14.8s\n","[CV 5/5] END .......alpha=0.0002, max_iter=1500;, score=0.947 total time=  18.4s\n","[CV 1/5] END .......alpha=0.0002, max_iter=2000;, score=0.928 total time=  17.5s\n","[CV 2/5] END .......alpha=0.0002, max_iter=2000;, score=0.939 total time=  15.2s\n","[CV 3/5] END .......alpha=0.0002, max_iter=2000;, score=0.941 total time=  13.0s\n","[CV 4/5] END .......alpha=0.0002, max_iter=2000;, score=0.944 total time=  14.7s\n","[CV 5/5] END .......alpha=0.0002, max_iter=2000;, score=0.947 total time=  17.5s\n","[CV 1/5] END .......alpha=0.0002, max_iter=2500;, score=0.928 total time=  15.8s\n","[CV 2/5] END .......alpha=0.0002, max_iter=2500;, score=0.939 total time=  16.2s\n","[CV 3/5] END .......alpha=0.0002, max_iter=2500;, score=0.941 total time=  13.1s\n","[CV 4/5] END .......alpha=0.0002, max_iter=2500;, score=0.944 total time=  15.1s\n","[CV 5/5] END .......alpha=0.0002, max_iter=2500;, score=0.947 total time=  17.6s\n","[CV 1/5] END .......alpha=0.0002, max_iter=3000;, score=0.928 total time=  16.2s\n","[CV 2/5] END .......alpha=0.0002, max_iter=3000;, score=0.939 total time=  15.7s\n","[CV 3/5] END .......alpha=0.0002, max_iter=3000;, score=0.941 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0002, max_iter=3000;, score=0.944 total time=  15.1s\n","[CV 5/5] END .......alpha=0.0002, max_iter=3000;, score=0.947 total time=  18.0s\n","[CV 1/5] END .......alpha=0.0002, max_iter=3500;, score=0.928 total time=  16.0s\n","[CV 2/5] END .......alpha=0.0002, max_iter=3500;, score=0.939 total time=  17.4s\n","[CV 3/5] END .......alpha=0.0002, max_iter=3500;, score=0.941 total time=  13.0s\n","[CV 4/5] END .......alpha=0.0002, max_iter=3500;, score=0.944 total time=  14.4s\n","[CV 5/5] END .......alpha=0.0002, max_iter=3500;, score=0.947 total time=  19.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0003, max_iter=500;, score=0.917 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0003, max_iter=500;, score=0.922 total time=   7.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0003, max_iter=500;, score=0.930 total time=   6.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0003, max_iter=500;, score=0.934 total time=   7.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0003, max_iter=500;, score=0.933 total time=   6.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0003, max_iter=1000;, score=0.923 total time=  14.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0003, max_iter=1000;, score=0.933 total time=  14.1s\n","[CV 3/5] END .......alpha=0.0003, max_iter=1000;, score=0.941 total time=  14.6s\n","[CV 4/5] END .......alpha=0.0003, max_iter=1000;, score=0.944 total time=  13.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0003, max_iter=1000;, score=0.942 total time=  14.6s\n","[CV 1/5] END .......alpha=0.0003, max_iter=1500;, score=0.925 total time=  15.6s\n","[CV 2/5] END .......alpha=0.0003, max_iter=1500;, score=0.938 total time=  16.6s\n","[CV 3/5] END .......alpha=0.0003, max_iter=1500;, score=0.941 total time=  15.0s\n","[CV 4/5] END .......alpha=0.0003, max_iter=1500;, score=0.944 total time=  12.6s\n","[CV 5/5] END .......alpha=0.0003, max_iter=1500;, score=0.944 total time=  19.9s\n","[CV 1/5] END .......alpha=0.0003, max_iter=2000;, score=0.925 total time=  16.2s\n","[CV 2/5] END .......alpha=0.0003, max_iter=2000;, score=0.938 total time=  16.7s\n","[CV 3/5] END .......alpha=0.0003, max_iter=2000;, score=0.941 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0003, max_iter=2000;, score=0.944 total time=  13.0s\n","[CV 5/5] END .......alpha=0.0003, max_iter=2000;, score=0.944 total time=  20.4s\n","[CV 1/5] END .......alpha=0.0003, max_iter=2500;, score=0.925 total time=  16.3s\n","[CV 2/5] END .......alpha=0.0003, max_iter=2500;, score=0.938 total time=  17.4s\n","[CV 3/5] END .......alpha=0.0003, max_iter=2500;, score=0.941 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0003, max_iter=2500;, score=0.944 total time=  13.2s\n","[CV 5/5] END .......alpha=0.0003, max_iter=2500;, score=0.944 total time=  19.5s\n","[CV 1/5] END .......alpha=0.0003, max_iter=3000;, score=0.925 total time=  15.7s\n","[CV 2/5] END .......alpha=0.0003, max_iter=3000;, score=0.938 total time=  16.8s\n","[CV 3/5] END .......alpha=0.0003, max_iter=3000;, score=0.941 total time=  13.4s\n","[CV 4/5] END .......alpha=0.0003, max_iter=3000;, score=0.944 total time=  13.7s\n","[CV 5/5] END .......alpha=0.0003, max_iter=3000;, score=0.944 total time=  20.0s\n","[CV 1/5] END .......alpha=0.0003, max_iter=3500;, score=0.925 total time=  16.4s\n","[CV 2/5] END .......alpha=0.0003, max_iter=3500;, score=0.938 total time=  18.6s\n","[CV 3/5] END .......alpha=0.0003, max_iter=3500;, score=0.941 total time=  14.0s\n","[CV 4/5] END .......alpha=0.0003, max_iter=3500;, score=0.944 total time=  13.2s\n","[CV 5/5] END .......alpha=0.0003, max_iter=3500;, score=0.944 total time=  19.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0004, max_iter=500;, score=0.917 total time=   7.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0004, max_iter=500;, score=0.917 total time=   6.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0004, max_iter=500;, score=0.928 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0004, max_iter=500;, score=0.938 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0004, max_iter=500;, score=0.931 total time=   7.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0004, max_iter=1000;, score=0.927 total time=  14.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0004, max_iter=1000;, score=0.938 total time=  14.3s\n","[CV 3/5] END .......alpha=0.0004, max_iter=1000;, score=0.942 total time=  14.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .......alpha=0.0004, max_iter=1000;, score=0.945 total time=  14.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0004, max_iter=1000;, score=0.941 total time=  14.5s\n","[CV 1/5] END .......alpha=0.0004, max_iter=1500;, score=0.925 total time=  17.0s\n","[CV 2/5] END .......alpha=0.0004, max_iter=1500;, score=0.939 total time=  16.8s\n","[CV 3/5] END .......alpha=0.0004, max_iter=1500;, score=0.942 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0004, max_iter=1500;, score=0.950 total time=  14.3s\n","[CV 5/5] END .......alpha=0.0004, max_iter=1500;, score=0.942 total time=  17.0s\n","[CV 1/5] END .......alpha=0.0004, max_iter=2000;, score=0.925 total time=  16.4s\n","[CV 2/5] END .......alpha=0.0004, max_iter=2000;, score=0.939 total time=  15.5s\n","[CV 3/5] END .......alpha=0.0004, max_iter=2000;, score=0.942 total time=  13.0s\n","[CV 4/5] END .......alpha=0.0004, max_iter=2000;, score=0.950 total time=  15.2s\n","[CV 5/5] END .......alpha=0.0004, max_iter=2000;, score=0.942 total time=  16.7s\n","[CV 1/5] END .......alpha=0.0004, max_iter=2500;, score=0.925 total time=  16.1s\n","[CV 2/5] END .......alpha=0.0004, max_iter=2500;, score=0.939 total time=  16.0s\n","[CV 3/5] END .......alpha=0.0004, max_iter=2500;, score=0.942 total time=  13.9s\n","[CV 4/5] END .......alpha=0.0004, max_iter=2500;, score=0.950 total time=  15.0s\n","[CV 5/5] END .......alpha=0.0004, max_iter=2500;, score=0.942 total time=  17.2s\n","[CV 1/5] END .......alpha=0.0004, max_iter=3000;, score=0.925 total time=  16.9s\n","[CV 2/5] END .......alpha=0.0004, max_iter=3000;, score=0.939 total time=  15.8s\n","[CV 3/5] END .......alpha=0.0004, max_iter=3000;, score=0.942 total time=  13.6s\n","[CV 4/5] END .......alpha=0.0004, max_iter=3000;, score=0.950 total time=  14.7s\n","[CV 5/5] END .......alpha=0.0004, max_iter=3000;, score=0.942 total time=  16.1s\n","[CV 1/5] END .......alpha=0.0004, max_iter=3500;, score=0.925 total time=  16.7s\n","[CV 2/5] END .......alpha=0.0004, max_iter=3500;, score=0.939 total time=  16.7s\n","[CV 3/5] END .......alpha=0.0004, max_iter=3500;, score=0.942 total time=  16.8s\n","[CV 4/5] END .......alpha=0.0004, max_iter=3500;, score=0.950 total time=  15.0s\n","[CV 5/5] END .......alpha=0.0004, max_iter=3500;, score=0.942 total time=  16.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0005, max_iter=500;, score=0.917 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0005, max_iter=500;, score=0.922 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0005, max_iter=500;, score=0.923 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0005, max_iter=500;, score=0.938 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0005, max_iter=500;, score=0.934 total time=   7.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0005, max_iter=1000;, score=0.920 total time=  14.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0005, max_iter=1000;, score=0.936 total time=  14.6s\n","[CV 3/5] END .......alpha=0.0005, max_iter=1000;, score=0.938 total time=  13.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .......alpha=0.0005, max_iter=1000;, score=0.947 total time=  14.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0005, max_iter=1000;, score=0.941 total time=  14.7s\n","[CV 1/5] END .......alpha=0.0005, max_iter=1500;, score=0.919 total time=  16.4s\n","[CV 2/5] END .......alpha=0.0005, max_iter=1500;, score=0.933 total time=  16.9s\n","[CV 3/5] END .......alpha=0.0005, max_iter=1500;, score=0.938 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0005, max_iter=1500;, score=0.950 total time=  16.7s\n","[CV 5/5] END .......alpha=0.0005, max_iter=1500;, score=0.941 total time=  18.3s\n","[CV 1/5] END .......alpha=0.0005, max_iter=2000;, score=0.919 total time=  16.7s\n","[CV 2/5] END .......alpha=0.0005, max_iter=2000;, score=0.933 total time=  17.0s\n","[CV 3/5] END .......alpha=0.0005, max_iter=2000;, score=0.938 total time=  13.6s\n","[CV 4/5] END .......alpha=0.0005, max_iter=2000;, score=0.950 total time=  16.1s\n","[CV 5/5] END .......alpha=0.0005, max_iter=2000;, score=0.941 total time=  17.5s\n","[CV 1/5] END .......alpha=0.0005, max_iter=2500;, score=0.919 total time=  16.7s\n","[CV 2/5] END .......alpha=0.0005, max_iter=2500;, score=0.933 total time=  16.4s\n","[CV 3/5] END .......alpha=0.0005, max_iter=2500;, score=0.938 total time=  13.1s\n","[CV 4/5] END .......alpha=0.0005, max_iter=2500;, score=0.950 total time=  16.0s\n","[CV 5/5] END .......alpha=0.0005, max_iter=2500;, score=0.941 total time=  22.6s\n","[CV 1/5] END .......alpha=0.0005, max_iter=3000;, score=0.919 total time=  16.1s\n","[CV 2/5] END .......alpha=0.0005, max_iter=3000;, score=0.933 total time=  16.4s\n","[CV 3/5] END .......alpha=0.0005, max_iter=3000;, score=0.938 total time=  13.8s\n","[CV 4/5] END .......alpha=0.0005, max_iter=3000;, score=0.950 total time=  24.5s\n","[CV 5/5] END .......alpha=0.0005, max_iter=3000;, score=0.941 total time=  23.0s\n","[CV 1/5] END .......alpha=0.0005, max_iter=3500;, score=0.919 total time=  17.6s\n","[CV 2/5] END .......alpha=0.0005, max_iter=3500;, score=0.933 total time=  16.7s\n","[CV 3/5] END .......alpha=0.0005, max_iter=3500;, score=0.938 total time=  13.6s\n","[CV 4/5] END .......alpha=0.0005, max_iter=3500;, score=0.950 total time=  16.8s\n","[CV 5/5] END .......alpha=0.0005, max_iter=3500;, score=0.941 total time=  19.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .........alpha=0.006, max_iter=500;, score=0.919 total time=   7.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .........alpha=0.006, max_iter=500;, score=0.920 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END .........alpha=0.006, max_iter=500;, score=0.928 total time=   6.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .........alpha=0.006, max_iter=500;, score=0.938 total time=   7.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .........alpha=0.006, max_iter=500;, score=0.933 total time=   7.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.006, max_iter=1000;, score=0.928 total time=  14.5s\n","[CV 2/5] END ........alpha=0.006, max_iter=1000;, score=0.925 total time=  13.4s\n","[CV 3/5] END ........alpha=0.006, max_iter=1000;, score=0.941 total time=  13.9s\n","[CV 4/5] END ........alpha=0.006, max_iter=1000;, score=0.947 total time=  14.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.006, max_iter=1000;, score=0.939 total time=  15.2s\n","[CV 1/5] END ........alpha=0.006, max_iter=1500;, score=0.928 total time=  16.8s\n","[CV 2/5] END ........alpha=0.006, max_iter=1500;, score=0.925 total time=  12.4s\n","[CV 3/5] END ........alpha=0.006, max_iter=1500;, score=0.941 total time=  13.6s\n","[CV 4/5] END ........alpha=0.006, max_iter=1500;, score=0.947 total time=  14.0s\n","[CV 5/5] END ........alpha=0.006, max_iter=1500;, score=0.944 total time=  16.2s\n","[CV 1/5] END ........alpha=0.006, max_iter=2000;, score=0.928 total time=  16.5s\n","[CV 2/5] END ........alpha=0.006, max_iter=2000;, score=0.925 total time=  12.6s\n","[CV 3/5] END ........alpha=0.006, max_iter=2000;, score=0.941 total time=  13.5s\n","[CV 4/5] END ........alpha=0.006, max_iter=2000;, score=0.947 total time=  13.4s\n","[CV 5/5] END ........alpha=0.006, max_iter=2000;, score=0.944 total time=  16.5s\n","[CV 1/5] END ........alpha=0.006, max_iter=2500;, score=0.928 total time=  16.5s\n","[CV 2/5] END ........alpha=0.006, max_iter=2500;, score=0.925 total time=  11.6s\n","[CV 3/5] END ........alpha=0.006, max_iter=2500;, score=0.941 total time=  13.2s\n","[CV 4/5] END ........alpha=0.006, max_iter=2500;, score=0.947 total time=  13.7s\n","[CV 5/5] END ........alpha=0.006, max_iter=2500;, score=0.944 total time=  17.0s\n","[CV 1/5] END ........alpha=0.006, max_iter=3000;, score=0.928 total time=  16.1s\n","[CV 2/5] END ........alpha=0.006, max_iter=3000;, score=0.925 total time=  12.2s\n","[CV 3/5] END ........alpha=0.006, max_iter=3000;, score=0.941 total time=  13.5s\n","[CV 4/5] END ........alpha=0.006, max_iter=3000;, score=0.947 total time=  13.8s\n","[CV 5/5] END ........alpha=0.006, max_iter=3000;, score=0.944 total time=  16.4s\n","[CV 1/5] END ........alpha=0.006, max_iter=3500;, score=0.928 total time=  16.2s\n","[CV 2/5] END ........alpha=0.006, max_iter=3500;, score=0.925 total time=  12.2s\n","[CV 3/5] END ........alpha=0.006, max_iter=3500;, score=0.941 total time=  13.5s\n","[CV 4/5] END ........alpha=0.006, max_iter=3500;, score=0.947 total time=  13.3s\n","[CV 5/5] END ........alpha=0.006, max_iter=3500;, score=0.944 total time=  16.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0007, max_iter=500;, score=0.919 total time=   7.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0007, max_iter=500;, score=0.923 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0007, max_iter=500;, score=0.931 total time=   7.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0007, max_iter=500;, score=0.933 total time=   7.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0007, max_iter=500;, score=0.930 total time=   7.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0007, max_iter=1000;, score=0.925 total time=  14.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0007, max_iter=1000;, score=0.939 total time=  14.2s\n","[CV 3/5] END .......alpha=0.0007, max_iter=1000;, score=0.941 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0007, max_iter=1000;, score=0.948 total time=  13.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0007, max_iter=1000;, score=0.939 total time=  14.2s\n","[CV 1/5] END .......alpha=0.0007, max_iter=1500;, score=0.927 total time=  15.7s\n","[CV 2/5] END .......alpha=0.0007, max_iter=1500;, score=0.938 total time=  19.1s\n","[CV 3/5] END .......alpha=0.0007, max_iter=1500;, score=0.941 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0007, max_iter=1500;, score=0.948 total time=  13.3s\n","[CV 5/5] END .......alpha=0.0007, max_iter=1500;, score=0.947 total time=  18.1s\n","[CV 1/5] END .......alpha=0.0007, max_iter=2000;, score=0.927 total time=  15.7s\n","[CV 2/5] END .......alpha=0.0007, max_iter=2000;, score=0.938 total time=  19.2s\n","[CV 3/5] END .......alpha=0.0007, max_iter=2000;, score=0.941 total time=  13.0s\n","[CV 4/5] END .......alpha=0.0007, max_iter=2000;, score=0.948 total time=  14.0s\n","[CV 5/5] END .......alpha=0.0007, max_iter=2000;, score=0.947 total time=  17.9s\n","[CV 1/5] END .......alpha=0.0007, max_iter=2500;, score=0.927 total time=  16.5s\n","[CV 2/5] END .......alpha=0.0007, max_iter=2500;, score=0.938 total time=  18.8s\n","[CV 3/5] END .......alpha=0.0007, max_iter=2500;, score=0.941 total time=  13.1s\n","[CV 4/5] END .......alpha=0.0007, max_iter=2500;, score=0.948 total time=  13.4s\n","[CV 5/5] END .......alpha=0.0007, max_iter=2500;, score=0.947 total time=  18.3s\n","[CV 1/5] END .......alpha=0.0007, max_iter=3000;, score=0.927 total time=  15.2s\n","[CV 2/5] END .......alpha=0.0007, max_iter=3000;, score=0.938 total time=  18.8s\n","[CV 3/5] END .......alpha=0.0007, max_iter=3000;, score=0.941 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0007, max_iter=3000;, score=0.948 total time=  12.9s\n","[CV 5/5] END .......alpha=0.0007, max_iter=3000;, score=0.947 total time=  19.0s\n","[CV 1/5] END .......alpha=0.0007, max_iter=3500;, score=0.927 total time=  15.8s\n","[CV 2/5] END .......alpha=0.0007, max_iter=3500;, score=0.938 total time=  18.4s\n","[CV 3/5] END .......alpha=0.0007, max_iter=3500;, score=0.941 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0007, max_iter=3500;, score=0.948 total time=  13.7s\n","[CV 5/5] END .......alpha=0.0007, max_iter=3500;, score=0.947 total time=  18.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0008, max_iter=500;, score=0.917 total time=   6.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0008, max_iter=500;, score=0.923 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0008, max_iter=500;, score=0.931 total time=   6.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0008, max_iter=500;, score=0.934 total time=   7.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0008, max_iter=500;, score=0.933 total time=   6.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0008, max_iter=1000;, score=0.927 total time=  14.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0008, max_iter=1000;, score=0.936 total time=  15.3s\n","[CV 3/5] END .......alpha=0.0008, max_iter=1000;, score=0.942 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0008, max_iter=1000;, score=0.944 total time=  13.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0008, max_iter=1000;, score=0.939 total time=  15.3s\n","[CV 1/5] END .......alpha=0.0008, max_iter=1500;, score=0.925 total time=  16.1s\n","[CV 2/5] END .......alpha=0.0008, max_iter=1500;, score=0.941 total time=  15.9s\n","[CV 3/5] END .......alpha=0.0008, max_iter=1500;, score=0.942 total time=  13.7s\n","[CV 4/5] END .......alpha=0.0008, max_iter=1500;, score=0.944 total time=  13.4s\n","[CV 5/5] END .......alpha=0.0008, max_iter=1500;, score=0.942 total time=  16.5s\n","[CV 1/5] END .......alpha=0.0008, max_iter=2000;, score=0.925 total time=  17.0s\n","[CV 2/5] END .......alpha=0.0008, max_iter=2000;, score=0.941 total time=  16.7s\n","[CV 3/5] END .......alpha=0.0008, max_iter=2000;, score=0.942 total time=  13.5s\n","[CV 4/5] END .......alpha=0.0008, max_iter=2000;, score=0.944 total time=  13.8s\n","[CV 5/5] END .......alpha=0.0008, max_iter=2000;, score=0.942 total time=  15.9s\n","[CV 1/5] END .......alpha=0.0008, max_iter=2500;, score=0.925 total time=  16.1s\n","[CV 2/5] END .......alpha=0.0008, max_iter=2500;, score=0.941 total time=  15.6s\n","[CV 3/5] END .......alpha=0.0008, max_iter=2500;, score=0.942 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0008, max_iter=2500;, score=0.944 total time=  12.7s\n","[CV 5/5] END .......alpha=0.0008, max_iter=2500;, score=0.942 total time=  15.8s\n","[CV 1/5] END .......alpha=0.0008, max_iter=3000;, score=0.925 total time=  17.3s\n","[CV 2/5] END .......alpha=0.0008, max_iter=3000;, score=0.941 total time=  15.8s\n","[CV 3/5] END .......alpha=0.0008, max_iter=3000;, score=0.942 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0008, max_iter=3000;, score=0.944 total time=  12.9s\n","[CV 5/5] END .......alpha=0.0008, max_iter=3000;, score=0.942 total time=  15.9s\n","[CV 1/5] END .......alpha=0.0008, max_iter=3500;, score=0.925 total time=  15.5s\n","[CV 2/5] END .......alpha=0.0008, max_iter=3500;, score=0.941 total time=  15.9s\n","[CV 3/5] END .......alpha=0.0008, max_iter=3500;, score=0.942 total time=  13.4s\n","[CV 4/5] END .......alpha=0.0008, max_iter=3500;, score=0.944 total time=  13.2s\n","[CV 5/5] END .......alpha=0.0008, max_iter=3500;, score=0.942 total time=  16.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.0009, max_iter=500;, score=0.916 total time=   7.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.0009, max_iter=500;, score=0.927 total time=   7.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END ........alpha=0.0009, max_iter=500;, score=0.927 total time=   6.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END ........alpha=0.0009, max_iter=500;, score=0.933 total time=   7.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.0009, max_iter=500;, score=0.928 total time=   6.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .......alpha=0.0009, max_iter=1000;, score=0.925 total time=  14.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .......alpha=0.0009, max_iter=1000;, score=0.936 total time=  14.0s\n","[CV 3/5] END .......alpha=0.0009, max_iter=1000;, score=0.936 total time=  13.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .......alpha=0.0009, max_iter=1000;, score=0.945 total time=  14.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .......alpha=0.0009, max_iter=1000;, score=0.939 total time=  13.7s\n","[CV 1/5] END .......alpha=0.0009, max_iter=1500;, score=0.922 total time=  15.5s\n","[CV 2/5] END .......alpha=0.0009, max_iter=1500;, score=0.938 total time=  16.6s\n","[CV 3/5] END .......alpha=0.0009, max_iter=1500;, score=0.936 total time=  12.8s\n","[CV 4/5] END .......alpha=0.0009, max_iter=1500;, score=0.947 total time=  14.7s\n","[CV 5/5] END .......alpha=0.0009, max_iter=1500;, score=0.945 total time=  17.1s\n","[CV 1/5] END .......alpha=0.0009, max_iter=2000;, score=0.922 total time=  15.0s\n","[CV 2/5] END .......alpha=0.0009, max_iter=2000;, score=0.938 total time=  15.5s\n","[CV 3/5] END .......alpha=0.0009, max_iter=2000;, score=0.936 total time=  13.2s\n","[CV 4/5] END .......alpha=0.0009, max_iter=2000;, score=0.947 total time=  14.8s\n","[CV 5/5] END .......alpha=0.0009, max_iter=2000;, score=0.945 total time=  18.1s\n","[CV 1/5] END .......alpha=0.0009, max_iter=2500;, score=0.922 total time=  15.2s\n","[CV 2/5] END .......alpha=0.0009, max_iter=2500;, score=0.938 total time=  15.5s\n","[CV 3/5] END .......alpha=0.0009, max_iter=2500;, score=0.936 total time=  13.2s\n","[CV 4/5] END .......alpha=0.0009, max_iter=2500;, score=0.947 total time=  14.2s\n","[CV 5/5] END .......alpha=0.0009, max_iter=2500;, score=0.945 total time=  17.0s\n","[CV 1/5] END .......alpha=0.0009, max_iter=3000;, score=0.922 total time=  14.7s\n","[CV 2/5] END .......alpha=0.0009, max_iter=3000;, score=0.938 total time=  17.1s\n","[CV 3/5] END .......alpha=0.0009, max_iter=3000;, score=0.936 total time=  12.7s\n","[CV 4/5] END .......alpha=0.0009, max_iter=3000;, score=0.947 total time=  14.6s\n","[CV 5/5] END .......alpha=0.0009, max_iter=3000;, score=0.945 total time=  17.4s\n","[CV 1/5] END .......alpha=0.0009, max_iter=3500;, score=0.922 total time=  15.6s\n","[CV 2/5] END .......alpha=0.0009, max_iter=3500;, score=0.938 total time=  15.7s\n","[CV 3/5] END .......alpha=0.0009, max_iter=3500;, score=0.936 total time=  13.3s\n","[CV 4/5] END .......alpha=0.0009, max_iter=3500;, score=0.947 total time=  14.6s\n","[CV 5/5] END .......alpha=0.0009, max_iter=3500;, score=0.945 total time=  18.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END .........alpha=0.001, max_iter=500;, score=0.917 total time=   6.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END .........alpha=0.001, max_iter=500;, score=0.925 total time=   7.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END .........alpha=0.001, max_iter=500;, score=0.930 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END .........alpha=0.001, max_iter=500;, score=0.938 total time=   7.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END .........alpha=0.001, max_iter=500;, score=0.933 total time=   6.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END ........alpha=0.001, max_iter=1000;, score=0.927 total time=  14.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END ........alpha=0.001, max_iter=1000;, score=0.939 total time=  14.2s\n","[CV 3/5] END ........alpha=0.001, max_iter=1000;, score=0.939 total time=  13.4s\n","[CV 4/5] END ........alpha=0.001, max_iter=1000;, score=0.947 total time=  13.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END ........alpha=0.001, max_iter=1000;, score=0.942 total time=  14.1s\n","[CV 1/5] END ........alpha=0.001, max_iter=1500;, score=0.928 total time=  15.7s\n","[CV 2/5] END ........alpha=0.001, max_iter=1500;, score=0.938 total time=  15.6s\n","[CV 3/5] END ........alpha=0.001, max_iter=1500;, score=0.939 total time=  13.5s\n","[CV 4/5] END ........alpha=0.001, max_iter=1500;, score=0.947 total time=  13.2s\n","[CV 5/5] END ........alpha=0.001, max_iter=1500;, score=0.942 total time=  17.1s\n","[CV 1/5] END ........alpha=0.001, max_iter=2000;, score=0.928 total time=  16.1s\n","[CV 2/5] END ........alpha=0.001, max_iter=2000;, score=0.938 total time=  15.9s\n","[CV 3/5] END ........alpha=0.001, max_iter=2000;, score=0.939 total time=  13.7s\n","[CV 4/5] END ........alpha=0.001, max_iter=2000;, score=0.947 total time=  13.5s\n","[CV 5/5] END ........alpha=0.001, max_iter=2000;, score=0.942 total time=  18.4s\n","[CV 1/5] END ........alpha=0.001, max_iter=2500;, score=0.928 total time=  15.9s\n","[CV 2/5] END ........alpha=0.001, max_iter=2500;, score=0.938 total time=  15.9s\n","[CV 3/5] END ........alpha=0.001, max_iter=2500;, score=0.939 total time=  13.5s\n","[CV 4/5] END ........alpha=0.001, max_iter=2500;, score=0.947 total time=  13.0s\n","[CV 5/5] END ........alpha=0.001, max_iter=2500;, score=0.942 total time=  17.3s\n","[CV 1/5] END ........alpha=0.001, max_iter=3000;, score=0.928 total time=  16.9s\n","[CV 2/5] END ........alpha=0.001, max_iter=3000;, score=0.938 total time=  15.6s\n","[CV 3/5] END ........alpha=0.001, max_iter=3000;, score=0.939 total time=  13.4s\n","[CV 4/5] END ........alpha=0.001, max_iter=3000;, score=0.947 total time=  13.3s\n","[CV 5/5] END ........alpha=0.001, max_iter=3000;, score=0.942 total time=  18.2s\n","[CV 1/5] END ........alpha=0.001, max_iter=3500;, score=0.928 total time=  16.2s\n","[CV 2/5] END ........alpha=0.001, max_iter=3500;, score=0.938 total time=  17.0s\n","[CV 3/5] END ........alpha=0.001, max_iter=3500;, score=0.939 total time=  13.7s\n","[CV 4/5] END ........alpha=0.001, max_iter=3500;, score=0.947 total time=  13.8s\n","[CV 5/5] END ........alpha=0.001, max_iter=3500;, score=0.942 total time=  18.1s\n","Best parameters: {'alpha': 0.0007, 'max_iter': 1500}\n","Best score:  0.9400000000000001\n","Model accuracy: 0.9487\n"]}],"source":["#turns out there's not much of a point to this.\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","# It's often a good practice to scale your data for neural network models\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Define the hyperparameter grid for MLPClassifier\n","param_grid = {\n","    'max_iter': [500, 1000, 1500, 2000, 2500, 3000, 3500],\n","    'alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001]\n","}\n","\n","\n","# Configure GridSearchCV\n","grid_search = GridSearchCV(MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42),\n","                           param_grid, scoring='accuracy', cv=5, verbose=3)\n","\n","# Fit GridSearchCV\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Review the results\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best score: \", grid_search.best_score_)\n","\n","# Use the best model\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Model accuracy: {accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7086,"status":"ok","timestamp":1713788266480,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"_oHFvUHAvXvR","outputId":"988c679c-954e-427c-f006-df74d391bc8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1713812989211,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"npvyWBVKNtoj","outputId":"602f5ef5-bb4c-4153-ff47-bc2b18b21e94"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available.\n"]}],"source":["if len(tf.config.list_physical_devices('GPU')) > 0:\n","    print(\"GPU is available.\")\n","else:\n","    print(\"GPU is not available, running on CPU.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26506,"status":"ok","timestamp":1713814957523,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"sv_pwQ0AVEf_","outputId":"f2ffb75d-3c43-4ddf-8193-0066c4a932b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","25/25 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.7513\n","Epoch 2/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8266\n","Epoch 3/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8544\n","Epoch 4/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8684\n","Epoch 5/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.8800\n","Epoch 6/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8866\n","Epoch 7/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.8941\n","Epoch 8/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8991\n","Epoch 9/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9003\n","Epoch 10/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9069\n","Epoch 11/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9112\n","Epoch 12/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9153\n","Epoch 13/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9184\n","Epoch 14/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9206\n","Epoch 15/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9197\n","Epoch 16/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9237\n","Epoch 17/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9253\n","Epoch 18/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9325\n","Epoch 19/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9353\n","Epoch 20/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9344\n","Epoch 21/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9347\n","Epoch 22/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9378\n","Epoch 23/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9388\n","Epoch 24/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9406\n","Epoch 25/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9444\n","Epoch 26/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9444\n","Epoch 27/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9475\n","Epoch 28/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9469\n","Epoch 29/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9416\n","Epoch 30/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9503\n","Epoch 31/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9519\n","Epoch 32/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9519\n","Epoch 33/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9506\n","Epoch 34/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9506\n","Epoch 35/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9522\n","Epoch 36/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9547\n","Epoch 37/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9538\n","Epoch 38/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9600\n","Epoch 39/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9575\n","Epoch 40/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9622\n","Epoch 41/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9641\n","Epoch 42/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9616\n","Epoch 43/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9622\n","Epoch 44/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9634\n","Epoch 45/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9650\n","Epoch 46/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9638\n","Epoch 47/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9641\n","Epoch 48/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9616\n","Epoch 49/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9656\n","Epoch 50/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9691\n","Epoch 1/50\n","25/25 [==============================] - 1s 3ms/step - loss: 0.5945 - accuracy: 0.7003\n","Epoch 2/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8122\n","Epoch 3/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8334\n","Epoch 4/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8506\n","Epoch 5/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8606\n","Epoch 6/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8694\n","Epoch 7/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8766\n","Epoch 8/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.8850\n","Epoch 9/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8888\n","Epoch 10/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.8944\n","Epoch 11/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9022\n","Epoch 12/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9022\n","Epoch 13/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9078\n","Epoch 14/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9109\n","Epoch 15/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9106\n","Epoch 16/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9112\n","Epoch 17/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9191\n","Epoch 18/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9222\n","Epoch 19/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9247\n","Epoch 20/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9247\n","Epoch 21/50\n","25/25 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9281\n","Epoch 22/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9325\n","Epoch 23/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9291\n","Epoch 24/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9347\n","Epoch 25/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9350\n","Epoch 26/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9391\n","Epoch 27/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9341\n","Epoch 28/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9419\n","Epoch 29/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9466\n","Epoch 30/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9475\n","Epoch 31/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9434\n","Epoch 32/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9406\n","Epoch 33/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9478\n","Epoch 34/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9472\n","Epoch 35/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9509\n","Epoch 36/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9538\n","Epoch 37/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9509\n","Epoch 38/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9519\n","Epoch 39/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9516\n","Epoch 40/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9575\n","Epoch 41/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9541\n","Epoch 42/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9531\n","Epoch 43/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9584\n","Epoch 44/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9550\n","Epoch 45/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9591\n","Epoch 46/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9625\n","Epoch 47/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9628\n","Epoch 48/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9606\n","Epoch 49/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9594\n","Epoch 50/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9659\n","Epoch 1/50\n","25/25 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.7509\n","Epoch 2/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8309\n","Epoch 3/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8512\n","Epoch 4/50\n","25/25 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8678\n","Epoch 5/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8778\n","Epoch 6/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8866\n","Epoch 7/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.8953\n","Epoch 8/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9006\n","Epoch 9/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9022\n","Epoch 10/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9094\n","Epoch 11/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9094\n","Epoch 12/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9147\n","Epoch 13/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9206\n","Epoch 14/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2008 - accuracy: 0.9209\n","Epoch 15/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9234\n","Epoch 16/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9269\n","Epoch 17/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9272\n","Epoch 18/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9312\n","Epoch 19/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9312\n","Epoch 20/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9328\n","Epoch 21/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9350\n","Epoch 22/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9350\n","Epoch 23/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9394\n","Epoch 24/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9434\n","Epoch 25/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9400\n","Epoch 26/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9375\n","Epoch 27/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9431\n","Epoch 28/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9472\n","Epoch 29/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9481\n","Epoch 30/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9478\n","Epoch 31/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9503\n","Epoch 32/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9503\n","Epoch 33/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9522\n","Epoch 34/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9506\n","Epoch 35/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9513\n","Epoch 36/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9566\n","Epoch 37/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9588\n","Epoch 38/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9553\n","Epoch 39/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9575\n","Epoch 40/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9541\n","Epoch 41/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9606\n","Epoch 42/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9628\n","Epoch 43/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9641\n","Epoch 44/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9634\n","Epoch 45/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9656\n","Epoch 46/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9663\n","Epoch 47/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9653\n","Epoch 48/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9653\n","Epoch 49/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9628\n","Epoch 50/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9697\n","Epoch 1/50\n","25/25 [==============================] - 1s 3ms/step - loss: 0.6102 - accuracy: 0.6919\n","Epoch 2/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8097\n","Epoch 3/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8388\n","Epoch 4/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8616\n","Epoch 5/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8737\n","Epoch 6/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8766\n","Epoch 7/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8831\n","Epoch 8/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8925\n","Epoch 9/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.8956\n","Epoch 10/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9022\n","Epoch 11/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9038\n","Epoch 12/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9097\n","Epoch 13/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9128\n","Epoch 14/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9187\n","Epoch 15/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9191\n","Epoch 16/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9169\n","Epoch 17/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9228\n","Epoch 18/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9222\n","Epoch 19/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9294\n","Epoch 20/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9309\n","Epoch 21/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9297\n","Epoch 22/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9325\n","Epoch 23/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9353\n","Epoch 24/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9416\n","Epoch 25/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9419\n","Epoch 26/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9394\n","Epoch 27/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9334\n","Epoch 28/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9394\n","Epoch 29/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9450\n","Epoch 30/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9459\n","Epoch 31/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9444\n","Epoch 32/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9475\n","Epoch 33/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9488\n","Epoch 34/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9466\n","Epoch 35/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9491\n","Epoch 36/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9506\n","Epoch 37/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9547\n","Epoch 38/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9566\n","Epoch 39/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9544\n","Epoch 40/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9534\n","Epoch 41/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9544\n","Epoch 42/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9578\n","Epoch 43/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9609\n","Epoch 44/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9600\n","Epoch 45/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9606\n","Epoch 46/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9609\n","Epoch 47/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9606\n","Epoch 48/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9622\n","Epoch 49/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9653\n","Epoch 50/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9663\n","Epoch 1/50\n","25/25 [==============================] - 1s 3ms/step - loss: 0.5303 - accuracy: 0.7634\n","Epoch 2/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8494\n","Epoch 3/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8734\n","Epoch 4/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8863\n","Epoch 5/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8903\n","Epoch 6/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.8988\n","Epoch 7/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9031\n","Epoch 8/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9066\n","Epoch 9/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9122\n","Epoch 10/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9094\n","Epoch 11/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9169\n","Epoch 12/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9212\n","Epoch 13/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9216\n","Epoch 14/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9228\n","Epoch 15/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9259\n","Epoch 16/50\n","25/25 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9309\n","Epoch 17/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9297\n","Epoch 18/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9325\n","Epoch 19/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9369\n","Epoch 20/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9394\n","Epoch 21/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9444\n","Epoch 22/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9438\n","Epoch 23/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9400\n","Epoch 24/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9413\n","Epoch 25/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9469\n","Epoch 26/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9491\n","Epoch 27/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9488\n","Epoch 28/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9481\n","Epoch 29/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9494\n","Epoch 30/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9509\n","Epoch 31/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9534\n","Epoch 32/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9544\n","Epoch 33/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9541\n","Epoch 34/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9591\n","Epoch 35/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9559\n","Epoch 36/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9634\n","Epoch 37/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9600\n","Epoch 38/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9616\n","Epoch 39/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9597\n","Epoch 40/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9644\n","Epoch 41/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9625\n","Epoch 42/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9597\n","Epoch 43/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9691\n","Epoch 44/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9691\n","Epoch 45/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9712\n","Epoch 46/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9716\n","Epoch 47/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9731\n","Epoch 48/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9688\n","Epoch 49/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9719\n","Epoch 50/50\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9737\n"]}],"source":["#from https://www.kaggle.com/code/krippanandhini/apple-quality-classification-with-98-roc-auc-score\n","\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Define a function to create the neural network model\n","def create_model():\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(128, input_dim = features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(8, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Initialize lists to store accuracy scores\n","accuracy_scores = []\n","\n","# Iterate through each fold of cross-validation\n","for train_index, test_index in skf.split(features, target):\n","    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n","    y_train, y_test = target[train_index], target[test_index]\n","\n","    # Create the neural network model\n","    model = create_model()\n","\n","    # Fit the model on the training data\n","    model.fit(X_train, y_train, epochs=50, batch_size=128, verbose=1)\n","\n","    # Evaluate the model on the test data\n","    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","    # Store the accuracy score\n","    accuracy_scores.append(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148924,"status":"ok","timestamp":1713817302136,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"w1gel7sTeQ6d","outputId":"72a5328f-e637-44fa-894b-7f5b93f8b94c"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 2ms/step - loss: 4.2672 - accuracy: 0.7275\n"]},{"data":{"text/plain":["[4.267166614532471, 0.7275000214576721]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","# Create the model\n","model = tf.keras.Sequential([\n","                      tf.keras.layers.Dense(128, activation='relu'),\n","                  tf.keras.layers.Dense(512, activation='relu'),\n","                 tf.keras.layers.Dense(512, activation='relu'),\n","                  tf.keras.layers.Dense(1, activation='sigmoid')\n"," ])\n","# Compile the model\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"Adam\",\n","              metrics=[\"accuracy\"])\n","# Fit the model\n","history = model.fit(X_train,\n","                    y_train,\n","                    epochs=500,\n","                    validation_data=(X_test, y_test),\n","                    verbose=0)\n","model.evaluate(X_test_scaled, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420310,"status":"ok","timestamp":1713816405836,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"l7LSy_aBXwhM","outputId":"aa46ef36-8656-4307-b247-9d015bbda78b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0263e-07 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8560e-07 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8121e-07 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7359e-07 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6365e-07 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5933e-07 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5462e-07 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4316e-07 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3413e-07 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2784e-07 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2197e-07 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1230e-07 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0192e-07 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9464e-07 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0011e-07 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8753e-07 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7960e-07 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7311e-07 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6624e-07 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 4.6654e-07 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6092e-07 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4451e-07 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3916e-07 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3196e-07 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3136e-07 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2212e-07 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1958e-07 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0730e-07 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9872e-07 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9103e-07 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9278e-07 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8297e-07 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7682e-07 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7143e-07 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6743e-07 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6150e-07 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6235e-07 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5184e-07 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4322e-07 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3757e-07 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4057e-07 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2984e-07 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2564e-07 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2660e-07 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1642e-07 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2298e-07 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0686e-07 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0063e-07 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0029e-07 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9281e-07 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9028e-07 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8658e-07 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8269e-07 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7700e-07 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7820e-07 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6980e-07 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6575e-07 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6427e-07 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5833e-07 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5654e-07 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4979e-07 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5156e-07 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4603e-07 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4668e-07 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4086e-07 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3489e-07 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3112e-07 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2781e-07 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2766e-07 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2210e-07 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1841e-07 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1482e-07 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1226e-07 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0980e-07 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0578e-07 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0132e-07 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0090e-07 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9669e-07 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9303e-07 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0115e-07 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8816e-07 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8855e-07 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8597e-07 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8119e-07 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7708e-07 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7413e-07 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7563e-07 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7181e-07 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6959e-07 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6781e-07 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6302e-07 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6157e-07 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5977e-07 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5758e-07 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5653e-07 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5506e-07 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5101e-07 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4782e-07 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4628e-07 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4385e-07 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4275e-07 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4001e-07 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3876e-07 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3686e-07 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3292e-07 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3215e-07 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2963e-07 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2956e-07 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2765e-07 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2425e-07 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2578e-07 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2579e-07 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1968e-07 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2157e-07 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1845e-07 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1517e-07 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1434e-07 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1223e-07 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0947e-07 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0817e-07 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0803e-07 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0592e-07 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0365e-07 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0378e-07 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0111e-07 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9395e-08 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9208e-08 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6984e-08 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6517e-08 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4976e-08 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2009e-08 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1464e-08 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9795e-08 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8875e-08 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7928e-08 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6271e-08 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5537e-08 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4787e-08 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3518e-08 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2178e-08 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0986e-08 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1020e-08 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9352e-08 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7654e-08 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6465e-08 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4734e-08 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5295e-08 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3289e-08 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2918e-08 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3478e-08 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9938e-08 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9134e-08 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8153e-08 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7447e-08 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6491e-08 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5370e-08 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4952e-08 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6288e-08 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3038e-08 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2252e-08 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1863e-08 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0584e-08 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8932e-08 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0074e-08 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7580e-08 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6979e-08 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6667e-08 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5412e-08 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4785e-08 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4027e-08 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.3871e-08 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2940e-08 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1784e-08 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1498e-08 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0188e-08 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0090e-08 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9287e-08 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8437e-08 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8037e-08 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8079e-08 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6502e-08 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5639e-08 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5306e-08 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4408e-08 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3936e-08 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3860e-08 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2434e-08 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2855e-08 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2091e-08 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1402e-08 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1317e-08 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0030e-08 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9621e-08 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9014e-08 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8133e-08 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7980e-08 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7342e-08 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7100e-08 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6513e-08 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6130e-08 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5684e-08 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5223e-08 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4698e-08 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4635e-08 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4196e-08 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3155e-08 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2808e-08 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2136e-08 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2036e-08 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1667e-08 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0848e-08 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0866e-08 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0275e-08 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0290e-08 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9573e-08 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8939e-08 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8568e-08 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8296e-08 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7912e-08 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7619e-08 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7247e-08 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7558e-08 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6563e-08 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6262e-08 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5916e-08 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5308e-08 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5120e-08 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4992e-08 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4644e-08 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4281e-08 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3771e-08 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3656e-08 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3352e-08 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3612e-08 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2702e-08 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2435e-08 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2328e-08 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1919e-08 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1933e-08 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1629e-08 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1164e-08 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0727e-08 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0547e-08 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0268e-08 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0265e-08 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9739e-08 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9950e-08 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9600e-08 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9095e-08 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8791e-08 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8635e-08 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8094e-08 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8144e-08 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7673e-08 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7485e-08 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7819e-08 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6877e-08 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7124e-08 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6818e-08 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6516e-08 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6239e-08 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6048e-08 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6068e-08 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5702e-08 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5462e-08 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5206e-08 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4996e-08 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4786e-08 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4767e-08 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4782e-08 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4472e-08 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4548e-08 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3896e-08 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3907e-08 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3699e-08 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3556e-08 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3452e-08 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3126e-08 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3108e-08 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2854e-08 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2654e-08 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2526e-08 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2402e-08 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2302e-08 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2294e-08 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1875e-08 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1867e-08 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1600e-08 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1533e-08 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1321e-08 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1284e-08 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1158e-08 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0980e-08 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0863e-08 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0676e-08 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0682e-08 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0657e-08 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0374e-08 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0206e-08 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0058e-08 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9642e-09 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8627e-09 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7108e-09 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6243e-09 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5441e-09 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3306e-09 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2398e-09 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2519e-09 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1385e-09 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0068e-09 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8059e-09 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7751e-09 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5935e-09 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5023e-09 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4063e-09 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3924e-09 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3810e-09 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1255e-09 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0559e-09 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0185e-09 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0455e-09 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 7.7721e-09 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7107e-09 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5784e-09 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4783e-09 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4416e-09 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5129e-09 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4852e-09 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1371e-09 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2191e-09 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9559e-09 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9008e-09 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9437e-09 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7762e-09 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7294e-09 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7105e-09 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5336e-09 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4935e-09 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4204e-09 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4089e-09 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4236e-09 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1955e-09 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1448e-09 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0079e-09 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9566e-09 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.9495e-09 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7947e-09 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8149e-09 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8422e-09 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6975e-09 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5916e-09 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5256e-09 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5315e-09 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4434e-09 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4066e-09 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3725e-09 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3084e-09 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1813e-09 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.2211e-09 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0877e-09 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0310e-09 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9769e-09 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9690e-09 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8885e-09 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8903e-09 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7766e-09 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7166e-09 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7213e-09 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6558e-09 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6003e-09 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5508e-09 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6198e-09 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5846e-09 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4316e-09 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3616e-09 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2997e-09 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2607e-09 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2695e-09 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1926e-09 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1092e-09 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1151e-09 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0440e-09 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0434e-09 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9727e-09 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9546e-09 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9511e-09 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8979e-09 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8234e-09 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7868e-09 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7573e-09 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7325e-09 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7477e-09 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6940e-09 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6330e-09 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6334e-09 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5415e-09 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5712e-09 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4918e-09 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4466e-09 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4585e-09 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3977e-09 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4011e-09 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3493e-09 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3351e-09 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3114e-09 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2686e-09 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2578e-09 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1990e-09 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2330e-09 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1459e-09 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1344e-09 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1205e-09 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1104e-09 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0320e-09 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0899e-09 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0344e-09 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0019e-09 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9803e-09 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9351e-09 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9188e-09 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.9434e-09 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8717e-09 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8776e-09 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8347e-09 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7984e-09 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8296e-09 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7618e-09 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7605e-09 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7359e-09 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6998e-09 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6672e-09 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6124e-09 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6479e-09 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6495e-09 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5935e-09 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5657e-09 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5584e-09 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5851e-09 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5298e-09 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5248e-09 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5028e-09 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4987e-09 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4640e-09 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4761e-09 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4499e-09 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3826e-09 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4202e-09 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4197e-09 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3677e-09 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3388e-09 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3528e-09 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3346e-09 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3323e-09 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2613e-09 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2779e-09 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2917e-09 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2322e-09 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2723e-09 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2169e-09 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2169e-09 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2216e-09 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1384e-09 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1912e-09 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1607e-09 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1097e-09 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1418e-09 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1163e-09 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1321e-09 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1205e-09 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0833e-09 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.1035e-09 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0535e-09 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0700e-09 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0858e-09 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0413e-09 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0024e-09 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0252e-09 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9975e-09 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9917e-09 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0033e-09 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0146e-09 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9668e-09 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9423e-09 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9379e-09 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9470e-09 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9071e-09 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9158e-09 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9229e-09 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8955e-09 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8980e-09 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8866e-09 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9027e-09 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8550e-09 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8836e-09 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8518e-09 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7914e-09 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8289e-09 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8176e-09 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8003e-09 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7689e-09 - accuracy: 1.0000\n","Epoch 1/1000\n","25/25 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.7859\n","Epoch 2/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8619\n","Epoch 3/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8925\n","Epoch 4/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.8984\n","Epoch 5/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.9013\n","Epoch 6/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9153\n","Epoch 7/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9216\n","Epoch 8/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9256\n","Epoch 9/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9253\n","Epoch 10/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9300\n","Epoch 11/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9341\n","Epoch 12/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9291\n","Epoch 13/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9413\n","Epoch 14/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9478\n","Epoch 15/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9463\n","Epoch 16/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9509\n","Epoch 17/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9509\n","Epoch 18/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9603\n","Epoch 19/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9566\n","Epoch 20/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9600\n","Epoch 21/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9638\n","Epoch 22/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9650\n","Epoch 23/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9647\n","Epoch 24/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9631\n","Epoch 25/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9609\n","Epoch 26/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9694\n","Epoch 27/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9678\n","Epoch 28/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9716\n","Epoch 29/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9650\n","Epoch 30/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9744\n","Epoch 31/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9750\n","Epoch 32/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9734\n","Epoch 33/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9781\n","Epoch 34/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9756\n","Epoch 35/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9766\n","Epoch 36/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9750\n","Epoch 37/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9778\n","Epoch 38/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9812\n","Epoch 39/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9803\n","Epoch 40/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9828\n","Epoch 41/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9775\n","Epoch 42/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9847\n","Epoch 43/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9866\n","Epoch 44/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9872\n","Epoch 45/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9891\n","Epoch 46/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9872\n","Epoch 47/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9891\n","Epoch 48/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9881\n","Epoch 49/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9834\n","Epoch 50/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9897\n","Epoch 51/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9916\n","Epoch 52/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9906\n","Epoch 53/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9931\n","Epoch 54/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9941\n","Epoch 55/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9947\n","Epoch 56/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9944\n","Epoch 57/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9900\n","Epoch 58/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9828\n","Epoch 59/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9781\n","Epoch 60/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9912\n","Epoch 61/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9891\n","Epoch 62/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9922\n","Epoch 63/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9897\n","Epoch 64/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9912\n","Epoch 65/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9931\n","Epoch 66/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9956\n","Epoch 67/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9959\n","Epoch 68/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9969\n","Epoch 69/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9978\n","Epoch 70/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9969\n","Epoch 71/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9934\n","Epoch 72/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9912\n","Epoch 73/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9912\n","Epoch 74/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9909\n","Epoch 75/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9906\n","Epoch 76/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9878\n","Epoch 77/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9847\n","Epoch 78/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9859\n","Epoch 79/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9872\n","Epoch 80/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9912\n","Epoch 81/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9919\n","Epoch 82/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9956\n","Epoch 83/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9969\n","Epoch 84/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9981\n","Epoch 85/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9978\n","Epoch 86/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991\n","Epoch 87/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9987\n","Epoch 88/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991\n","Epoch 89/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9994\n","Epoch 90/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9991\n","Epoch 91/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9991\n","Epoch 92/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9984\n","Epoch 93/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9975\n","Epoch 94/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9969\n","Epoch 95/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9981\n","Epoch 96/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9966\n","Epoch 97/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9969\n","Epoch 98/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9969\n","Epoch 99/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972\n","Epoch 100/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9984\n","Epoch 101/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9984\n","Epoch 102/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9997\n","Epoch 103/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9997\n","Epoch 104/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9997\n","Epoch 105/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9997\n","Epoch 106/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 107/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9997\n","Epoch 108/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9991\n","Epoch 109/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994\n","Epoch 110/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 111/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9994\n","Epoch 112/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 113/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 114/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 115/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7283e-04 - accuracy: 1.0000\n","Epoch 116/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9994\n","Epoch 117/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n","Epoch 118/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9941\n","Epoch 119/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9834\n","Epoch 120/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9684\n","Epoch 121/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9859\n","Epoch 122/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9906\n","Epoch 123/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9941\n","Epoch 124/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9931\n","Epoch 125/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9944\n","Epoch 126/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9912\n","Epoch 127/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9941\n","Epoch 128/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9984\n","Epoch 129/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9994\n","Epoch 130/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 131/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9997\n","Epoch 132/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9997\n","Epoch 133/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9997\n","Epoch 134/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9997\n","Epoch 135/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 136/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 137/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8938e-04 - accuracy: 1.0000\n","Epoch 138/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2157e-04 - accuracy: 1.0000\n","Epoch 139/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 8.8898e-04 - accuracy: 1.0000\n","Epoch 140/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9630e-04 - accuracy: 1.0000\n","Epoch 141/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8055e-04 - accuracy: 1.0000\n","Epoch 142/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1193e-04 - accuracy: 1.0000\n","Epoch 143/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9306e-04 - accuracy: 1.0000\n","Epoch 144/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7509e-04 - accuracy: 1.0000\n","Epoch 145/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2220e-04 - accuracy: 1.0000\n","Epoch 146/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0731e-04 - accuracy: 1.0000\n","Epoch 147/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6556e-04 - accuracy: 1.0000\n","Epoch 148/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4256e-04 - accuracy: 1.0000\n","Epoch 149/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3424e-04 - accuracy: 1.0000\n","Epoch 150/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1549e-04 - accuracy: 1.0000\n","Epoch 151/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9163e-04 - accuracy: 1.0000\n","Epoch 152/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6987e-04 - accuracy: 1.0000\n","Epoch 153/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4795e-04 - accuracy: 1.0000\n","Epoch 154/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3387e-04 - accuracy: 1.0000\n","Epoch 155/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2070e-04 - accuracy: 1.0000\n","Epoch 156/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0761e-04 - accuracy: 1.0000\n","Epoch 157/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9342e-04 - accuracy: 1.0000\n","Epoch 158/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8554e-04 - accuracy: 1.0000\n","Epoch 159/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7289e-04 - accuracy: 1.0000\n","Epoch 160/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5683e-04 - accuracy: 1.0000\n","Epoch 161/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4933e-04 - accuracy: 1.0000\n","Epoch 162/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4195e-04 - accuracy: 1.0000\n","Epoch 163/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3004e-04 - accuracy: 1.0000\n","Epoch 164/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2043e-04 - accuracy: 1.0000\n","Epoch 165/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2264e-04 - accuracy: 1.0000\n","Epoch 166/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0535e-04 - accuracy: 1.0000\n","Epoch 167/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9219e-04 - accuracy: 1.0000\n","Epoch 168/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8901e-04 - accuracy: 1.0000\n","Epoch 169/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8301e-04 - accuracy: 1.0000\n","Epoch 170/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7474e-04 - accuracy: 1.0000\n","Epoch 171/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6415e-04 - accuracy: 1.0000\n","Epoch 172/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5771e-04 - accuracy: 1.0000\n","Epoch 173/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5225e-04 - accuracy: 1.0000\n","Epoch 174/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4528e-04 - accuracy: 1.0000\n","Epoch 175/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3776e-04 - accuracy: 1.0000\n","Epoch 176/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3287e-04 - accuracy: 1.0000\n","Epoch 177/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2691e-04 - accuracy: 1.0000\n","Epoch 178/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1901e-04 - accuracy: 1.0000\n","Epoch 179/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1615e-04 - accuracy: 1.0000\n","Epoch 180/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1160e-04 - accuracy: 1.0000\n","Epoch 181/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0741e-04 - accuracy: 1.0000\n","Epoch 182/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0689e-04 - accuracy: 1.0000\n","Epoch 183/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0104e-04 - accuracy: 1.0000\n","Epoch 184/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9108e-04 - accuracy: 1.0000\n","Epoch 185/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8618e-04 - accuracy: 1.0000\n","Epoch 186/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8451e-04 - accuracy: 1.0000\n","Epoch 187/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7825e-04 - accuracy: 1.0000\n","Epoch 188/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7616e-04 - accuracy: 1.0000\n","Epoch 189/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7073e-04 - accuracy: 1.0000\n","Epoch 190/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6745e-04 - accuracy: 1.0000\n","Epoch 191/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6266e-04 - accuracy: 1.0000\n","Epoch 192/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5936e-04 - accuracy: 1.0000\n","Epoch 193/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5708e-04 - accuracy: 1.0000\n","Epoch 194/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5200e-04 - accuracy: 1.0000\n","Epoch 195/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4969e-04 - accuracy: 1.0000\n","Epoch 196/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4896e-04 - accuracy: 1.0000\n","Epoch 197/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4442e-04 - accuracy: 1.0000\n","Epoch 198/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3987e-04 - accuracy: 1.0000\n","Epoch 199/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3701e-04 - accuracy: 1.0000\n","Epoch 200/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3518e-04 - accuracy: 1.0000\n","Epoch 201/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3097e-04 - accuracy: 1.0000\n","Epoch 202/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2916e-04 - accuracy: 1.0000\n","Epoch 203/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2588e-04 - accuracy: 1.0000\n","Epoch 204/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2488e-04 - accuracy: 1.0000\n","Epoch 205/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2412e-04 - accuracy: 1.0000\n","Epoch 206/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2055e-04 - accuracy: 1.0000\n","Epoch 207/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1682e-04 - accuracy: 1.0000\n","Epoch 208/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1539e-04 - accuracy: 1.0000\n","Epoch 209/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1556e-04 - accuracy: 1.0000\n","Epoch 210/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1204e-04 - accuracy: 1.0000\n","Epoch 211/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0914e-04 - accuracy: 1.0000\n","Epoch 212/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0711e-04 - accuracy: 1.0000\n","Epoch 213/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0408e-04 - accuracy: 1.0000\n","Epoch 214/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0146e-04 - accuracy: 1.0000\n","Epoch 215/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0007e-04 - accuracy: 1.0000\n","Epoch 216/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7593e-05 - accuracy: 1.0000\n","Epoch 217/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5961e-05 - accuracy: 1.0000\n","Epoch 218/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3873e-05 - accuracy: 1.0000\n","Epoch 219/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2779e-05 - accuracy: 1.0000\n","Epoch 220/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1516e-05 - accuracy: 1.0000\n","Epoch 221/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8623e-05 - accuracy: 1.0000\n","Epoch 222/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6707e-05 - accuracy: 1.0000\n","Epoch 223/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6731e-05 - accuracy: 1.0000\n","Epoch 224/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5345e-05 - accuracy: 1.0000\n","Epoch 225/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2479e-05 - accuracy: 1.0000\n","Epoch 226/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1718e-05 - accuracy: 1.0000\n","Epoch 227/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1055e-05 - accuracy: 1.0000\n","Epoch 228/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0572e-05 - accuracy: 1.0000\n","Epoch 229/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6284e-05 - accuracy: 1.0000\n","Epoch 230/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5495e-05 - accuracy: 1.0000\n","Epoch 231/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4018e-05 - accuracy: 1.0000\n","Epoch 232/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2849e-05 - accuracy: 1.0000\n","Epoch 233/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1497e-05 - accuracy: 1.0000\n","Epoch 234/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9972e-05 - accuracy: 1.0000\n","Epoch 235/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4279e-05 - accuracy: 1.0000\n","Epoch 236/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7968e-05 - accuracy: 1.0000\n","Epoch 237/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6934e-05 - accuracy: 1.0000\n","Epoch 238/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6310e-05 - accuracy: 1.0000\n","Epoch 239/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3881e-05 - accuracy: 1.0000\n","Epoch 240/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2995e-05 - accuracy: 1.0000\n","Epoch 241/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1985e-05 - accuracy: 1.0000\n","Epoch 242/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0676e-05 - accuracy: 1.0000\n","Epoch 243/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0609e-05 - accuracy: 1.0000\n","Epoch 244/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9535e-05 - accuracy: 1.0000\n","Epoch 245/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7967e-05 - accuracy: 1.0000\n","Epoch 246/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6783e-05 - accuracy: 1.0000\n","Epoch 247/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5730e-05 - accuracy: 1.0000\n","Epoch 248/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4942e-05 - accuracy: 1.0000\n","Epoch 249/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4161e-05 - accuracy: 1.0000\n","Epoch 250/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3229e-05 - accuracy: 1.0000\n","Epoch 251/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2392e-05 - accuracy: 1.0000\n","Epoch 252/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2385e-05 - accuracy: 1.0000\n","Epoch 253/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2254e-05 - accuracy: 1.0000\n","Epoch 254/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9809e-05 - accuracy: 1.0000\n","Epoch 255/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8084e-05 - accuracy: 1.0000\n","Epoch 256/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8489e-05 - accuracy: 1.0000\n","Epoch 257/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8275e-05 - accuracy: 1.0000\n","Epoch 258/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7524e-05 - accuracy: 1.0000\n","Epoch 259/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6255e-05 - accuracy: 1.0000\n","Epoch 260/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4051e-05 - accuracy: 1.0000\n","Epoch 261/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3593e-05 - accuracy: 1.0000\n","Epoch 262/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3031e-05 - accuracy: 1.0000\n","Epoch 263/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2221e-05 - accuracy: 1.0000\n","Epoch 264/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1094e-05 - accuracy: 1.0000\n","Epoch 265/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0792e-05 - accuracy: 1.0000\n","Epoch 266/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0047e-05 - accuracy: 1.0000\n","Epoch 267/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9621e-05 - accuracy: 1.0000\n","Epoch 268/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0282e-05 - accuracy: 1.0000\n","Epoch 269/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8505e-05 - accuracy: 1.0000\n","Epoch 270/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7979e-05 - accuracy: 1.0000\n","Epoch 271/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7213e-05 - accuracy: 1.0000\n","Epoch 272/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7067e-05 - accuracy: 1.0000\n","Epoch 273/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6119e-05 - accuracy: 1.0000\n","Epoch 274/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5799e-05 - accuracy: 1.0000\n","Epoch 275/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5207e-05 - accuracy: 1.0000\n","Epoch 276/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4047e-05 - accuracy: 1.0000\n","Epoch 277/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3780e-05 - accuracy: 1.0000\n","Epoch 278/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3230e-05 - accuracy: 1.0000\n","Epoch 279/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2634e-05 - accuracy: 1.0000\n","Epoch 280/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1807e-05 - accuracy: 1.0000\n","Epoch 281/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1906e-05 - accuracy: 1.0000\n","Epoch 282/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1074e-05 - accuracy: 1.0000\n","Epoch 283/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0161e-05 - accuracy: 1.0000\n","Epoch 284/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9678e-05 - accuracy: 1.0000\n","Epoch 285/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9543e-05 - accuracy: 1.0000\n","Epoch 286/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9191e-05 - accuracy: 1.0000\n","Epoch 287/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8911e-05 - accuracy: 1.0000\n","Epoch 288/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8232e-05 - accuracy: 1.0000\n","Epoch 289/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7711e-05 - accuracy: 1.0000\n","Epoch 290/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7153e-05 - accuracy: 1.0000\n","Epoch 291/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7074e-05 - accuracy: 1.0000\n","Epoch 292/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6114e-05 - accuracy: 1.0000\n","Epoch 293/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5671e-05 - accuracy: 1.0000\n","Epoch 294/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5551e-05 - accuracy: 1.0000\n","Epoch 295/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5149e-05 - accuracy: 1.0000\n","Epoch 296/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4974e-05 - accuracy: 1.0000\n","Epoch 297/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4519e-05 - accuracy: 1.0000\n","Epoch 298/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3908e-05 - accuracy: 1.0000\n","Epoch 299/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3228e-05 - accuracy: 1.0000\n","Epoch 300/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3257e-05 - accuracy: 1.0000\n","Epoch 301/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3077e-05 - accuracy: 1.0000\n","Epoch 302/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2031e-05 - accuracy: 1.0000\n","Epoch 303/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2249e-05 - accuracy: 1.0000\n","Epoch 304/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1563e-05 - accuracy: 1.0000\n","Epoch 305/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1261e-05 - accuracy: 1.0000\n","Epoch 306/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0813e-05 - accuracy: 1.0000\n","Epoch 307/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0620e-05 - accuracy: 1.0000\n","Epoch 308/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0416e-05 - accuracy: 1.0000\n","Epoch 309/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9937e-05 - accuracy: 1.0000\n","Epoch 310/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9870e-05 - accuracy: 1.0000\n","Epoch 311/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9385e-05 - accuracy: 1.0000\n","Epoch 312/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9106e-05 - accuracy: 1.0000\n","Epoch 313/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9270e-05 - accuracy: 1.0000\n","Epoch 314/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8654e-05 - accuracy: 1.0000\n","Epoch 315/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8733e-05 - accuracy: 1.0000\n","Epoch 316/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7718e-05 - accuracy: 1.0000\n","Epoch 317/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7676e-05 - accuracy: 1.0000\n","Epoch 318/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7611e-05 - accuracy: 1.0000\n","Epoch 319/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7226e-05 - accuracy: 1.0000\n","Epoch 320/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6910e-05 - accuracy: 1.0000\n","Epoch 321/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6546e-05 - accuracy: 1.0000\n","Epoch 322/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6143e-05 - accuracy: 1.0000\n","Epoch 323/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6240e-05 - accuracy: 1.0000\n","Epoch 324/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5849e-05 - accuracy: 1.0000\n","Epoch 325/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5786e-05 - accuracy: 1.0000\n","Epoch 326/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5322e-05 - accuracy: 1.0000\n","Epoch 327/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5172e-05 - accuracy: 1.0000\n","Epoch 328/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4869e-05 - accuracy: 1.0000\n","Epoch 329/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4556e-05 - accuracy: 1.0000\n","Epoch 330/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4491e-05 - accuracy: 1.0000\n","Epoch 331/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4220e-05 - accuracy: 1.0000\n","Epoch 332/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4055e-05 - accuracy: 1.0000\n","Epoch 333/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3735e-05 - accuracy: 1.0000\n","Epoch 334/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3295e-05 - accuracy: 1.0000\n","Epoch 335/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3235e-05 - accuracy: 1.0000\n","Epoch 336/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3138e-05 - accuracy: 1.0000\n","Epoch 337/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2764e-05 - accuracy: 1.0000\n","Epoch 338/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2666e-05 - accuracy: 1.0000\n","Epoch 339/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2523e-05 - accuracy: 1.0000\n","Epoch 340/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2257e-05 - accuracy: 1.0000\n","Epoch 341/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1956e-05 - accuracy: 1.0000\n","Epoch 342/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1863e-05 - accuracy: 1.0000\n","Epoch 343/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1726e-05 - accuracy: 1.0000\n","Epoch 344/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1548e-05 - accuracy: 1.0000\n","Epoch 345/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1232e-05 - accuracy: 1.0000\n","Epoch 346/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1168e-05 - accuracy: 1.0000\n","Epoch 347/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1033e-05 - accuracy: 1.0000\n","Epoch 348/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0884e-05 - accuracy: 1.0000\n","Epoch 349/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0814e-05 - accuracy: 1.0000\n","Epoch 350/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0399e-05 - accuracy: 1.0000\n","Epoch 351/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0266e-05 - accuracy: 1.0000\n","Epoch 352/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0122e-05 - accuracy: 1.0000\n","Epoch 353/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9696e-06 - accuracy: 1.0000\n","Epoch 354/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8065e-06 - accuracy: 1.0000\n","Epoch 355/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5963e-06 - accuracy: 1.0000\n","Epoch 356/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7942e-06 - accuracy: 1.0000\n","Epoch 357/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5321e-06 - accuracy: 1.0000\n","Epoch 358/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2173e-06 - accuracy: 1.0000\n","Epoch 359/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0668e-06 - accuracy: 1.0000\n","Epoch 360/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9428e-06 - accuracy: 1.0000\n","Epoch 361/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7638e-06 - accuracy: 1.0000\n","Epoch 362/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6902e-06 - accuracy: 1.0000\n","Epoch 363/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6028e-06 - accuracy: 1.0000\n","Epoch 364/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5252e-06 - accuracy: 1.0000\n","Epoch 365/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3285e-06 - accuracy: 1.0000\n","Epoch 366/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3409e-06 - accuracy: 1.0000\n","Epoch 367/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0236e-06 - accuracy: 1.0000\n","Epoch 368/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9978e-06 - accuracy: 1.0000\n","Epoch 369/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7807e-06 - accuracy: 1.0000\n","Epoch 370/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8136e-06 - accuracy: 1.0000\n","Epoch 371/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5995e-06 - accuracy: 1.0000\n","Epoch 372/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5473e-06 - accuracy: 1.0000\n","Epoch 373/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4409e-06 - accuracy: 1.0000\n","Epoch 374/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2725e-06 - accuracy: 1.0000\n","Epoch 375/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1876e-06 - accuracy: 1.0000\n","Epoch 376/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0541e-06 - accuracy: 1.0000\n","Epoch 377/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8789e-06 - accuracy: 1.0000\n","Epoch 378/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7784e-06 - accuracy: 1.0000\n","Epoch 379/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6874e-06 - accuracy: 1.0000\n","Epoch 380/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5893e-06 - accuracy: 1.0000\n","Epoch 381/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4239e-06 - accuracy: 1.0000\n","Epoch 382/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3359e-06 - accuracy: 1.0000\n","Epoch 383/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2410e-06 - accuracy: 1.0000\n","Epoch 384/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2075e-06 - accuracy: 1.0000\n","Epoch 385/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1641e-06 - accuracy: 1.0000\n","Epoch 386/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9813e-06 - accuracy: 1.0000\n","Epoch 387/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8508e-06 - accuracy: 1.0000\n","Epoch 388/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8032e-06 - accuracy: 1.0000\n","Epoch 389/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7176e-06 - accuracy: 1.0000\n","Epoch 390/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6510e-06 - accuracy: 1.0000\n","Epoch 391/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5870e-06 - accuracy: 1.0000\n","Epoch 392/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5029e-06 - accuracy: 1.0000\n","Epoch 393/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3802e-06 - accuracy: 1.0000\n","Epoch 394/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3700e-06 - accuracy: 1.0000\n","Epoch 395/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2193e-06 - accuracy: 1.0000\n","Epoch 396/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1839e-06 - accuracy: 1.0000\n","Epoch 397/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1311e-06 - accuracy: 1.0000\n","Epoch 398/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0022e-06 - accuracy: 1.0000\n","Epoch 399/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9430e-06 - accuracy: 1.0000\n","Epoch 400/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9015e-06 - accuracy: 1.0000\n","Epoch 401/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8263e-06 - accuracy: 1.0000\n","Epoch 402/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7566e-06 - accuracy: 1.0000\n","Epoch 403/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6163e-06 - accuracy: 1.0000\n","Epoch 404/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5418e-06 - accuracy: 1.0000\n","Epoch 405/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5483e-06 - accuracy: 1.0000\n","Epoch 406/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4368e-06 - accuracy: 1.0000\n","Epoch 407/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4796e-06 - accuracy: 1.0000\n","Epoch 408/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2474e-06 - accuracy: 1.0000\n","Epoch 409/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2667e-06 - accuracy: 1.0000\n","Epoch 410/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1646e-06 - accuracy: 1.0000\n","Epoch 411/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1096e-06 - accuracy: 1.0000\n","Epoch 412/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0510e-06 - accuracy: 1.0000\n","Epoch 413/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0362e-06 - accuracy: 1.0000\n","Epoch 414/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9619e-06 - accuracy: 1.0000\n","Epoch 415/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8766e-06 - accuracy: 1.0000\n","Epoch 416/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8508e-06 - accuracy: 1.0000\n","Epoch 417/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7447e-06 - accuracy: 1.0000\n","Epoch 418/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7061e-06 - accuracy: 1.0000\n","Epoch 419/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6073e-06 - accuracy: 1.0000\n","Epoch 420/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5506e-06 - accuracy: 1.0000\n","Epoch 421/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4827e-06 - accuracy: 1.0000\n","Epoch 422/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4147e-06 - accuracy: 1.0000\n","Epoch 423/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4006e-06 - accuracy: 1.0000\n","Epoch 424/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3297e-06 - accuracy: 1.0000\n","Epoch 425/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3531e-06 - accuracy: 1.0000\n","Epoch 426/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3009e-06 - accuracy: 1.0000\n","Epoch 427/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2328e-06 - accuracy: 1.0000\n","Epoch 428/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2021e-06 - accuracy: 1.0000\n","Epoch 429/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1043e-06 - accuracy: 1.0000\n","Epoch 430/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1406e-06 - accuracy: 1.0000\n","Epoch 431/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0984e-06 - accuracy: 1.0000\n","Epoch 432/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9957e-06 - accuracy: 1.0000\n","Epoch 433/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9838e-06 - accuracy: 1.0000\n","Epoch 434/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8635e-06 - accuracy: 1.0000\n","Epoch 435/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8615e-06 - accuracy: 1.0000\n","Epoch 436/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8592e-06 - accuracy: 1.0000\n","Epoch 437/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7687e-06 - accuracy: 1.0000\n","Epoch 438/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7529e-06 - accuracy: 1.0000\n","Epoch 439/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.6785e-06 - accuracy: 1.0000\n","Epoch 440/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6716e-06 - accuracy: 1.0000\n","Epoch 441/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6574e-06 - accuracy: 1.0000\n","Epoch 442/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6038e-06 - accuracy: 1.0000\n","Epoch 443/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5154e-06 - accuracy: 1.0000\n","Epoch 444/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5169e-06 - accuracy: 1.0000\n","Epoch 445/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5024e-06 - accuracy: 1.0000\n","Epoch 446/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4492e-06 - accuracy: 1.0000\n","Epoch 447/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3757e-06 - accuracy: 1.0000\n","Epoch 448/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3406e-06 - accuracy: 1.0000\n","Epoch 449/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3373e-06 - accuracy: 1.0000\n","Epoch 450/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2961e-06 - accuracy: 1.0000\n","Epoch 451/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2448e-06 - accuracy: 1.0000\n","Epoch 452/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2077e-06 - accuracy: 1.0000\n","Epoch 453/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1793e-06 - accuracy: 1.0000\n","Epoch 454/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2106e-06 - accuracy: 1.0000\n","Epoch 455/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1198e-06 - accuracy: 1.0000\n","Epoch 456/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.1257e-06 - accuracy: 1.0000\n","Epoch 457/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0626e-06 - accuracy: 1.0000\n","Epoch 458/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0404e-06 - accuracy: 1.0000\n","Epoch 459/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0163e-06 - accuracy: 1.0000\n","Epoch 460/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9895e-06 - accuracy: 1.0000\n","Epoch 461/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9890e-06 - accuracy: 1.0000\n","Epoch 462/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9768e-06 - accuracy: 1.0000\n","Epoch 463/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9166e-06 - accuracy: 1.0000\n","Epoch 464/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8656e-06 - accuracy: 1.0000\n","Epoch 465/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8357e-06 - accuracy: 1.0000\n","Epoch 466/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7982e-06 - accuracy: 1.0000\n","Epoch 467/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8019e-06 - accuracy: 1.0000\n","Epoch 468/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7700e-06 - accuracy: 1.0000\n","Epoch 469/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7557e-06 - accuracy: 1.0000\n","Epoch 470/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7273e-06 - accuracy: 1.0000\n","Epoch 471/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7447e-06 - accuracy: 1.0000\n","Epoch 472/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6669e-06 - accuracy: 1.0000\n","Epoch 473/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6579e-06 - accuracy: 1.0000\n","Epoch 474/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6308e-06 - accuracy: 1.0000\n","Epoch 475/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5975e-06 - accuracy: 1.0000\n","Epoch 476/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5619e-06 - accuracy: 1.0000\n","Epoch 477/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5765e-06 - accuracy: 1.0000\n","Epoch 478/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5262e-06 - accuracy: 1.0000\n","Epoch 479/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5184e-06 - accuracy: 1.0000\n","Epoch 480/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4957e-06 - accuracy: 1.0000\n","Epoch 481/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4603e-06 - accuracy: 1.0000\n","Epoch 482/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4301e-06 - accuracy: 1.0000\n","Epoch 483/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4217e-06 - accuracy: 1.0000\n","Epoch 484/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4059e-06 - accuracy: 1.0000\n","Epoch 485/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3842e-06 - accuracy: 1.0000\n","Epoch 486/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3828e-06 - accuracy: 1.0000\n","Epoch 487/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3739e-06 - accuracy: 1.0000\n","Epoch 488/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3222e-06 - accuracy: 1.0000\n","Epoch 489/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3009e-06 - accuracy: 1.0000\n","Epoch 490/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3063e-06 - accuracy: 1.0000\n","Epoch 491/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2866e-06 - accuracy: 1.0000\n","Epoch 492/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2332e-06 - accuracy: 1.0000\n","Epoch 493/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2180e-06 - accuracy: 1.0000\n","Epoch 494/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2022e-06 - accuracy: 1.0000\n","Epoch 495/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2054e-06 - accuracy: 1.0000\n","Epoch 496/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1939e-06 - accuracy: 1.0000\n","Epoch 497/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1951e-06 - accuracy: 1.0000\n","Epoch 498/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1339e-06 - accuracy: 1.0000\n","Epoch 499/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1449e-06 - accuracy: 1.0000\n","Epoch 500/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1128e-06 - accuracy: 1.0000\n","Epoch 501/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1059e-06 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0878e-06 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0618e-06 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0359e-06 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0314e-06 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0046e-06 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0022e-06 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9549e-07 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5860e-07 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5737e-07 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5056e-07 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4524e-07 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3656e-07 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1070e-07 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9696e-07 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7669e-07 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8391e-07 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4063e-07 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7740e-07 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3184e-07 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2365e-07 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9252e-07 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9579e-07 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7952e-07 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6916e-07 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7201e-07 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4932e-07 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4064e-07 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2002e-07 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2388e-07 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0956e-07 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9779e-07 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9080e-07 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8153e-07 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6682e-07 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6951e-07 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4683e-07 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2957e-07 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2729e-07 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2520e-07 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2635e-07 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1265e-07 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9099e-07 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9522e-07 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8120e-07 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6532e-07 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6179e-07 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5290e-07 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6034e-07 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4407e-07 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.3396e-07 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3144e-07 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1176e-07 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1348e-07 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9860e-07 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9545e-07 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8290e-07 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7843e-07 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7068e-07 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6708e-07 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5390e-07 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4853e-07 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4412e-07 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3846e-07 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3427e-07 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2833e-07 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2124e-07 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0986e-07 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0995e-07 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9768e-07 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9766e-07 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8929e-07 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8234e-07 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8178e-07 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7656e-07 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.7466e-07 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6613e-07 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5863e-07 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5105e-07 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4465e-07 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4490e-07 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3551e-07 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3327e-07 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2717e-07 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2332e-07 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2229e-07 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1800e-07 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0858e-07 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.0467e-07 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0401e-07 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9808e-07 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9102e-07 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9016e-07 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8241e-07 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8456e-07 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7852e-07 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7587e-07 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6911e-07 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6769e-07 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6983e-07 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5882e-07 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5276e-07 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5257e-07 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4728e-07 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4269e-07 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3946e-07 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4005e-07 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3398e-07 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3160e-07 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2608e-07 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2238e-07 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2316e-07 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2101e-07 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1511e-07 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1028e-07 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0720e-07 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0999e-07 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0230e-07 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9996e-07 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9451e-07 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9447e-07 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9181e-07 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8880e-07 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8532e-07 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8581e-07 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8559e-07 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8305e-07 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7815e-07 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7549e-07 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7392e-07 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7173e-07 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7045e-07 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6764e-07 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6303e-07 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6094e-07 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5879e-07 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5835e-07 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5518e-07 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5110e-07 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5009e-07 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4746e-07 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4909e-07 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4516e-07 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4101e-07 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3952e-07 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3689e-07 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3531e-07 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3469e-07 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3202e-07 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2935e-07 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.2999e-07 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2930e-07 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2539e-07 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2285e-07 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2179e-07 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1908e-07 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1672e-07 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1401e-07 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1562e-07 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1333e-07 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1262e-07 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0972e-07 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0717e-07 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0650e-07 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0616e-07 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0666e-07 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0487e-07 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0407e-07 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0077e-07 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7998e-08 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8800e-08 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5830e-08 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4718e-08 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2088e-08 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3477e-08 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0620e-08 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0338e-08 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8475e-08 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7572e-08 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6175e-08 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5677e-08 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3024e-08 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2467e-08 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0694e-08 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0050e-08 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0622e-08 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0314e-08 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7258e-08 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8010e-08 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4892e-08 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4292e-08 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3627e-08 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2301e-08 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0734e-08 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9076e-08 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8110e-08 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7595e-08 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7245e-08 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5714e-08 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4935e-08 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 6.5139e-08 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4640e-08 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3951e-08 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1906e-08 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1254e-08 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0029e-08 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9379e-08 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8305e-08 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7498e-08 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7096e-08 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6268e-08 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5439e-08 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5784e-08 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4357e-08 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3468e-08 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3050e-08 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1378e-08 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2235e-08 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0184e-08 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9550e-08 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9807e-08 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8531e-08 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7442e-08 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7249e-08 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6937e-08 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6516e-08 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5998e-08 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5259e-08 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4879e-08 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3489e-08 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2659e-08 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2424e-08 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2587e-08 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3181e-08 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1279e-08 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1197e-08 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9625e-08 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.9282e-08 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8836e-08 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8179e-08 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8085e-08 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7644e-08 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6598e-08 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5917e-08 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5946e-08 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5090e-08 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4501e-08 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4105e-08 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3517e-08 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3851e-08 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3586e-08 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2668e-08 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2905e-08 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1881e-08 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1174e-08 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0922e-08 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0159e-08 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0494e-08 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9753e-08 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9036e-08 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9389e-08 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8835e-08 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8287e-08 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8135e-08 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7953e-08 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7579e-08 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7212e-08 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6342e-08 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6202e-08 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5728e-08 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5381e-08 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5082e-08 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4752e-08 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4400e-08 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4097e-08 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4156e-08 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3707e-08 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3259e-08 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3308e-08 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2633e-08 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2195e-08 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1870e-08 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1503e-08 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1409e-08 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0983e-08 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0849e-08 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0762e-08 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0892e-08 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0069e-08 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9940e-08 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9478e-08 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9119e-08 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8866e-08 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8635e-08 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8500e-08 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8324e-08 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8112e-08 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7795e-08 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7473e-08 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7462e-08 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7318e-08 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7359e-08 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7152e-08 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6861e-08 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6546e-08 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5991e-08 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5914e-08 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6019e-08 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5808e-08 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5538e-08 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5411e-08 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5145e-08 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4880e-08 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4775e-08 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4592e-08 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4248e-08 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3993e-08 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3748e-08 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3821e-08 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3460e-08 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3479e-08 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3346e-08 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3052e-08 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3034e-08 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2705e-08 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2622e-08 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2499e-08 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2417e-08 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2088e-08 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1992e-08 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1910e-08 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2050e-08 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1597e-08 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1483e-08 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1481e-08 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1043e-08 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0968e-08 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0867e-08 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0789e-08 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0525e-08 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0435e-08 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0389e-08 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0209e-08 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0279e-08 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8749e-09 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9523e-09 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7523e-09 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7088e-09 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5178e-09 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 9.5629e-09 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3310e-09 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1398e-09 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9907e-09 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8914e-09 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8444e-09 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8201e-09 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7616e-09 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5258e-09 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5079e-09 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4268e-09 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2010e-09 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3155e-09 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0604e-09 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9496e-09 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9472e-09 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8791e-09 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8875e-09 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7468e-09 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4974e-09 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3720e-09 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4470e-09 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4775e-09 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2101e-09 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1194e-09 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0117e-09 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9826e-09 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8269e-09 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7589e-09 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7537e-09 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6903e-09 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5648e-09 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5303e-09 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4011e-09 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3799e-09 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3843e-09 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2019e-09 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2088e-09 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 6.2700e-09 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0128e-09 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9185e-09 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8450e-09 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8340e-09 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7184e-09 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7326e-09 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5262e-09 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5286e-09 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4528e-09 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3786e-09 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3427e-09 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3031e-09 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2446e-09 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1448e-09 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1401e-09 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1339e-09 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0978e-09 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9966e-09 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9803e-09 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9482e-09 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8152e-09 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7412e-09 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8560e-09 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7319e-09 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6834e-09 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6006e-09 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5907e-09 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4887e-09 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4846e-09 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4875e-09 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3249e-09 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3084e-09 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2943e-09 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1707e-09 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2870e-09 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1965e-09 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1149e-09 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0226e-09 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9844e-09 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9657e-09 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9783e-09 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8642e-09 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9663e-09 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8160e-09 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8818e-09 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7694e-09 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7751e-09 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7009e-09 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6538e-09 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6553e-09 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6415e-09 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5611e-09 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4896e-09 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5187e-09 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4678e-09 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4931e-09 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4114e-09 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4051e-09 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3231e-09 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3487e-09 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3215e-09 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.2652e-09 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1966e-09 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2273e-09 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1791e-09 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1701e-09 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1523e-09 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1568e-09 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1085e-09 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1192e-09 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0378e-09 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9887e-09 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9787e-09 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9220e-09 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9903e-09 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8708e-09 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9114e-09 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9219e-09 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8421e-09 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8711e-09 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7841e-09 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7522e-09 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7671e-09 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7383e-09 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7288e-09 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6771e-09 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6512e-09 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6435e-09 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6237e-09 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6036e-09 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5775e-09 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6066e-09 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5814e-09 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5908e-09 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5386e-09 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4924e-09 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4952e-09 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4818e-09 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4859e-09 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4047e-09 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4116e-09 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4023e-09 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4089e-09 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3690e-09 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3571e-09 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3448e-09 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2967e-09 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3004e-09 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3236e-09 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2283e-09 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2482e-09 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2576e-09 - accuracy: 1.0000\n","Epoch 1/1000\n","25/25 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7716\n","Epoch 2/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8716\n","Epoch 3/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.8906\n","Epoch 4/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8984\n","Epoch 5/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.8984\n","Epoch 6/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9134\n","Epoch 7/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9047\n","Epoch 8/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9172\n","Epoch 9/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9178\n","Epoch 10/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9266\n","Epoch 11/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9250\n","Epoch 12/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9331\n","Epoch 13/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9356\n","Epoch 14/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9356\n","Epoch 15/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9453\n","Epoch 16/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9403\n","Epoch 17/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9441\n","Epoch 18/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9469\n","Epoch 19/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9528\n","Epoch 20/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9513\n","Epoch 21/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9503\n","Epoch 22/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9553\n","Epoch 23/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9597\n","Epoch 24/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9569\n","Epoch 25/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9622\n","Epoch 26/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9622\n","Epoch 27/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9597\n","Epoch 28/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9641\n","Epoch 29/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9678\n","Epoch 30/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9697\n","Epoch 31/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9703\n","Epoch 32/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9737\n","Epoch 33/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9756\n","Epoch 34/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9706\n","Epoch 35/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9712\n","Epoch 36/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9734\n","Epoch 37/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9769\n","Epoch 38/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9831\n","Epoch 39/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9806\n","Epoch 40/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9853\n","Epoch 41/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9803\n","Epoch 42/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9747\n","Epoch 43/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9834\n","Epoch 44/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9859\n","Epoch 45/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9878\n","Epoch 46/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819\n","Epoch 47/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9828\n","Epoch 48/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9909\n","Epoch 49/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9916\n","Epoch 50/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9934\n","Epoch 51/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9934\n","Epoch 52/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9925\n","Epoch 53/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9909\n","Epoch 54/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9919\n","Epoch 55/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9900\n","Epoch 56/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9841\n","Epoch 57/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9909\n","Epoch 58/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9931\n","Epoch 59/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9956\n","Epoch 60/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9959\n","Epoch 61/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9966\n","Epoch 62/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9962\n","Epoch 63/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9978\n","Epoch 64/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9950\n","Epoch 65/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9944\n","Epoch 66/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9969\n","Epoch 67/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9947\n","Epoch 68/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9962\n","Epoch 69/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9947\n","Epoch 70/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9937\n","Epoch 71/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9944\n","Epoch 72/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9962\n","Epoch 73/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9981\n","Epoch 74/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9962\n","Epoch 75/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9944\n","Epoch 76/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9922\n","Epoch 77/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9912\n","Epoch 78/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9966\n","Epoch 79/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9966\n","Epoch 80/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9959\n","Epoch 81/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9987\n","Epoch 82/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9994\n","Epoch 83/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9978\n","Epoch 84/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987\n","Epoch 85/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9994\n","Epoch 86/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9994\n","Epoch 87/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987\n","Epoch 88/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9837\n","Epoch 89/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9747\n","Epoch 90/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9872\n","Epoch 91/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9922\n","Epoch 92/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9953\n","Epoch 93/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9975\n","Epoch 94/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9962\n","Epoch 95/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9987\n","Epoch 96/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9987\n","Epoch 97/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n","Epoch 98/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9994\n","Epoch 99/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9997\n","Epoch 100/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9994\n","Epoch 101/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9994\n","Epoch 102/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991\n","Epoch 103/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9994\n","Epoch 104/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994\n","Epoch 105/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9994\n","Epoch 106/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9997\n","Epoch 107/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997\n","Epoch 108/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n","Epoch 109/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9981\n","Epoch 110/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9962\n","Epoch 111/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9959\n","Epoch 112/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9869\n","Epoch 113/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9841\n","Epoch 114/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9856\n","Epoch 115/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9828\n","Epoch 116/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9891\n","Epoch 117/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9934\n","Epoch 118/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9975\n","Epoch 119/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9997\n","Epoch 120/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9994\n","Epoch 121/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9997\n","Epoch 122/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9997\n","Epoch 123/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 124/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9997\n","Epoch 125/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9997\n","Epoch 126/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 127/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 128/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8135e-04 - accuracy: 1.0000\n","Epoch 129/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1298e-04 - accuracy: 1.0000\n","Epoch 130/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8212e-04 - accuracy: 1.0000\n","Epoch 131/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8723e-04 - accuracy: 1.0000\n","Epoch 132/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4274e-04 - accuracy: 1.0000\n","Epoch 133/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9361e-04 - accuracy: 1.0000\n","Epoch 134/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6334e-04 - accuracy: 1.0000\n","Epoch 135/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9928e-04 - accuracy: 1.0000\n","Epoch 136/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0075e-04 - accuracy: 1.0000\n","Epoch 137/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5802e-04 - accuracy: 1.0000\n","Epoch 138/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4688e-04 - accuracy: 1.0000\n","Epoch 139/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0580e-04 - accuracy: 1.0000\n","Epoch 140/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8516e-04 - accuracy: 1.0000\n","Epoch 141/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2570e-04 - accuracy: 1.0000\n","Epoch 142/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9288e-04 - accuracy: 1.0000\n","Epoch 143/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1795e-04 - accuracy: 1.0000\n","Epoch 144/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8727e-04 - accuracy: 1.0000\n","Epoch 145/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0966e-04 - accuracy: 1.0000\n","Epoch 146/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6527e-04 - accuracy: 1.0000\n","Epoch 147/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3632e-04 - accuracy: 1.0000\n","Epoch 148/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3126e-04 - accuracy: 1.0000\n","Epoch 149/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7229e-04 - accuracy: 1.0000\n","Epoch 150/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4258e-04 - accuracy: 1.0000\n","Epoch 151/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3413e-04 - accuracy: 1.0000\n","Epoch 152/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1688e-04 - accuracy: 1.0000\n","Epoch 153/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0826e-04 - accuracy: 1.0000\n","Epoch 154/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1602e-04 - accuracy: 1.0000\n","Epoch 155/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0038e-04 - accuracy: 1.0000\n","Epoch 156/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4099e-04 - accuracy: 1.0000\n","Epoch 157/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8334e-04 - accuracy: 1.0000\n","Epoch 158/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7068e-04 - accuracy: 1.0000\n","Epoch 159/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6612e-04 - accuracy: 1.0000\n","Epoch 160/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4744e-04 - accuracy: 1.0000\n","Epoch 161/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3653e-04 - accuracy: 1.0000\n","Epoch 162/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3114e-04 - accuracy: 1.0000\n","Epoch 163/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2757e-04 - accuracy: 1.0000\n","Epoch 164/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2730e-04 - accuracy: 1.0000\n","Epoch 165/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0772e-04 - accuracy: 1.0000\n","Epoch 166/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0706e-04 - accuracy: 1.0000\n","Epoch 167/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0690e-04 - accuracy: 1.0000\n","Epoch 168/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.9099e-04 - accuracy: 1.0000\n","Epoch 169/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8744e-04 - accuracy: 1.0000\n","Epoch 170/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7953e-04 - accuracy: 1.0000\n","Epoch 171/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8085e-04 - accuracy: 1.0000\n","Epoch 172/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7592e-04 - accuracy: 1.0000\n","Epoch 173/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6351e-04 - accuracy: 1.0000\n","Epoch 174/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6297e-04 - accuracy: 1.0000\n","Epoch 175/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5387e-04 - accuracy: 1.0000\n","Epoch 176/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5192e-04 - accuracy: 1.0000\n","Epoch 177/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4750e-04 - accuracy: 1.0000\n","Epoch 178/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4307e-04 - accuracy: 1.0000\n","Epoch 179/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3983e-04 - accuracy: 1.0000\n","Epoch 180/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3334e-04 - accuracy: 1.0000\n","Epoch 181/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3265e-04 - accuracy: 1.0000\n","Epoch 182/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3195e-04 - accuracy: 1.0000\n","Epoch 183/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2559e-04 - accuracy: 1.0000\n","Epoch 184/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2158e-04 - accuracy: 1.0000\n","Epoch 185/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1742e-04 - accuracy: 1.0000\n","Epoch 186/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2022e-04 - accuracy: 1.0000\n","Epoch 187/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1775e-04 - accuracy: 1.0000\n","Epoch 188/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0995e-04 - accuracy: 1.0000\n","Epoch 189/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0769e-04 - accuracy: 1.0000\n","Epoch 190/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0424e-04 - accuracy: 1.0000\n","Epoch 191/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0547e-04 - accuracy: 1.0000\n","Epoch 192/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0150e-04 - accuracy: 1.0000\n","Epoch 193/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8760e-05 - accuracy: 1.0000\n","Epoch 194/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7499e-05 - accuracy: 1.0000\n","Epoch 195/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1446e-05 - accuracy: 1.0000\n","Epoch 196/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1266e-05 - accuracy: 1.0000\n","Epoch 197/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0231e-05 - accuracy: 1.0000\n","Epoch 198/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8054e-05 - accuracy: 1.0000\n","Epoch 199/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5418e-05 - accuracy: 1.0000\n","Epoch 200/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3633e-05 - accuracy: 1.0000\n","Epoch 201/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1573e-05 - accuracy: 1.0000\n","Epoch 202/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9205e-05 - accuracy: 1.0000\n","Epoch 203/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7343e-05 - accuracy: 1.0000\n","Epoch 204/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6348e-05 - accuracy: 1.0000\n","Epoch 205/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5177e-05 - accuracy: 1.0000\n","Epoch 206/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3267e-05 - accuracy: 1.0000\n","Epoch 207/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2543e-05 - accuracy: 1.0000\n","Epoch 208/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2001e-05 - accuracy: 1.0000\n","Epoch 209/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2819e-05 - accuracy: 1.0000\n","Epoch 210/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0361e-05 - accuracy: 1.0000\n","Epoch 211/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6415e-05 - accuracy: 1.0000\n","Epoch 212/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5249e-05 - accuracy: 1.0000\n","Epoch 213/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5187e-05 - accuracy: 1.0000\n","Epoch 214/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3235e-05 - accuracy: 1.0000\n","Epoch 215/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1953e-05 - accuracy: 1.0000\n","Epoch 216/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0320e-05 - accuracy: 1.0000\n","Epoch 217/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0627e-05 - accuracy: 1.0000\n","Epoch 218/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8486e-05 - accuracy: 1.0000\n","Epoch 219/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6649e-05 - accuracy: 1.0000\n","Epoch 220/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6468e-05 - accuracy: 1.0000\n","Epoch 221/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5978e-05 - accuracy: 1.0000\n","Epoch 222/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5129e-05 - accuracy: 1.0000\n","Epoch 223/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2987e-05 - accuracy: 1.0000\n","Epoch 224/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2397e-05 - accuracy: 1.0000\n","Epoch 225/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0940e-05 - accuracy: 1.0000\n","Epoch 226/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1331e-05 - accuracy: 1.0000\n","Epoch 227/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0015e-05 - accuracy: 1.0000\n","Epoch 228/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0260e-05 - accuracy: 1.0000\n","Epoch 229/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3859e-05 - accuracy: 1.0000\n","Epoch 230/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7488e-05 - accuracy: 1.0000\n","Epoch 231/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6992e-05 - accuracy: 1.0000\n","Epoch 232/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4433e-05 - accuracy: 1.0000\n","Epoch 233/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5169e-05 - accuracy: 1.0000\n","Epoch 234/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4968e-05 - accuracy: 1.0000\n","Epoch 235/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3391e-05 - accuracy: 1.0000\n","Epoch 236/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1955e-05 - accuracy: 1.0000\n","Epoch 237/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1835e-05 - accuracy: 1.0000\n","Epoch 238/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1377e-05 - accuracy: 1.0000\n","Epoch 239/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0784e-05 - accuracy: 1.0000\n","Epoch 240/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0372e-05 - accuracy: 1.0000\n","Epoch 241/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9135e-05 - accuracy: 1.0000\n","Epoch 242/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8637e-05 - accuracy: 1.0000\n","Epoch 243/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7596e-05 - accuracy: 1.0000\n","Epoch 244/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7293e-05 - accuracy: 1.0000\n","Epoch 245/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7969e-05 - accuracy: 1.0000\n","Epoch 246/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5896e-05 - accuracy: 1.0000\n","Epoch 247/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5630e-05 - accuracy: 1.0000\n","Epoch 248/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4715e-05 - accuracy: 1.0000\n","Epoch 249/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4333e-05 - accuracy: 1.0000\n","Epoch 250/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3212e-05 - accuracy: 1.0000\n","Epoch 251/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3140e-05 - accuracy: 1.0000\n","Epoch 252/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3225e-05 - accuracy: 1.0000\n","Epoch 253/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4058e-05 - accuracy: 1.0000\n","Epoch 254/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2135e-05 - accuracy: 1.0000\n","Epoch 255/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1220e-05 - accuracy: 1.0000\n","Epoch 256/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0186e-05 - accuracy: 1.0000\n","Epoch 257/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0749e-05 - accuracy: 1.0000\n","Epoch 258/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9081e-05 - accuracy: 1.0000\n","Epoch 259/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9033e-05 - accuracy: 1.0000\n","Epoch 260/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8205e-05 - accuracy: 1.0000\n","Epoch 261/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8271e-05 - accuracy: 1.0000\n","Epoch 262/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8242e-05 - accuracy: 1.0000\n","Epoch 263/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7547e-05 - accuracy: 1.0000\n","Epoch 264/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6950e-05 - accuracy: 1.0000\n","Epoch 265/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6400e-05 - accuracy: 1.0000\n","Epoch 266/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5487e-05 - accuracy: 1.0000\n","Epoch 267/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6132e-05 - accuracy: 1.0000\n","Epoch 268/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4769e-05 - accuracy: 1.0000\n","Epoch 269/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4512e-05 - accuracy: 1.0000\n","Epoch 270/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4415e-05 - accuracy: 1.0000\n","Epoch 271/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3719e-05 - accuracy: 1.0000\n","Epoch 272/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3565e-05 - accuracy: 1.0000\n","Epoch 273/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3510e-05 - accuracy: 1.0000\n","Epoch 274/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2412e-05 - accuracy: 1.0000\n","Epoch 275/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2942e-05 - accuracy: 1.0000\n","Epoch 276/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2630e-05 - accuracy: 1.0000\n","Epoch 277/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1922e-05 - accuracy: 1.0000\n","Epoch 278/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1310e-05 - accuracy: 1.0000\n","Epoch 279/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1580e-05 - accuracy: 1.0000\n","Epoch 280/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.1541e-05 - accuracy: 1.0000\n","Epoch 281/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0088e-05 - accuracy: 1.0000\n","Epoch 282/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0094e-05 - accuracy: 1.0000\n","Epoch 283/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9687e-05 - accuracy: 1.0000\n","Epoch 284/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0044e-05 - accuracy: 1.0000\n","Epoch 285/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9821e-05 - accuracy: 1.0000\n","Epoch 286/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9902e-05 - accuracy: 1.0000\n","Epoch 287/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9043e-05 - accuracy: 1.0000\n","Epoch 288/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8622e-05 - accuracy: 1.0000\n","Epoch 289/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8083e-05 - accuracy: 1.0000\n","Epoch 290/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7737e-05 - accuracy: 1.0000\n","Epoch 291/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8453e-05 - accuracy: 1.0000\n","Epoch 292/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7582e-05 - accuracy: 1.0000\n","Epoch 293/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6788e-05 - accuracy: 1.0000\n","Epoch 294/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6611e-05 - accuracy: 1.0000\n","Epoch 295/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6331e-05 - accuracy: 1.0000\n","Epoch 296/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6346e-05 - accuracy: 1.0000\n","Epoch 297/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5817e-05 - accuracy: 1.0000\n","Epoch 298/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6110e-05 - accuracy: 1.0000\n","Epoch 299/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5051e-05 - accuracy: 1.0000\n","Epoch 300/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5522e-05 - accuracy: 1.0000\n","Epoch 301/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5122e-05 - accuracy: 1.0000\n","Epoch 302/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4713e-05 - accuracy: 1.0000\n","Epoch 303/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4472e-05 - accuracy: 1.0000\n","Epoch 304/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4111e-05 - accuracy: 1.0000\n","Epoch 305/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3649e-05 - accuracy: 1.0000\n","Epoch 306/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3537e-05 - accuracy: 1.0000\n","Epoch 307/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3599e-05 - accuracy: 1.0000\n","Epoch 308/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3400e-05 - accuracy: 1.0000\n","Epoch 309/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3232e-05 - accuracy: 1.0000\n","Epoch 310/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2745e-05 - accuracy: 1.0000\n","Epoch 311/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2944e-05 - accuracy: 1.0000\n","Epoch 312/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2433e-05 - accuracy: 1.0000\n","Epoch 313/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2266e-05 - accuracy: 1.0000\n","Epoch 314/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2067e-05 - accuracy: 1.0000\n","Epoch 315/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1836e-05 - accuracy: 1.0000\n","Epoch 316/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2211e-05 - accuracy: 1.0000\n","Epoch 317/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.1208e-05 - accuracy: 1.0000\n","Epoch 318/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1342e-05 - accuracy: 1.0000\n","Epoch 319/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1112e-05 - accuracy: 1.0000\n","Epoch 320/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0984e-05 - accuracy: 1.0000\n","Epoch 321/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0587e-05 - accuracy: 1.0000\n","Epoch 322/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0695e-05 - accuracy: 1.0000\n","Epoch 323/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0445e-05 - accuracy: 1.0000\n","Epoch 324/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0301e-05 - accuracy: 1.0000\n","Epoch 325/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0094e-05 - accuracy: 1.0000\n","Epoch 326/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0030e-05 - accuracy: 1.0000\n","Epoch 327/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7972e-06 - accuracy: 1.0000\n","Epoch 328/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6794e-06 - accuracy: 1.0000\n","Epoch 329/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5230e-06 - accuracy: 1.0000\n","Epoch 330/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4850e-06 - accuracy: 1.0000\n","Epoch 331/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1044e-06 - accuracy: 1.0000\n","Epoch 332/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8687e-06 - accuracy: 1.0000\n","Epoch 333/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0149e-06 - accuracy: 1.0000\n","Epoch 334/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7708e-06 - accuracy: 1.0000\n","Epoch 335/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8480e-06 - accuracy: 1.0000\n","Epoch 336/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6102e-06 - accuracy: 1.0000\n","Epoch 337/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5638e-06 - accuracy: 1.0000\n","Epoch 338/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3074e-06 - accuracy: 1.0000\n","Epoch 339/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3292e-06 - accuracy: 1.0000\n","Epoch 340/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2103e-06 - accuracy: 1.0000\n","Epoch 341/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1730e-06 - accuracy: 1.0000\n","Epoch 342/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9354e-06 - accuracy: 1.0000\n","Epoch 343/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6412e-06 - accuracy: 1.0000\n","Epoch 344/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6119e-06 - accuracy: 1.0000\n","Epoch 345/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5953e-06 - accuracy: 1.0000\n","Epoch 346/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5673e-06 - accuracy: 1.0000\n","Epoch 347/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2487e-06 - accuracy: 1.0000\n","Epoch 348/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1409e-06 - accuracy: 1.0000\n","Epoch 349/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8437e-06 - accuracy: 1.0000\n","Epoch 350/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8646e-06 - accuracy: 1.0000\n","Epoch 351/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7382e-06 - accuracy: 1.0000\n","Epoch 352/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7129e-06 - accuracy: 1.0000\n","Epoch 353/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6180e-06 - accuracy: 1.0000\n","Epoch 354/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5805e-06 - accuracy: 1.0000\n","Epoch 355/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3986e-06 - accuracy: 1.0000\n","Epoch 356/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2448e-06 - accuracy: 1.0000\n","Epoch 357/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1170e-06 - accuracy: 1.0000\n","Epoch 358/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2069e-06 - accuracy: 1.0000\n","Epoch 359/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1531e-06 - accuracy: 1.0000\n","Epoch 360/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0100e-06 - accuracy: 1.0000\n","Epoch 361/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6773e-06 - accuracy: 1.0000\n","Epoch 362/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8148e-06 - accuracy: 1.0000\n","Epoch 363/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7200e-06 - accuracy: 1.0000\n","Epoch 364/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5701e-06 - accuracy: 1.0000\n","Epoch 365/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5947e-06 - accuracy: 1.0000\n","Epoch 366/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4985e-06 - accuracy: 1.0000\n","Epoch 367/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3038e-06 - accuracy: 1.0000\n","Epoch 368/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2555e-06 - accuracy: 1.0000\n","Epoch 369/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0508e-06 - accuracy: 1.0000\n","Epoch 370/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1016e-06 - accuracy: 1.0000\n","Epoch 371/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9550e-06 - accuracy: 1.0000\n","Epoch 372/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9387e-06 - accuracy: 1.0000\n","Epoch 373/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0990e-06 - accuracy: 1.0000\n","Epoch 374/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7868e-06 - accuracy: 1.0000\n","Epoch 375/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7162e-06 - accuracy: 1.0000\n","Epoch 376/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6535e-06 - accuracy: 1.0000\n","Epoch 377/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5671e-06 - accuracy: 1.0000\n","Epoch 378/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5432e-06 - accuracy: 1.0000\n","Epoch 379/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4483e-06 - accuracy: 1.0000\n","Epoch 380/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5647e-06 - accuracy: 1.0000\n","Epoch 381/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3153e-06 - accuracy: 1.0000\n","Epoch 382/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2716e-06 - accuracy: 1.0000\n","Epoch 383/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1533e-06 - accuracy: 1.0000\n","Epoch 384/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1410e-06 - accuracy: 1.0000\n","Epoch 385/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1424e-06 - accuracy: 1.0000\n","Epoch 386/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0251e-06 - accuracy: 1.0000\n","Epoch 387/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9381e-06 - accuracy: 1.0000\n","Epoch 388/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8566e-06 - accuracy: 1.0000\n","Epoch 389/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8074e-06 - accuracy: 1.0000\n","Epoch 390/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.8230e-06 - accuracy: 1.0000\n","Epoch 391/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6407e-06 - accuracy: 1.0000\n","Epoch 392/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7447e-06 - accuracy: 1.0000\n","Epoch 393/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7717e-06 - accuracy: 1.0000\n","Epoch 394/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4932e-06 - accuracy: 1.0000\n","Epoch 395/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4135e-06 - accuracy: 1.0000\n","Epoch 396/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4826e-06 - accuracy: 1.0000\n","Epoch 397/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4156e-06 - accuracy: 1.0000\n","Epoch 398/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2950e-06 - accuracy: 1.0000\n","Epoch 399/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4138e-06 - accuracy: 1.0000\n","Epoch 400/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3492e-06 - accuracy: 1.0000\n","Epoch 401/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2104e-06 - accuracy: 1.0000\n","Epoch 402/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1914e-06 - accuracy: 1.0000\n","Epoch 403/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1404e-06 - accuracy: 1.0000\n","Epoch 404/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0999e-06 - accuracy: 1.0000\n","Epoch 405/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9525e-06 - accuracy: 1.0000\n","Epoch 406/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9386e-06 - accuracy: 1.0000\n","Epoch 407/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9437e-06 - accuracy: 1.0000\n","Epoch 408/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8621e-06 - accuracy: 1.0000\n","Epoch 409/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7984e-06 - accuracy: 1.0000\n","Epoch 410/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7945e-06 - accuracy: 1.0000\n","Epoch 411/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7558e-06 - accuracy: 1.0000\n","Epoch 412/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6815e-06 - accuracy: 1.0000\n","Epoch 413/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6317e-06 - accuracy: 1.0000\n","Epoch 414/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6251e-06 - accuracy: 1.0000\n","Epoch 415/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5929e-06 - accuracy: 1.0000\n","Epoch 416/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6070e-06 - accuracy: 1.0000\n","Epoch 417/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5161e-06 - accuracy: 1.0000\n","Epoch 418/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4229e-06 - accuracy: 1.0000\n","Epoch 419/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4455e-06 - accuracy: 1.0000\n","Epoch 420/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4307e-06 - accuracy: 1.0000\n","Epoch 421/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3494e-06 - accuracy: 1.0000\n","Epoch 422/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2890e-06 - accuracy: 1.0000\n","Epoch 423/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2908e-06 - accuracy: 1.0000\n","Epoch 424/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2286e-06 - accuracy: 1.0000\n","Epoch 425/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2850e-06 - accuracy: 1.0000\n","Epoch 426/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2886e-06 - accuracy: 1.0000\n","Epoch 427/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.1723e-06 - accuracy: 1.0000\n","Epoch 428/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1310e-06 - accuracy: 1.0000\n","Epoch 429/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1850e-06 - accuracy: 1.0000\n","Epoch 430/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0683e-06 - accuracy: 1.0000\n","Epoch 431/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0122e-06 - accuracy: 1.0000\n","Epoch 432/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0030e-06 - accuracy: 1.0000\n","Epoch 433/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9760e-06 - accuracy: 1.0000\n","Epoch 434/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9184e-06 - accuracy: 1.0000\n","Epoch 435/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9498e-06 - accuracy: 1.0000\n","Epoch 436/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8442e-06 - accuracy: 1.0000\n","Epoch 437/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9424e-06 - accuracy: 1.0000\n","Epoch 438/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8701e-06 - accuracy: 1.0000\n","Epoch 439/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8062e-06 - accuracy: 1.0000\n","Epoch 440/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7440e-06 - accuracy: 1.0000\n","Epoch 441/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7640e-06 - accuracy: 1.0000\n","Epoch 442/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7306e-06 - accuracy: 1.0000\n","Epoch 443/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6928e-06 - accuracy: 1.0000\n","Epoch 444/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6497e-06 - accuracy: 1.0000\n","Epoch 445/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6543e-06 - accuracy: 1.0000\n","Epoch 446/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6021e-06 - accuracy: 1.0000\n","Epoch 447/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6057e-06 - accuracy: 1.0000\n","Epoch 448/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5537e-06 - accuracy: 1.0000\n","Epoch 449/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5518e-06 - accuracy: 1.0000\n","Epoch 450/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5391e-06 - accuracy: 1.0000\n","Epoch 451/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4888e-06 - accuracy: 1.0000\n","Epoch 452/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.4718e-06 - accuracy: 1.0000\n","Epoch 453/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4574e-06 - accuracy: 1.0000\n","Epoch 454/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4801e-06 - accuracy: 1.0000\n","Epoch 455/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4449e-06 - accuracy: 1.0000\n","Epoch 456/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3664e-06 - accuracy: 1.0000\n","Epoch 457/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3832e-06 - accuracy: 1.0000\n","Epoch 458/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3434e-06 - accuracy: 1.0000\n","Epoch 459/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3408e-06 - accuracy: 1.0000\n","Epoch 460/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3132e-06 - accuracy: 1.0000\n","Epoch 461/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2801e-06 - accuracy: 1.0000\n","Epoch 462/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2643e-06 - accuracy: 1.0000\n","Epoch 463/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2850e-06 - accuracy: 1.0000\n","Epoch 464/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2604e-06 - accuracy: 1.0000\n","Epoch 465/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2161e-06 - accuracy: 1.0000\n","Epoch 466/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1999e-06 - accuracy: 1.0000\n","Epoch 467/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1749e-06 - accuracy: 1.0000\n","Epoch 468/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1595e-06 - accuracy: 1.0000\n","Epoch 469/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1535e-06 - accuracy: 1.0000\n","Epoch 470/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1572e-06 - accuracy: 1.0000\n","Epoch 471/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1270e-06 - accuracy: 1.0000\n","Epoch 472/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0871e-06 - accuracy: 1.0000\n","Epoch 473/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1020e-06 - accuracy: 1.0000\n","Epoch 474/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0605e-06 - accuracy: 1.0000\n","Epoch 475/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0721e-06 - accuracy: 1.0000\n","Epoch 476/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0193e-06 - accuracy: 1.0000\n","Epoch 477/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0156e-06 - accuracy: 1.0000\n","Epoch 478/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0041e-06 - accuracy: 1.0000\n","Epoch 479/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7740e-07 - accuracy: 1.0000\n","Epoch 480/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7293e-07 - accuracy: 1.0000\n","Epoch 481/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7723e-07 - accuracy: 1.0000\n","Epoch 482/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8106e-07 - accuracy: 1.0000\n","Epoch 483/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4600e-07 - accuracy: 1.0000\n","Epoch 484/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4062e-07 - accuracy: 1.0000\n","Epoch 485/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0285e-07 - accuracy: 1.0000\n","Epoch 486/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9846e-07 - accuracy: 1.0000\n","Epoch 487/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8083e-07 - accuracy: 1.0000\n","Epoch 488/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7211e-07 - accuracy: 1.0000\n","Epoch 489/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5585e-07 - accuracy: 1.0000\n","Epoch 490/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5860e-07 - accuracy: 1.0000\n","Epoch 491/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2799e-07 - accuracy: 1.0000\n","Epoch 492/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2085e-07 - accuracy: 1.0000\n","Epoch 493/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9946e-07 - accuracy: 1.0000\n","Epoch 494/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0487e-07 - accuracy: 1.0000\n","Epoch 495/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8761e-07 - accuracy: 1.0000\n","Epoch 496/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6923e-07 - accuracy: 1.0000\n","Epoch 497/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5914e-07 - accuracy: 1.0000\n","Epoch 498/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4543e-07 - accuracy: 1.0000\n","Epoch 499/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4821e-07 - accuracy: 1.0000\n","Epoch 500/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2367e-07 - accuracy: 1.0000\n","Epoch 501/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1899e-07 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1737e-07 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0288e-07 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8527e-07 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7968e-07 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7293e-07 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5203e-07 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3621e-07 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3447e-07 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1819e-07 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2582e-07 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0185e-07 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0284e-07 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8365e-07 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7917e-07 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8287e-07 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6249e-07 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6196e-07 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4731e-07 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3608e-07 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3442e-07 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2744e-07 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2497e-07 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1310e-07 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0378e-07 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9637e-07 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8202e-07 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8476e-07 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7757e-07 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5936e-07 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6195e-07 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4939e-07 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4745e-07 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3737e-07 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3422e-07 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2665e-07 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2240e-07 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3506e-07 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2673e-07 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1323e-07 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0275e-07 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8864e-07 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8102e-07 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7414e-07 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7148e-07 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6536e-07 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6023e-07 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6408e-07 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6547e-07 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4651e-07 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3730e-07 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3517e-07 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3350e-07 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2979e-07 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2882e-07 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1701e-07 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2103e-07 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0785e-07 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0272e-07 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0551e-07 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8774e-07 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9459e-07 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8747e-07 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7861e-07 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7422e-07 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6892e-07 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6522e-07 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6194e-07 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5880e-07 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5454e-07 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5492e-07 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4995e-07 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4668e-07 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4334e-07 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3696e-07 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.3169e-07 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3236e-07 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2822e-07 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3103e-07 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2083e-07 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1416e-07 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1408e-07 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0961e-07 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0669e-07 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0545e-07 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0077e-07 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9869e-07 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9675e-07 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9265e-07 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9072e-07 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9019e-07 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8313e-07 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8429e-07 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7939e-07 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7545e-07 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7525e-07 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7053e-07 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6925e-07 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6640e-07 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6341e-07 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.6426e-07 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6967e-07 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5983e-07 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5362e-07 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5434e-07 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5121e-07 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5254e-07 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4605e-07 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4505e-07 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4224e-07 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4130e-07 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3953e-07 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.3385e-07 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3976e-07 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3202e-07 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3241e-07 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2912e-07 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2712e-07 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2482e-07 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2285e-07 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2216e-07 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1948e-07 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1930e-07 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1633e-07 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1547e-07 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1862e-07 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1146e-07 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0926e-07 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0952e-07 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0676e-07 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0571e-07 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0404e-07 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0377e-07 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0462e-07 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0121e-07 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9326e-08 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5805e-08 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6596e-08 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4454e-08 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2407e-08 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1953e-08 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2104e-08 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9370e-08 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9027e-08 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8237e-08 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5037e-08 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3520e-08 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3541e-08 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3289e-08 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0394e-08 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0554e-08 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9266e-08 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8341e-08 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5943e-08 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6404e-08 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4819e-08 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3413e-08 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3475e-08 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0865e-08 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0261e-08 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0261e-08 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8656e-08 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7782e-08 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6256e-08 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6251e-08 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5085e-08 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4415e-08 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4241e-08 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2426e-08 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1134e-08 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1360e-08 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9827e-08 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9385e-08 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7938e-08 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7177e-08 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6330e-08 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6365e-08 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4352e-08 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4918e-08 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3354e-08 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3096e-08 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2185e-08 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2329e-08 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0567e-08 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0790e-08 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9378e-08 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8432e-08 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7846e-08 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7474e-08 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7538e-08 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6280e-08 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6291e-08 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5735e-08 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4691e-08 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3818e-08 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3170e-08 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2963e-08 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4330e-08 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2309e-08 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1032e-08 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0378e-08 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9727e-08 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9409e-08 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8539e-08 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8633e-08 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7919e-08 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7011e-08 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6511e-08 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6119e-08 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5536e-08 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5530e-08 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4800e-08 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4363e-08 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4054e-08 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3856e-08 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3342e-08 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2354e-08 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2214e-08 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2216e-08 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1430e-08 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1086e-08 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1070e-08 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0331e-08 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9753e-08 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9713e-08 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.8463e-08 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8391e-08 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8471e-08 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8329e-08 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7686e-08 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6921e-08 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7072e-08 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7011e-08 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6383e-08 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5884e-08 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5380e-08 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5024e-08 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4793e-08 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4372e-08 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4717e-08 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4001e-08 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3973e-08 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3272e-08 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2978e-08 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2821e-08 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2337e-08 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2042e-08 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1878e-08 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1091e-08 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1132e-08 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0913e-08 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0667e-08 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0388e-08 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0065e-08 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9849e-08 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9623e-08 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9347e-08 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9081e-08 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8789e-08 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8613e-08 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8452e-08 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8648e-08 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.8058e-08 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7766e-08 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7653e-08 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7243e-08 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7103e-08 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6595e-08 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6563e-08 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6392e-08 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6353e-08 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6046e-08 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5779e-08 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6006e-08 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5234e-08 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5271e-08 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5189e-08 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5027e-08 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4611e-08 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4405e-08 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4105e-08 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4225e-08 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3839e-08 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3808e-08 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3692e-08 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3343e-08 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3390e-08 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2915e-08 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2998e-08 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2980e-08 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2500e-08 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2331e-08 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2245e-08 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2132e-08 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1912e-08 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1702e-08 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1613e-08 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1373e-08 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1371e-08 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1089e-08 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0960e-08 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0992e-08 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0960e-08 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0764e-08 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0743e-08 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0543e-08 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0257e-08 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0234e-08 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0051e-08 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0078e-08 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8374e-09 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6259e-09 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5342e-09 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4675e-09 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4073e-09 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2550e-09 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3680e-09 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1087e-09 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4444e-09 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1404e-09 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7804e-09 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8108e-09 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9090e-09 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3214e-09 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2194e-09 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0795e-09 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1006e-09 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0184e-09 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9370e-09 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8503e-09 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6755e-09 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5725e-09 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5259e-09 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4276e-09 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3998e-09 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2955e-09 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2700e-09 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2478e-09 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0436e-09 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9481e-09 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8593e-09 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8077e-09 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6251e-09 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7000e-09 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4722e-09 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5123e-09 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8126e-09 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3808e-09 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2989e-09 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2831e-09 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1363e-09 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0647e-09 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0350e-09 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8370e-09 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8556e-09 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8122e-09 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7388e-09 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6977e-09 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6215e-09 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5193e-09 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4872e-09 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4062e-09 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3478e-09 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2789e-09 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2501e-09 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1758e-09 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2413e-09 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1072e-09 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9930e-09 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9142e-09 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9225e-09 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8202e-09 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8856e-09 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7988e-09 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7754e-09 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 4.7182e-09 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6295e-09 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5474e-09 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5235e-09 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4532e-09 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4164e-09 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3399e-09 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3309e-09 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2834e-09 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2315e-09 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2208e-09 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1552e-09 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1134e-09 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0754e-09 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0106e-09 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9589e-09 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9379e-09 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9314e-09 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9116e-09 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9172e-09 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7833e-09 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7453e-09 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8088e-09 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7066e-09 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6665e-09 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6329e-09 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6287e-09 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5855e-09 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5145e-09 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4856e-09 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4509e-09 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4358e-09 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4364e-09 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3818e-09 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3635e-09 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3451e-09 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.2945e-09 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2658e-09 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1797e-09 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1913e-09 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1956e-09 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1262e-09 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1454e-09 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1526e-09 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0673e-09 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0436e-09 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0519e-09 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8954e-09 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9967e-09 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9011e-09 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9340e-09 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8841e-09 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8517e-09 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7966e-09 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7885e-09 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7963e-09 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7645e-09 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8816e-09 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6794e-09 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6983e-09 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6847e-09 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6474e-09 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6340e-09 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6158e-09 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5609e-09 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5302e-09 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5531e-09 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5415e-09 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5208e-09 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4695e-09 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4427e-09 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4535e-09 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4002e-09 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4104e-09 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4204e-09 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3541e-09 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4168e-09 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3217e-09 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3326e-09 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2973e-09 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3055e-09 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2704e-09 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2503e-09 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2284e-09 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1181e-09 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2000e-09 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1974e-09 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1807e-09 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1202e-09 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1565e-09 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1363e-09 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1364e-09 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0807e-09 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1003e-09 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0601e-09 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0715e-09 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0605e-09 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0760e-09 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0431e-09 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.0104e-09 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9988e-09 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9911e-09 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9452e-09 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9396e-09 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9637e-09 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8944e-09 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9079e-09 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8948e-09 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9114e-09 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8991e-09 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8315e-09 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8831e-09 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8532e-09 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8530e-09 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8373e-09 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8486e-09 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8126e-09 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8151e-09 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8218e-09 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7362e-09 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7996e-09 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7828e-09 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7331e-09 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7335e-09 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7428e-09 - accuracy: 1.0000\n"]}],"source":["\n","\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Define a function to create the neural network model\n","def create_model():\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(128, input_dim = features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(256, input_dim = features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(8, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Initialize lists to store accuracy scores\n","accuracy_scores = []\n","\n","# Iterate through each fold of cross-validation\n","for train_index, test_index in skf.split(features, target):\n","    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n","    y_train, y_test = target[train_index], target[test_index]\n","\n","    # Create the neural network model\n","    model = create_model()\n","\n","    # Fit the model on the training data\n","    model.fit(X_train, y_train, epochs=1000, batch_size=128, verbose=1)\n","\n","    # Evaluate the model on the test data\n","    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","    # Store the accuracy score\n","    accuracy_scores.append(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412908,"status":"ok","timestamp":1713819201481,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"mFsB2aaifdM_","outputId":"9676f12f-3f9c-40a7-e918-dab3b96ba23a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6894e-07 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5983e-07 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4798e-07 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4929e-07 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3227e-07 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2819e-07 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1445e-07 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1118e-07 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0275e-07 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0280e-07 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9063e-07 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9214e-07 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8992e-07 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8071e-07 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6313e-07 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5665e-07 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5514e-07 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4735e-07 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3851e-07 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3303e-07 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2266e-07 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2660e-07 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2063e-07 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0535e-07 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9679e-07 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9163e-07 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8835e-07 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8208e-07 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7755e-07 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8596e-07 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7009e-07 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5855e-07 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5692e-07 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4977e-07 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4699e-07 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4027e-07 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4151e-07 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3641e-07 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3109e-07 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2027e-07 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1838e-07 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1208e-07 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0835e-07 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0584e-07 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0467e-07 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.9469e-07 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9344e-07 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8751e-07 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8330e-07 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8212e-07 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7699e-07 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7205e-07 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6721e-07 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6437e-07 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5942e-07 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5924e-07 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5404e-07 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4715e-07 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4279e-07 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4361e-07 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4383e-07 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3795e-07 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3852e-07 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2882e-07 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2994e-07 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2200e-07 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1923e-07 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1801e-07 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1539e-07 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1119e-07 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0748e-07 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0397e-07 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0339e-07 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9930e-07 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0340e-07 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9465e-07 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9088e-07 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8735e-07 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8587e-07 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8273e-07 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8000e-07 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7781e-07 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7440e-07 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7167e-07 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7136e-07 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6636e-07 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6548e-07 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6313e-07 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6079e-07 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5989e-07 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5768e-07 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5313e-07 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5302e-07 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5240e-07 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5350e-07 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4858e-07 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4878e-07 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4237e-07 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3878e-07 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3843e-07 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3489e-07 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3397e-07 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3333e-07 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3003e-07 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2749e-07 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2712e-07 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2542e-07 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2633e-07 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2205e-07 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2255e-07 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1749e-07 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1739e-07 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1719e-07 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1356e-07 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1161e-07 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0992e-07 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0876e-07 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0660e-07 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0626e-07 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0333e-07 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0170e-07 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0072e-07 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0076e-07 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9125e-08 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7382e-08 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4714e-08 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8025e-08 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6792e-08 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3178e-08 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9979e-08 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8754e-08 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8089e-08 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6133e-08 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5721e-08 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4711e-08 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2360e-08 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2147e-08 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1930e-08 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0967e-08 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9484e-08 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7827e-08 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7145e-08 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6319e-08 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3739e-08 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3110e-08 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2664e-08 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1144e-08 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0570e-08 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9617e-08 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9624e-08 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7718e-08 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6636e-08 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6020e-08 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6189e-08 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4258e-08 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3494e-08 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2755e-08 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1064e-08 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1760e-08 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9958e-08 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0911e-08 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8682e-08 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7210e-08 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7015e-08 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5523e-08 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4675e-08 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4386e-08 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4942e-08 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3970e-08 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3097e-08 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2845e-08 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0647e-08 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0174e-08 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9464e-08 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9358e-08 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7932e-08 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7459e-08 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7206e-08 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6184e-08 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6032e-08 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5758e-08 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4600e-08 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3867e-08 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3879e-08 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2719e-08 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2543e-08 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1768e-08 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0543e-08 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0788e-08 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9892e-08 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8910e-08 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0045e-08 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8531e-08 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7684e-08 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7342e-08 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6799e-08 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.6312e-08 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5971e-08 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5167e-08 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4822e-08 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4472e-08 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3701e-08 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3530e-08 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3277e-08 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2713e-08 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2315e-08 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1932e-08 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1128e-08 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1069e-08 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.0425e-08 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0357e-08 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9681e-08 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9213e-08 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9573e-08 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8807e-08 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7988e-08 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7936e-08 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7771e-08 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6983e-08 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7019e-08 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6473e-08 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6225e-08 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5836e-08 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5409e-08 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.5325e-08 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4728e-08 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5219e-08 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4228e-08 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4515e-08 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3030e-08 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3702e-08 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2797e-08 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3230e-08 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.2765e-08 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2624e-08 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1849e-08 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1289e-08 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1303e-08 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1185e-08 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0867e-08 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1077e-08 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0401e-08 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9879e-08 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9353e-08 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9384e-08 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8995e-08 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8643e-08 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8655e-08 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8536e-08 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8572e-08 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8213e-08 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7550e-08 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7291e-08 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7257e-08 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6958e-08 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6675e-08 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6535e-08 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6432e-08 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6571e-08 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5998e-08 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5735e-08 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5504e-08 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5439e-08 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5099e-08 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4897e-08 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4787e-08 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4526e-08 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4665e-08 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4244e-08 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4031e-08 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3755e-08 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3784e-08 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3562e-08 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3366e-08 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3496e-08 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2816e-08 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2768e-08 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2607e-08 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2532e-08 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2364e-08 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2363e-08 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2291e-08 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1867e-08 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1746e-08 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1659e-08 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1444e-08 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1486e-08 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1226e-08 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1222e-08 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0934e-08 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0843e-08 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0840e-08 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0658e-08 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0394e-08 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0310e-08 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.0318e-08 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0161e-08 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9181e-09 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7674e-09 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9605e-09 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6274e-09 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5255e-09 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3054e-09 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2955e-09 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0560e-09 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1226e-09 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8699e-09 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8131e-09 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6790e-09 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6774e-09 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5064e-09 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5759e-09 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2830e-09 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3103e-09 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0897e-09 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0698e-09 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0189e-09 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8062e-09 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7351e-09 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6942e-09 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5802e-09 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4619e-09 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5670e-09 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3088e-09 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1982e-09 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0561e-09 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1958e-09 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9319e-09 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8514e-09 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8546e-09 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7439e-09 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7174e-09 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5796e-09 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5073e-09 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5044e-09 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4165e-09 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4404e-09 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2817e-09 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2793e-09 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1302e-09 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1473e-09 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0112e-09 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8764e-09 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1094e-09 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9228e-09 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7089e-09 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6649e-09 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6028e-09 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5891e-09 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4430e-09 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4146e-09 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3073e-09 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3377e-09 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3668e-09 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2045e-09 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1437e-09 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1097e-09 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0593e-09 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0256e-09 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9102e-09 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9361e-09 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9305e-09 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7019e-09 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7448e-09 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6771e-09 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5968e-09 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6005e-09 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5724e-09 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5492e-09 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4924e-09 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4046e-09 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3390e-09 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3282e-09 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2510e-09 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2383e-09 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2107e-09 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2202e-09 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0178e-09 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1272e-09 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0655e-09 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9954e-09 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9747e-09 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9263e-09 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9821e-09 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.8271e-09 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8175e-09 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8026e-09 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8190e-09 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7349e-09 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6834e-09 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6122e-09 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6235e-09 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5903e-09 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5885e-09 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4693e-09 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4431e-09 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4391e-09 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3857e-09 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3885e-09 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3452e-09 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3517e-09 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3120e-09 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2929e-09 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2692e-09 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2247e-09 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2014e-09 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1962e-09 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0768e-09 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1158e-09 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0879e-09 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0932e-09 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9668e-09 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0470e-09 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9760e-09 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9725e-09 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9341e-09 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9284e-09 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8888e-09 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8672e-09 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8346e-09 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8538e-09 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8290e-09 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7807e-09 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7472e-09 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7149e-09 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6907e-09 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7204e-09 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6764e-09 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6596e-09 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6476e-09 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5799e-09 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6061e-09 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5437e-09 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5892e-09 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5549e-09 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5131e-09 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5000e-09 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4692e-09 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4110e-09 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4865e-09 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4016e-09 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4122e-09 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3919e-09 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3921e-09 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3234e-09 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3527e-09 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3813e-09 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.3279e-09 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3174e-09 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2949e-09 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2697e-09 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2792e-09 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2450e-09 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2193e-09 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2743e-09 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2008e-09 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2080e-09 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1284e-09 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1638e-09 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1130e-09 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1471e-09 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1375e-09 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0584e-09 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0799e-09 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0776e-09 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0779e-09 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0375e-09 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0719e-09 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0057e-09 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0226e-09 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9249e-09 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9499e-09 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9716e-09 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9331e-09 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9126e-09 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9573e-09 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9322e-09 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9326e-09 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9052e-09 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8791e-09 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8809e-09 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8640e-09 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8884e-09 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8582e-09 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8342e-09 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8459e-09 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8585e-09 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8260e-09 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8098e-09 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8359e-09 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7496e-09 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8025e-09 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7318e-09 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7858e-09 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7873e-09 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7666e-09 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7762e-09 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7454e-09 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6620e-09 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7518e-09 - accuracy: 1.0000\n","Epoch 1/1000\n","25/25 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8000\n","Epoch 2/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8669\n","Epoch 3/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8853\n","Epoch 4/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8941\n","Epoch 5/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9047\n","Epoch 6/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9134\n","Epoch 7/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.9137\n","Epoch 8/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9241\n","Epoch 9/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9219\n","Epoch 10/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9262\n","Epoch 11/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9278\n","Epoch 12/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9369\n","Epoch 13/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9372\n","Epoch 14/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9428\n","Epoch 15/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9416\n","Epoch 16/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9494\n","Epoch 17/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9466\n","Epoch 18/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9538\n","Epoch 19/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9581\n","Epoch 20/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9600\n","Epoch 21/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9563\n","Epoch 22/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9591\n","Epoch 23/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9578\n","Epoch 24/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9669\n","Epoch 25/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9663\n","Epoch 26/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9638\n","Epoch 27/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9666\n","Epoch 28/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9719\n","Epoch 29/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9691\n","Epoch 30/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9672\n","Epoch 31/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9747\n","Epoch 32/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9772\n","Epoch 33/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9778\n","Epoch 34/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9712\n","Epoch 35/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9666\n","Epoch 36/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9756\n","Epoch 37/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9794\n","Epoch 38/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9778\n","Epoch 39/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9825\n","Epoch 40/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9841\n","Epoch 41/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9853\n","Epoch 42/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9812\n","Epoch 43/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9797\n","Epoch 44/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9797\n","Epoch 45/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9853\n","Epoch 46/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9853\n","Epoch 47/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9894\n","Epoch 48/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9878\n","Epoch 49/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9862\n","Epoch 50/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9881\n","Epoch 51/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9850\n","Epoch 52/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9875\n","Epoch 53/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9881\n","Epoch 54/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9872\n","Epoch 55/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9834\n","Epoch 56/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9881\n","Epoch 57/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9928\n","Epoch 58/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9916\n","Epoch 59/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9941\n","Epoch 60/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9950\n","Epoch 61/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9975\n","Epoch 62/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9969\n","Epoch 63/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9972\n","Epoch 64/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9975\n","Epoch 65/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9981\n","Epoch 66/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9978\n","Epoch 67/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9991\n","Epoch 68/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9991\n","Epoch 69/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9944\n","Epoch 70/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9928\n","Epoch 71/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9937\n","Epoch 72/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9941\n","Epoch 73/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9906\n","Epoch 74/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9847\n","Epoch 75/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9791\n","Epoch 76/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9784\n","Epoch 77/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9881\n","Epoch 78/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9947\n","Epoch 79/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9947\n","Epoch 80/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9969\n","Epoch 81/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9991\n","Epoch 82/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9981\n","Epoch 83/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9991\n","Epoch 84/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9984\n","Epoch 85/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9991\n","Epoch 86/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991\n","Epoch 87/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991\n","Epoch 88/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991\n","Epoch 89/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991\n","Epoch 90/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9969\n","Epoch 91/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9969\n","Epoch 92/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9947\n","Epoch 93/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9916\n","Epoch 94/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9934\n","Epoch 95/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9937\n","Epoch 96/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9950\n","Epoch 97/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9987\n","Epoch 98/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9981\n","Epoch 99/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9978\n","Epoch 100/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9997\n","Epoch 101/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 102/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 103/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 104/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 105/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5639e-04 - accuracy: 1.0000\n","Epoch 106/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9843e-04 - accuracy: 1.0000\n","Epoch 107/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3467e-04 - accuracy: 1.0000\n","Epoch 108/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0750e-04 - accuracy: 1.0000\n","Epoch 109/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1853e-04 - accuracy: 1.0000\n","Epoch 110/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9353e-04 - accuracy: 1.0000\n","Epoch 111/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6192e-04 - accuracy: 1.0000\n","Epoch 112/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5916e-04 - accuracy: 1.0000\n","Epoch 113/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7638e-04 - accuracy: 1.0000\n","Epoch 114/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9656e-04 - accuracy: 1.0000\n","Epoch 115/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9283e-04 - accuracy: 1.0000\n","Epoch 116/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5296e-04 - accuracy: 1.0000\n","Epoch 117/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2775e-04 - accuracy: 1.0000\n","Epoch 118/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1286e-04 - accuracy: 1.0000\n","Epoch 119/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0979e-04 - accuracy: 1.0000\n","Epoch 120/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0590e-04 - accuracy: 1.0000\n","Epoch 121/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9678e-04 - accuracy: 1.0000\n","Epoch 122/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3204e-04 - accuracy: 1.0000\n","Epoch 123/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2065e-04 - accuracy: 1.0000\n","Epoch 124/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1633e-04 - accuracy: 1.0000\n","Epoch 125/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9929e-04 - accuracy: 1.0000\n","Epoch 126/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8483e-04 - accuracy: 1.0000\n","Epoch 127/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7036e-04 - accuracy: 1.0000\n","Epoch 128/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6314e-04 - accuracy: 1.0000\n","Epoch 129/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6165e-04 - accuracy: 1.0000\n","Epoch 130/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4247e-04 - accuracy: 1.0000\n","Epoch 131/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3684e-04 - accuracy: 1.0000\n","Epoch 132/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2343e-04 - accuracy: 1.0000\n","Epoch 133/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1162e-04 - accuracy: 1.0000\n","Epoch 134/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3727e-04 - accuracy: 1.0000\n","Epoch 135/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9449e-04 - accuracy: 1.0000\n","Epoch 136/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8794e-04 - accuracy: 1.0000\n","Epoch 137/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7199e-04 - accuracy: 1.0000\n","Epoch 138/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8275e-04 - accuracy: 1.0000\n","Epoch 139/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6426e-04 - accuracy: 1.0000\n","Epoch 140/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5531e-04 - accuracy: 1.0000\n","Epoch 141/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4938e-04 - accuracy: 1.0000\n","Epoch 142/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4504e-04 - accuracy: 1.0000\n","Epoch 143/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.3295e-04 - accuracy: 1.0000\n","Epoch 144/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3035e-04 - accuracy: 1.0000\n","Epoch 145/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2519e-04 - accuracy: 1.0000\n","Epoch 146/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2106e-04 - accuracy: 1.0000\n","Epoch 147/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1778e-04 - accuracy: 1.0000\n","Epoch 148/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1172e-04 - accuracy: 1.0000\n","Epoch 149/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0870e-04 - accuracy: 1.0000\n","Epoch 150/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0012e-04 - accuracy: 1.0000\n","Epoch 151/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9661e-04 - accuracy: 1.0000\n","Epoch 152/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9089e-04 - accuracy: 1.0000\n","Epoch 153/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8789e-04 - accuracy: 1.0000\n","Epoch 154/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9068e-04 - accuracy: 1.0000\n","Epoch 155/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8035e-04 - accuracy: 1.0000\n","Epoch 156/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7699e-04 - accuracy: 1.0000\n","Epoch 157/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7125e-04 - accuracy: 1.0000\n","Epoch 158/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6559e-04 - accuracy: 1.0000\n","Epoch 159/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6559e-04 - accuracy: 1.0000\n","Epoch 160/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6118e-04 - accuracy: 1.0000\n","Epoch 161/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5612e-04 - accuracy: 1.0000\n","Epoch 162/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4862e-04 - accuracy: 1.0000\n","Epoch 163/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4823e-04 - accuracy: 1.0000\n","Epoch 164/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4986e-04 - accuracy: 1.0000\n","Epoch 165/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4098e-04 - accuracy: 1.0000\n","Epoch 166/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3676e-04 - accuracy: 1.0000\n","Epoch 167/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.3421e-04 - accuracy: 1.0000\n","Epoch 168/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2714e-04 - accuracy: 1.0000\n","Epoch 169/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2717e-04 - accuracy: 1.0000\n","Epoch 170/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2807e-04 - accuracy: 1.0000\n","Epoch 171/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2446e-04 - accuracy: 1.0000\n","Epoch 172/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2235e-04 - accuracy: 1.0000\n","Epoch 173/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1515e-04 - accuracy: 1.0000\n","Epoch 174/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1366e-04 - accuracy: 1.0000\n","Epoch 175/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0963e-04 - accuracy: 1.0000\n","Epoch 176/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0923e-04 - accuracy: 1.0000\n","Epoch 177/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0820e-04 - accuracy: 1.0000\n","Epoch 178/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0674e-04 - accuracy: 1.0000\n","Epoch 179/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0322e-04 - accuracy: 1.0000\n","Epoch 180/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0169e-04 - accuracy: 1.0000\n","Epoch 181/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9468e-05 - accuracy: 1.0000\n","Epoch 182/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6267e-05 - accuracy: 1.0000\n","Epoch 183/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5502e-05 - accuracy: 1.0000\n","Epoch 184/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2368e-05 - accuracy: 1.0000\n","Epoch 185/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9752e-05 - accuracy: 1.0000\n","Epoch 186/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8007e-05 - accuracy: 1.0000\n","Epoch 187/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7062e-05 - accuracy: 1.0000\n","Epoch 188/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8622e-05 - accuracy: 1.0000\n","Epoch 189/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5799e-05 - accuracy: 1.0000\n","Epoch 190/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5610e-05 - accuracy: 1.0000\n","Epoch 191/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2295e-05 - accuracy: 1.0000\n","Epoch 192/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8782e-05 - accuracy: 1.0000\n","Epoch 193/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7499e-05 - accuracy: 1.0000\n","Epoch 194/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5643e-05 - accuracy: 1.0000\n","Epoch 195/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3221e-05 - accuracy: 1.0000\n","Epoch 196/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2472e-05 - accuracy: 1.0000\n","Epoch 197/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3267e-05 - accuracy: 1.0000\n","Epoch 198/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0199e-05 - accuracy: 1.0000\n","Epoch 199/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8694e-05 - accuracy: 1.0000\n","Epoch 200/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7345e-05 - accuracy: 1.0000\n","Epoch 201/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6127e-05 - accuracy: 1.0000\n","Epoch 202/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5262e-05 - accuracy: 1.0000\n","Epoch 203/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2570e-05 - accuracy: 1.0000\n","Epoch 204/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2683e-05 - accuracy: 1.0000\n","Epoch 205/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0378e-05 - accuracy: 1.0000\n","Epoch 206/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9205e-05 - accuracy: 1.0000\n","Epoch 207/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8298e-05 - accuracy: 1.0000\n","Epoch 208/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6887e-05 - accuracy: 1.0000\n","Epoch 209/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5970e-05 - accuracy: 1.0000\n","Epoch 210/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5578e-05 - accuracy: 1.0000\n","Epoch 211/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4687e-05 - accuracy: 1.0000\n","Epoch 212/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4814e-05 - accuracy: 1.0000\n","Epoch 213/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1966e-05 - accuracy: 1.0000\n","Epoch 214/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1178e-05 - accuracy: 1.0000\n","Epoch 215/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0383e-05 - accuracy: 1.0000\n","Epoch 216/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9685e-05 - accuracy: 1.0000\n","Epoch 217/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8131e-05 - accuracy: 1.0000\n","Epoch 218/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8103e-05 - accuracy: 1.0000\n","Epoch 219/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8928e-05 - accuracy: 1.0000\n","Epoch 220/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7140e-05 - accuracy: 1.0000\n","Epoch 221/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7830e-05 - accuracy: 1.0000\n","Epoch 222/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4193e-05 - accuracy: 1.0000\n","Epoch 223/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3874e-05 - accuracy: 1.0000\n","Epoch 224/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2815e-05 - accuracy: 1.0000\n","Epoch 225/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1201e-05 - accuracy: 1.0000\n","Epoch 226/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0447e-05 - accuracy: 1.0000\n","Epoch 227/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9604e-05 - accuracy: 1.0000\n","Epoch 228/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9452e-05 - accuracy: 1.0000\n","Epoch 229/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8376e-05 - accuracy: 1.0000\n","Epoch 230/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7920e-05 - accuracy: 1.0000\n","Epoch 231/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.7606e-05 - accuracy: 1.0000\n","Epoch 232/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6938e-05 - accuracy: 1.0000\n","Epoch 233/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6422e-05 - accuracy: 1.0000\n","Epoch 234/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4975e-05 - accuracy: 1.0000\n","Epoch 235/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4469e-05 - accuracy: 1.0000\n","Epoch 236/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4088e-05 - accuracy: 1.0000\n","Epoch 237/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3620e-05 - accuracy: 1.0000\n","Epoch 238/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3045e-05 - accuracy: 1.0000\n","Epoch 239/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3379e-05 - accuracy: 1.0000\n","Epoch 240/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2903e-05 - accuracy: 1.0000\n","Epoch 241/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1568e-05 - accuracy: 1.0000\n","Epoch 242/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1124e-05 - accuracy: 1.0000\n","Epoch 243/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9843e-05 - accuracy: 1.0000\n","Epoch 244/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9339e-05 - accuracy: 1.0000\n","Epoch 245/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8893e-05 - accuracy: 1.0000\n","Epoch 246/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8459e-05 - accuracy: 1.0000\n","Epoch 247/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8284e-05 - accuracy: 1.0000\n","Epoch 248/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7464e-05 - accuracy: 1.0000\n","Epoch 249/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7250e-05 - accuracy: 1.0000\n","Epoch 250/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7257e-05 - accuracy: 1.0000\n","Epoch 251/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7217e-05 - accuracy: 1.0000\n","Epoch 252/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6457e-05 - accuracy: 1.0000\n","Epoch 253/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6123e-05 - accuracy: 1.0000\n","Epoch 254/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4724e-05 - accuracy: 1.0000\n","Epoch 255/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3993e-05 - accuracy: 1.0000\n","Epoch 256/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3728e-05 - accuracy: 1.0000\n","Epoch 257/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3229e-05 - accuracy: 1.0000\n","Epoch 258/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3004e-05 - accuracy: 1.0000\n","Epoch 259/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2477e-05 - accuracy: 1.0000\n","Epoch 260/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2609e-05 - accuracy: 1.0000\n","Epoch 261/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2663e-05 - accuracy: 1.0000\n","Epoch 262/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1496e-05 - accuracy: 1.0000\n","Epoch 263/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1067e-05 - accuracy: 1.0000\n","Epoch 264/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0857e-05 - accuracy: 1.0000\n","Epoch 265/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0423e-05 - accuracy: 1.0000\n","Epoch 266/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0030e-05 - accuracy: 1.0000\n","Epoch 267/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0511e-05 - accuracy: 1.0000\n","Epoch 268/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9495e-05 - accuracy: 1.0000\n","Epoch 269/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8891e-05 - accuracy: 1.0000\n","Epoch 270/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8533e-05 - accuracy: 1.0000\n","Epoch 271/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8222e-05 - accuracy: 1.0000\n","Epoch 272/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7942e-05 - accuracy: 1.0000\n","Epoch 273/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7809e-05 - accuracy: 1.0000\n","Epoch 274/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7313e-05 - accuracy: 1.0000\n","Epoch 275/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7095e-05 - accuracy: 1.0000\n","Epoch 276/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7062e-05 - accuracy: 1.0000\n","Epoch 277/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7244e-05 - accuracy: 1.0000\n","Epoch 278/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6322e-05 - accuracy: 1.0000\n","Epoch 279/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5959e-05 - accuracy: 1.0000\n","Epoch 280/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6432e-05 - accuracy: 1.0000\n","Epoch 281/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5489e-05 - accuracy: 1.0000\n","Epoch 282/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.5127e-05 - accuracy: 1.0000\n","Epoch 283/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4808e-05 - accuracy: 1.0000\n","Epoch 284/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4993e-05 - accuracy: 1.0000\n","Epoch 285/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4351e-05 - accuracy: 1.0000\n","Epoch 286/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4346e-05 - accuracy: 1.0000\n","Epoch 287/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3743e-05 - accuracy: 1.0000\n","Epoch 288/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3693e-05 - accuracy: 1.0000\n","Epoch 289/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3483e-05 - accuracy: 1.0000\n","Epoch 290/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3284e-05 - accuracy: 1.0000\n","Epoch 291/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3215e-05 - accuracy: 1.0000\n","Epoch 292/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3073e-05 - accuracy: 1.0000\n","Epoch 293/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2722e-05 - accuracy: 1.0000\n","Epoch 294/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2751e-05 - accuracy: 1.0000\n","Epoch 295/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2267e-05 - accuracy: 1.0000\n","Epoch 296/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2139e-05 - accuracy: 1.0000\n","Epoch 297/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1898e-05 - accuracy: 1.0000\n","Epoch 298/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1613e-05 - accuracy: 1.0000\n","Epoch 299/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1404e-05 - accuracy: 1.0000\n","Epoch 300/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1144e-05 - accuracy: 1.0000\n","Epoch 301/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1153e-05 - accuracy: 1.0000\n","Epoch 302/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0818e-05 - accuracy: 1.0000\n","Epoch 303/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0753e-05 - accuracy: 1.0000\n","Epoch 304/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0625e-05 - accuracy: 1.0000\n","Epoch 305/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0310e-05 - accuracy: 1.0000\n","Epoch 306/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0202e-05 - accuracy: 1.0000\n","Epoch 307/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0311e-05 - accuracy: 1.0000\n","Epoch 308/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0001e-05 - accuracy: 1.0000\n","Epoch 309/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6969e-06 - accuracy: 1.0000\n","Epoch 310/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5477e-06 - accuracy: 1.0000\n","Epoch 311/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4039e-06 - accuracy: 1.0000\n","Epoch 312/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2338e-06 - accuracy: 1.0000\n","Epoch 313/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1567e-06 - accuracy: 1.0000\n","Epoch 314/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0723e-06 - accuracy: 1.0000\n","Epoch 315/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7641e-06 - accuracy: 1.0000\n","Epoch 316/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6092e-06 - accuracy: 1.0000\n","Epoch 317/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5378e-06 - accuracy: 1.0000\n","Epoch 318/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4085e-06 - accuracy: 1.0000\n","Epoch 319/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 8.2948e-06 - accuracy: 1.0000\n","Epoch 320/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3682e-06 - accuracy: 1.0000\n","Epoch 321/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0913e-06 - accuracy: 1.0000\n","Epoch 322/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8621e-06 - accuracy: 1.0000\n","Epoch 323/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6974e-06 - accuracy: 1.0000\n","Epoch 324/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4903e-06 - accuracy: 1.0000\n","Epoch 325/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4164e-06 - accuracy: 1.0000\n","Epoch 326/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3005e-06 - accuracy: 1.0000\n","Epoch 327/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2763e-06 - accuracy: 1.0000\n","Epoch 328/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1693e-06 - accuracy: 1.0000\n","Epoch 329/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9681e-06 - accuracy: 1.0000\n","Epoch 330/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9570e-06 - accuracy: 1.0000\n","Epoch 331/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8266e-06 - accuracy: 1.0000\n","Epoch 332/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7322e-06 - accuracy: 1.0000\n","Epoch 333/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5569e-06 - accuracy: 1.0000\n","Epoch 334/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5642e-06 - accuracy: 1.0000\n","Epoch 335/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5113e-06 - accuracy: 1.0000\n","Epoch 336/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2858e-06 - accuracy: 1.0000\n","Epoch 337/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1767e-06 - accuracy: 1.0000\n","Epoch 338/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2225e-06 - accuracy: 1.0000\n","Epoch 339/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0151e-06 - accuracy: 1.0000\n","Epoch 340/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9612e-06 - accuracy: 1.0000\n","Epoch 341/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8292e-06 - accuracy: 1.0000\n","Epoch 342/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6378e-06 - accuracy: 1.0000\n","Epoch 343/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5311e-06 - accuracy: 1.0000\n","Epoch 344/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.4381e-06 - accuracy: 1.0000\n","Epoch 345/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3948e-06 - accuracy: 1.0000\n","Epoch 346/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3052e-06 - accuracy: 1.0000\n","Epoch 347/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1714e-06 - accuracy: 1.0000\n","Epoch 348/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1769e-06 - accuracy: 1.0000\n","Epoch 349/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0464e-06 - accuracy: 1.0000\n","Epoch 350/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0349e-06 - accuracy: 1.0000\n","Epoch 351/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8849e-06 - accuracy: 1.0000\n","Epoch 352/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8058e-06 - accuracy: 1.0000\n","Epoch 353/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7058e-06 - accuracy: 1.0000\n","Epoch 354/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7232e-06 - accuracy: 1.0000\n","Epoch 355/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6683e-06 - accuracy: 1.0000\n","Epoch 356/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6864e-06 - accuracy: 1.0000\n","Epoch 357/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5909e-06 - accuracy: 1.0000\n","Epoch 358/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6123e-06 - accuracy: 1.0000\n","Epoch 359/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4097e-06 - accuracy: 1.0000\n","Epoch 360/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3198e-06 - accuracy: 1.0000\n","Epoch 361/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1877e-06 - accuracy: 1.0000\n","Epoch 362/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1692e-06 - accuracy: 1.0000\n","Epoch 363/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0710e-06 - accuracy: 1.0000\n","Epoch 364/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0696e-06 - accuracy: 1.0000\n","Epoch 365/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9814e-06 - accuracy: 1.0000\n","Epoch 366/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9505e-06 - accuracy: 1.0000\n","Epoch 367/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8500e-06 - accuracy: 1.0000\n","Epoch 368/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7778e-06 - accuracy: 1.0000\n","Epoch 369/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7072e-06 - accuracy: 1.0000\n","Epoch 370/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6255e-06 - accuracy: 1.0000\n","Epoch 371/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6657e-06 - accuracy: 1.0000\n","Epoch 372/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5485e-06 - accuracy: 1.0000\n","Epoch 373/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5394e-06 - accuracy: 1.0000\n","Epoch 374/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6049e-06 - accuracy: 1.0000\n","Epoch 375/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3362e-06 - accuracy: 1.0000\n","Epoch 376/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3214e-06 - accuracy: 1.0000\n","Epoch 377/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3266e-06 - accuracy: 1.0000\n","Epoch 378/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2131e-06 - accuracy: 1.0000\n","Epoch 379/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1382e-06 - accuracy: 1.0000\n","Epoch 380/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0968e-06 - accuracy: 1.0000\n","Epoch 381/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0848e-06 - accuracy: 1.0000\n","Epoch 382/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1083e-06 - accuracy: 1.0000\n","Epoch 383/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9715e-06 - accuracy: 1.0000\n","Epoch 384/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9377e-06 - accuracy: 1.0000\n","Epoch 385/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8718e-06 - accuracy: 1.0000\n","Epoch 386/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9198e-06 - accuracy: 1.0000\n","Epoch 387/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8048e-06 - accuracy: 1.0000\n","Epoch 388/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7746e-06 - accuracy: 1.0000\n","Epoch 389/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7659e-06 - accuracy: 1.0000\n","Epoch 390/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7082e-06 - accuracy: 1.0000\n","Epoch 391/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6966e-06 - accuracy: 1.0000\n","Epoch 392/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5769e-06 - accuracy: 1.0000\n","Epoch 393/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5404e-06 - accuracy: 1.0000\n","Epoch 394/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5518e-06 - accuracy: 1.0000\n","Epoch 395/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6545e-06 - accuracy: 1.0000\n","Epoch 396/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4737e-06 - accuracy: 1.0000\n","Epoch 397/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4369e-06 - accuracy: 1.0000\n","Epoch 398/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4019e-06 - accuracy: 1.0000\n","Epoch 399/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3381e-06 - accuracy: 1.0000\n","Epoch 400/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2911e-06 - accuracy: 1.0000\n","Epoch 401/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2389e-06 - accuracy: 1.0000\n","Epoch 402/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2390e-06 - accuracy: 1.0000\n","Epoch 403/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2669e-06 - accuracy: 1.0000\n","Epoch 404/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2131e-06 - accuracy: 1.0000\n","Epoch 405/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1102e-06 - accuracy: 1.0000\n","Epoch 406/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0982e-06 - accuracy: 1.0000\n","Epoch 407/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0736e-06 - accuracy: 1.0000\n","Epoch 408/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0338e-06 - accuracy: 1.0000\n","Epoch 409/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9967e-06 - accuracy: 1.0000\n","Epoch 410/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9556e-06 - accuracy: 1.0000\n","Epoch 411/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9556e-06 - accuracy: 1.0000\n","Epoch 412/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9026e-06 - accuracy: 1.0000\n","Epoch 413/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8812e-06 - accuracy: 1.0000\n","Epoch 414/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8442e-06 - accuracy: 1.0000\n","Epoch 415/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8113e-06 - accuracy: 1.0000\n","Epoch 416/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7864e-06 - accuracy: 1.0000\n","Epoch 417/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7486e-06 - accuracy: 1.0000\n","Epoch 418/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7841e-06 - accuracy: 1.0000\n","Epoch 419/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7611e-06 - accuracy: 1.0000\n","Epoch 420/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6917e-06 - accuracy: 1.0000\n","Epoch 421/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6317e-06 - accuracy: 1.0000\n","Epoch 422/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6342e-06 - accuracy: 1.0000\n","Epoch 423/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6255e-06 - accuracy: 1.0000\n","Epoch 424/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5686e-06 - accuracy: 1.0000\n","Epoch 425/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5710e-06 - accuracy: 1.0000\n","Epoch 426/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5181e-06 - accuracy: 1.0000\n","Epoch 427/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4910e-06 - accuracy: 1.0000\n","Epoch 428/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4645e-06 - accuracy: 1.0000\n","Epoch 429/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4529e-06 - accuracy: 1.0000\n","Epoch 430/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4356e-06 - accuracy: 1.0000\n","Epoch 431/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3903e-06 - accuracy: 1.0000\n","Epoch 432/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3854e-06 - accuracy: 1.0000\n","Epoch 433/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3418e-06 - accuracy: 1.0000\n","Epoch 434/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3335e-06 - accuracy: 1.0000\n","Epoch 435/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3127e-06 - accuracy: 1.0000\n","Epoch 436/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3054e-06 - accuracy: 1.0000\n","Epoch 437/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2782e-06 - accuracy: 1.0000\n","Epoch 438/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2616e-06 - accuracy: 1.0000\n","Epoch 439/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2455e-06 - accuracy: 1.0000\n","Epoch 440/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2046e-06 - accuracy: 1.0000\n","Epoch 441/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1946e-06 - accuracy: 1.0000\n","Epoch 442/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1981e-06 - accuracy: 1.0000\n","Epoch 443/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1653e-06 - accuracy: 1.0000\n","Epoch 444/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1361e-06 - accuracy: 1.0000\n","Epoch 445/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1251e-06 - accuracy: 1.0000\n","Epoch 446/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.1058e-06 - accuracy: 1.0000\n","Epoch 447/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0734e-06 - accuracy: 1.0000\n","Epoch 448/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0813e-06 - accuracy: 1.0000\n","Epoch 449/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0607e-06 - accuracy: 1.0000\n","Epoch 450/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0315e-06 - accuracy: 1.0000\n","Epoch 451/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0202e-06 - accuracy: 1.0000\n","Epoch 452/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9859e-07 - accuracy: 1.0000\n","Epoch 453/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0319e-06 - accuracy: 1.0000\n","Epoch 454/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8781e-07 - accuracy: 1.0000\n","Epoch 455/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6834e-07 - accuracy: 1.0000\n","Epoch 456/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5278e-07 - accuracy: 1.0000\n","Epoch 457/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5935e-07 - accuracy: 1.0000\n","Epoch 458/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2753e-07 - accuracy: 1.0000\n","Epoch 459/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9753e-07 - accuracy: 1.0000\n","Epoch 460/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9104e-07 - accuracy: 1.0000\n","Epoch 461/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8728e-07 - accuracy: 1.0000\n","Epoch 462/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6366e-07 - accuracy: 1.0000\n","Epoch 463/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5857e-07 - accuracy: 1.0000\n","Epoch 464/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3773e-07 - accuracy: 1.0000\n","Epoch 465/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3304e-07 - accuracy: 1.0000\n","Epoch 466/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2021e-07 - accuracy: 1.0000\n","Epoch 467/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9076e-07 - accuracy: 1.0000\n","Epoch 468/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9563e-07 - accuracy: 1.0000\n","Epoch 469/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9767e-07 - accuracy: 1.0000\n","Epoch 470/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 7.7078e-07 - accuracy: 1.0000\n","Epoch 471/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6386e-07 - accuracy: 1.0000\n","Epoch 472/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4149e-07 - accuracy: 1.0000\n","Epoch 473/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3800e-07 - accuracy: 1.0000\n","Epoch 474/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1683e-07 - accuracy: 1.0000\n","Epoch 475/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1474e-07 - accuracy: 1.0000\n","Epoch 476/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9706e-07 - accuracy: 1.0000\n","Epoch 477/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9839e-07 - accuracy: 1.0000\n","Epoch 478/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8444e-07 - accuracy: 1.0000\n","Epoch 479/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8698e-07 - accuracy: 1.0000\n","Epoch 480/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6902e-07 - accuracy: 1.0000\n","Epoch 481/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8825e-07 - accuracy: 1.0000\n","Epoch 482/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4150e-07 - accuracy: 1.0000\n","Epoch 483/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5071e-07 - accuracy: 1.0000\n","Epoch 484/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2176e-07 - accuracy: 1.0000\n","Epoch 485/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1632e-07 - accuracy: 1.0000\n","Epoch 486/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0481e-07 - accuracy: 1.0000\n","Epoch 487/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9928e-07 - accuracy: 1.0000\n","Epoch 488/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9672e-07 - accuracy: 1.0000\n","Epoch 489/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7605e-07 - accuracy: 1.0000\n","Epoch 490/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7365e-07 - accuracy: 1.0000\n","Epoch 491/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6349e-07 - accuracy: 1.0000\n","Epoch 492/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5477e-07 - accuracy: 1.0000\n","Epoch 493/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4065e-07 - accuracy: 1.0000\n","Epoch 494/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3570e-07 - accuracy: 1.0000\n","Epoch 495/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2324e-07 - accuracy: 1.0000\n","Epoch 496/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1689e-07 - accuracy: 1.0000\n","Epoch 497/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2585e-07 - accuracy: 1.0000\n","Epoch 498/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0101e-07 - accuracy: 1.0000\n","Epoch 499/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0711e-07 - accuracy: 1.0000\n","Epoch 500/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9187e-07 - accuracy: 1.0000\n","Epoch 501/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7763e-07 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7643e-07 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8651e-07 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7344e-07 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6021e-07 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5710e-07 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4428e-07 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3511e-07 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2706e-07 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2296e-07 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1923e-07 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0745e-07 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9728e-07 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9592e-07 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9128e-07 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8546e-07 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8487e-07 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7353e-07 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7381e-07 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6136e-07 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5986e-07 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5337e-07 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5243e-07 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5266e-07 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3930e-07 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4287e-07 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4312e-07 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3741e-07 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2014e-07 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1695e-07 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1491e-07 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0340e-07 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.0197e-07 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9763e-07 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9363e-07 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9136e-07 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8409e-07 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8116e-07 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7616e-07 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7122e-07 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7040e-07 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6642e-07 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6682e-07 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5665e-07 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5710e-07 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5074e-07 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4501e-07 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4223e-07 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3899e-07 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3461e-07 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3193e-07 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2709e-07 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4215e-07 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1874e-07 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1780e-07 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1416e-07 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1140e-07 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1303e-07 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0501e-07 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0191e-07 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0154e-07 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9602e-07 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9687e-07 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9067e-07 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8977e-07 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8859e-07 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8540e-07 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7820e-07 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7759e-07 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7409e-07 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7465e-07 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7091e-07 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7014e-07 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6612e-07 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6503e-07 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6476e-07 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6405e-07 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5711e-07 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5362e-07 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5561e-07 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4989e-07 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4678e-07 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4660e-07 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4446e-07 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4138e-07 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3938e-07 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3632e-07 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3564e-07 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3326e-07 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3250e-07 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3195e-07 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2846e-07 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2764e-07 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2674e-07 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2385e-07 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2183e-07 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2024e-07 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1817e-07 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1612e-07 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1545e-07 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1487e-07 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1203e-07 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1182e-07 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0730e-07 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0831e-07 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0845e-07 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0715e-07 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0187e-07 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0303e-07 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0141e-07 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7753e-08 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8382e-08 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5776e-08 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4041e-08 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3777e-08 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3170e-08 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3662e-08 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8171e-08 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6741e-08 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5383e-08 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4651e-08 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 8.4497e-08 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2518e-08 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1188e-08 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2050e-08 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1127e-08 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8584e-08 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8920e-08 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4854e-08 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4658e-08 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4600e-08 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2752e-08 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1847e-08 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0455e-08 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9133e-08 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9471e-08 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7667e-08 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7497e-08 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5324e-08 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5175e-08 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3596e-08 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4104e-08 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2074e-08 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2184e-08 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1238e-08 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0373e-08 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9007e-08 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8999e-08 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7270e-08 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7072e-08 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5926e-08 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6199e-08 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4702e-08 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5315e-08 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3550e-08 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2896e-08 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1203e-08 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0822e-08 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9827e-08 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0307e-08 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9353e-08 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7972e-08 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7496e-08 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7399e-08 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5753e-08 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5589e-08 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5170e-08 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3606e-08 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3612e-08 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4040e-08 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2891e-08 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1515e-08 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1213e-08 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1103e-08 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2384e-08 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9717e-08 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9355e-08 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9102e-08 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8296e-08 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7566e-08 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7696e-08 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6419e-08 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6585e-08 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5586e-08 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.5644e-08 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5438e-08 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4684e-08 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3776e-08 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3342e-08 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2963e-08 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3115e-08 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3282e-08 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1887e-08 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1859e-08 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1063e-08 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0787e-08 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0287e-08 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0053e-08 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9529e-08 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9086e-08 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8886e-08 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8298e-08 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7821e-08 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8294e-08 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7924e-08 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6577e-08 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6590e-08 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6558e-08 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6123e-08 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6681e-08 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5302e-08 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4832e-08 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4715e-08 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4834e-08 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3836e-08 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3940e-08 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3730e-08 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3462e-08 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2757e-08 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2356e-08 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2083e-08 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1673e-08 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1290e-08 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1508e-08 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0881e-08 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0775e-08 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0707e-08 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0229e-08 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9985e-08 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0129e-08 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9660e-08 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9297e-08 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9145e-08 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8705e-08 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8652e-08 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8693e-08 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8849e-08 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8267e-08 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7734e-08 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7603e-08 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7078e-08 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7263e-08 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6955e-08 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6826e-08 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6460e-08 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6277e-08 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6113e-08 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6092e-08 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5705e-08 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5539e-08 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5600e-08 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5038e-08 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4924e-08 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4741e-08 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4442e-08 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4317e-08 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3998e-08 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3963e-08 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3918e-08 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3536e-08 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3875e-08 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3266e-08 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3157e-08 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3461e-08 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3206e-08 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2730e-08 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2622e-08 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2322e-08 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2519e-08 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2278e-08 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1901e-08 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1854e-08 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1576e-08 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1818e-08 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1291e-08 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1488e-08 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1122e-08 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0976e-08 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0929e-08 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0767e-08 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0649e-08 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0516e-08 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0512e-08 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0359e-08 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0181e-08 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9519e-09 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9559e-09 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6734e-09 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8425e-09 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4699e-09 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4776e-09 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3170e-09 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2893e-09 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1545e-09 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1410e-09 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0296e-09 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9243e-09 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8648e-09 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 8.7508e-09 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7371e-09 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5704e-09 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3644e-09 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4049e-09 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4215e-09 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1293e-09 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0865e-09 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9533e-09 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8328e-09 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7564e-09 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7131e-09 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6846e-09 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5326e-09 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4987e-09 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3659e-09 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3126e-09 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2141e-09 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2823e-09 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0371e-09 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9809e-09 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9010e-09 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8425e-09 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8062e-09 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6760e-09 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5458e-09 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4883e-09 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4937e-09 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5258e-09 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2767e-09 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3176e-09 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1368e-09 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1473e-09 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0802e-09 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1220e-09 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0811e-09 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8623e-09 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9034e-09 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.7833e-09 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7065e-09 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6812e-09 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5082e-09 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5613e-09 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5503e-09 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4135e-09 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3346e-09 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2830e-09 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2002e-09 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1674e-09 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0867e-09 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1559e-09 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0945e-09 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9986e-09 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9373e-09 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9889e-09 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8210e-09 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7300e-09 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7862e-09 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7614e-09 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6294e-09 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5622e-09 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5517e-09 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5306e-09 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4205e-09 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3682e-09 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3634e-09 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3206e-09 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3167e-09 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2736e-09 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2042e-09 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1551e-09 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1418e-09 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1293e-09 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0362e-09 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0271e-09 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9411e-09 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9621e-09 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9884e-09 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9998e-09 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9338e-09 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8201e-09 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7262e-09 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7385e-09 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6522e-09 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6375e-09 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6215e-09 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6483e-09 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5729e-09 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6226e-09 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4528e-09 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5118e-09 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4514e-09 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3727e-09 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3489e-09 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3000e-09 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3104e-09 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3065e-09 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3005e-09 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2587e-09 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1894e-09 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1719e-09 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1698e-09 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1522e-09 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1141e-09 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0476e-09 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0518e-09 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0396e-09 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9566e-09 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9770e-09 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9299e-09 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8642e-09 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9016e-09 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9104e-09 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8437e-09 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8485e-09 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7771e-09 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8573e-09 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8164e-09 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8734e-09 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7206e-09 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7035e-09 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6431e-09 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6380e-09 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6153e-09 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6276e-09 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5779e-09 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.5465e-09 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5338e-09 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5090e-09 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4964e-09 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4867e-09 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4428e-09 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4494e-09 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4496e-09 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3994e-09 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4014e-09 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3606e-09 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4359e-09 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2851e-09 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3726e-09 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3520e-09 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2735e-09 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2795e-09 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2734e-09 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2592e-09 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2638e-09 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2538e-09 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2266e-09 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2068e-09 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2019e-09 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2075e-09 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1745e-09 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1193e-09 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1081e-09 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1266e-09 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1189e-09 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1132e-09 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0842e-09 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0673e-09 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0903e-09 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0466e-09 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0857e-09 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0151e-09 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0309e-09 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9893e-09 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9921e-09 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9361e-09 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9771e-09 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9887e-09 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9376e-09 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9026e-09 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9183e-09 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9474e-09 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9036e-09 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8922e-09 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8211e-09 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8559e-09 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8753e-09 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8298e-09 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8358e-09 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8406e-09 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8216e-09 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8601e-09 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8325e-09 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8260e-09 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8193e-09 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7673e-09 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8245e-09 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7194e-09 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.7748e-09 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7351e-09 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7752e-09 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7893e-09 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6975e-09 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7180e-09 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7265e-09 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7000e-09 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7217e-09 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6623e-09 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6510e-09 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6607e-09 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6856e-09 - accuracy: 1.0000\n","Epoch 1/1000\n","25/25 [==============================] - 1s 3ms/step - loss: 0.5620 - accuracy: 0.6884\n","Epoch 2/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8666\n","Epoch 3/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8853\n","Epoch 4/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8950\n","Epoch 5/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9050\n","Epoch 6/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9091\n","Epoch 7/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9153\n","Epoch 8/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9187\n","Epoch 9/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9212\n","Epoch 10/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9253\n","Epoch 11/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9347\n","Epoch 12/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9291\n","Epoch 13/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9366\n","Epoch 14/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9416\n","Epoch 15/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9456\n","Epoch 16/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9388\n","Epoch 17/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9463\n","Epoch 18/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9475\n","Epoch 19/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9516\n","Epoch 20/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9516\n","Epoch 21/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9566\n","Epoch 22/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9572\n","Epoch 23/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9538\n","Epoch 24/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9609\n","Epoch 25/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9622\n","Epoch 26/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9638\n","Epoch 27/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9669\n","Epoch 28/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9622\n","Epoch 29/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9684\n","Epoch 30/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9753\n","Epoch 31/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9712\n","Epoch 32/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9728\n","Epoch 33/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9762\n","Epoch 34/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9691\n","Epoch 35/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9700\n","Epoch 36/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9697\n","Epoch 37/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9728\n","Epoch 38/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9737\n","Epoch 39/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9794\n","Epoch 40/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9697\n","Epoch 41/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9734\n","Epoch 42/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9794\n","Epoch 43/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9831\n","Epoch 44/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9841\n","Epoch 45/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9856\n","Epoch 46/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9859\n","Epoch 47/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9862\n","Epoch 48/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9881\n","Epoch 49/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9897\n","Epoch 50/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9869\n","Epoch 51/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9847\n","Epoch 52/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9834\n","Epoch 53/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9875\n","Epoch 54/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9887\n","Epoch 55/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9875\n","Epoch 56/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9897\n","Epoch 57/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9884\n","Epoch 58/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9900\n","Epoch 59/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9912\n","Epoch 60/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9934\n","Epoch 61/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9937\n","Epoch 62/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9941\n","Epoch 63/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9903\n","Epoch 64/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9900\n","Epoch 65/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9906\n","Epoch 66/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9931\n","Epoch 67/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9947\n","Epoch 68/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9956\n","Epoch 69/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9959\n","Epoch 70/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9947\n","Epoch 71/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9912\n","Epoch 72/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9944\n","Epoch 73/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9887\n","Epoch 74/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9841\n","Epoch 75/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9825\n","Epoch 76/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9822\n","Epoch 77/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9834\n","Epoch 78/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9853\n","Epoch 79/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9906\n","Epoch 80/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9928\n","Epoch 81/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9937\n","Epoch 82/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9953\n","Epoch 83/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9978\n","Epoch 84/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9981\n","Epoch 85/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9978\n","Epoch 86/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9987\n","Epoch 87/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9984\n","Epoch 88/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9991\n","Epoch 89/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9987\n","Epoch 90/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991\n","Epoch 91/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991\n","Epoch 92/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991\n","Epoch 93/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9991\n","Epoch 94/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991\n","Epoch 95/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9987\n","Epoch 96/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n","Epoch 97/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9987\n","Epoch 98/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987\n","Epoch 99/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991\n","Epoch 100/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9991\n","Epoch 101/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9994\n","Epoch 102/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9997\n","Epoch 103/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9994\n","Epoch 104/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991\n","Epoch 105/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9997\n","Epoch 106/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9991\n","Epoch 107/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9997\n","Epoch 108/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9994\n","Epoch 109/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9997\n","Epoch 110/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9994\n","Epoch 111/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997\n","Epoch 112/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 113/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 114/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9991\n","Epoch 115/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 116/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994\n","Epoch 117/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9987\n","Epoch 118/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9987\n","Epoch 119/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9975\n","Epoch 120/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9866\n","Epoch 121/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9684\n","Epoch 122/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9691\n","Epoch 123/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9853\n","Epoch 124/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9959\n","Epoch 125/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9978\n","Epoch 126/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9984\n","Epoch 127/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9959\n","Epoch 128/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9925\n","Epoch 129/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9941\n","Epoch 130/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9922\n","Epoch 131/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9969\n","Epoch 132/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9978\n","Epoch 133/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9997\n","Epoch 134/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9981\n","Epoch 135/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9959\n","Epoch 136/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9947\n","Epoch 137/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9978\n","Epoch 138/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991\n","Epoch 139/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9991\n","Epoch 140/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9994\n","Epoch 141/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 142/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 143/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 144/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 145/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 146/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 147/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 148/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 149/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 150/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 151/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 152/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8821e-04 - accuracy: 1.0000\n","Epoch 153/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0580e-04 - accuracy: 1.0000\n","Epoch 154/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 155/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 156/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 157/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7789e-04 - accuracy: 1.0000\n","Epoch 158/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0870e-04 - accuracy: 1.0000\n","Epoch 159/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2395e-04 - accuracy: 1.0000\n","Epoch 160/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n","Epoch 161/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n","Epoch 162/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3141e-04 - accuracy: 0.9997\n","Epoch 163/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6363e-04 - accuracy: 1.0000\n","Epoch 164/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9498e-04 - accuracy: 1.0000\n","Epoch 165/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0618e-04 - accuracy: 1.0000\n","Epoch 166/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0259e-04 - accuracy: 1.0000\n","Epoch 167/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4409e-04 - accuracy: 1.0000\n","Epoch 168/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2383e-04 - accuracy: 1.0000\n","Epoch 169/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3274e-04 - accuracy: 1.0000\n","Epoch 170/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0971e-04 - accuracy: 1.0000\n","Epoch 171/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2871e-04 - accuracy: 1.0000\n","Epoch 172/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9465e-04 - accuracy: 1.0000\n","Epoch 173/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5986e-04 - accuracy: 1.0000\n","Epoch 174/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3393e-04 - accuracy: 1.0000\n","Epoch 175/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5084e-04 - accuracy: 1.0000\n","Epoch 176/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8013e-04 - accuracy: 1.0000\n","Epoch 177/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1293e-04 - accuracy: 1.0000\n","Epoch 178/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3052e-04 - accuracy: 1.0000\n","Epoch 179/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1982e-04 - accuracy: 1.0000\n","Epoch 180/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4888e-04 - accuracy: 1.0000\n","Epoch 181/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 182/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 183/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9959\n","Epoch 184/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9853\n","Epoch 185/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9644\n","Epoch 186/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9678\n","Epoch 187/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9819\n","Epoch 188/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9931\n","Epoch 189/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9903\n","Epoch 190/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9950\n","Epoch 191/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9969\n","Epoch 192/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9987\n","Epoch 193/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9997\n","Epoch 194/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 195/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 196/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 197/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 198/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 199/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 200/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 201/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 202/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 203/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8627e-04 - accuracy: 1.0000\n","Epoch 204/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3379e-04 - accuracy: 1.0000\n","Epoch 205/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3115e-04 - accuracy: 1.0000\n","Epoch 206/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8321e-04 - accuracy: 0.9997\n","Epoch 207/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 208/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 209/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9997\n","Epoch 210/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9864e-04 - accuracy: 0.9997\n","Epoch 211/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9848e-04 - accuracy: 1.0000\n","Epoch 212/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7930e-04 - accuracy: 1.0000\n","Epoch 213/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9426e-04 - accuracy: 1.0000\n","Epoch 214/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2439e-04 - accuracy: 1.0000\n","Epoch 215/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3060e-04 - accuracy: 1.0000\n","Epoch 216/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7619e-04 - accuracy: 1.0000\n","Epoch 217/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4836e-04 - accuracy: 1.0000\n","Epoch 218/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3342e-04 - accuracy: 1.0000\n","Epoch 219/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0736e-04 - accuracy: 1.0000\n","Epoch 220/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9861e-04 - accuracy: 1.0000\n","Epoch 221/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8120e-04 - accuracy: 1.0000\n","Epoch 222/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7239e-04 - accuracy: 1.0000\n","Epoch 223/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6352e-04 - accuracy: 1.0000\n","Epoch 224/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5637e-04 - accuracy: 1.0000\n","Epoch 225/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4425e-04 - accuracy: 1.0000\n","Epoch 226/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3470e-04 - accuracy: 1.0000\n","Epoch 227/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2695e-04 - accuracy: 1.0000\n","Epoch 228/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1914e-04 - accuracy: 1.0000\n","Epoch 229/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1266e-04 - accuracy: 1.0000\n","Epoch 230/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0582e-04 - accuracy: 1.0000\n","Epoch 231/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0218e-04 - accuracy: 1.0000\n","Epoch 232/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9595e-04 - accuracy: 1.0000\n","Epoch 233/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9034e-04 - accuracy: 1.0000\n","Epoch 234/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8398e-04 - accuracy: 1.0000\n","Epoch 235/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8104e-04 - accuracy: 1.0000\n","Epoch 236/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7539e-04 - accuracy: 1.0000\n","Epoch 237/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7041e-04 - accuracy: 1.0000\n","Epoch 238/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6573e-04 - accuracy: 1.0000\n","Epoch 239/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6329e-04 - accuracy: 1.0000\n","Epoch 240/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5755e-04 - accuracy: 1.0000\n","Epoch 241/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5217e-04 - accuracy: 1.0000\n","Epoch 242/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4894e-04 - accuracy: 1.0000\n","Epoch 243/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4429e-04 - accuracy: 1.0000\n","Epoch 244/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4183e-04 - accuracy: 1.0000\n","Epoch 245/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3986e-04 - accuracy: 1.0000\n","Epoch 246/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3544e-04 - accuracy: 1.0000\n","Epoch 247/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3276e-04 - accuracy: 1.0000\n","Epoch 248/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2973e-04 - accuracy: 1.0000\n","Epoch 249/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2680e-04 - accuracy: 1.0000\n","Epoch 250/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2513e-04 - accuracy: 1.0000\n","Epoch 251/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2041e-04 - accuracy: 1.0000\n","Epoch 252/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1798e-04 - accuracy: 1.0000\n","Epoch 253/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1627e-04 - accuracy: 1.0000\n","Epoch 254/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1339e-04 - accuracy: 1.0000\n","Epoch 255/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0923e-04 - accuracy: 1.0000\n","Epoch 256/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0851e-04 - accuracy: 1.0000\n","Epoch 257/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0497e-04 - accuracy: 1.0000\n","Epoch 258/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0241e-04 - accuracy: 1.0000\n","Epoch 259/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0048e-04 - accuracy: 1.0000\n","Epoch 260/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9688e-05 - accuracy: 1.0000\n","Epoch 261/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6049e-05 - accuracy: 1.0000\n","Epoch 262/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3949e-05 - accuracy: 1.0000\n","Epoch 263/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4899e-05 - accuracy: 1.0000\n","Epoch 264/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1603e-05 - accuracy: 1.0000\n","Epoch 265/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9912e-05 - accuracy: 1.0000\n","Epoch 266/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7843e-05 - accuracy: 1.0000\n","Epoch 267/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7370e-05 - accuracy: 1.0000\n","Epoch 268/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 8.5207e-05 - accuracy: 1.0000\n","Epoch 269/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4243e-05 - accuracy: 1.0000\n","Epoch 270/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1086e-05 - accuracy: 1.0000\n","Epoch 271/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0841e-05 - accuracy: 1.0000\n","Epoch 272/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6628e-05 - accuracy: 1.0000\n","Epoch 273/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7682e-05 - accuracy: 1.0000\n","Epoch 274/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6747e-05 - accuracy: 1.0000\n","Epoch 275/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5352e-05 - accuracy: 1.0000\n","Epoch 276/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1368e-05 - accuracy: 1.0000\n","Epoch 277/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1077e-05 - accuracy: 1.0000\n","Epoch 278/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0838e-05 - accuracy: 1.0000\n","Epoch 279/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8467e-05 - accuracy: 1.0000\n","Epoch 280/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6505e-05 - accuracy: 1.0000\n","Epoch 281/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5588e-05 - accuracy: 1.0000\n","Epoch 282/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6293e-05 - accuracy: 1.0000\n","Epoch 283/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4941e-05 - accuracy: 1.0000\n","Epoch 284/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1584e-05 - accuracy: 1.0000\n","Epoch 285/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0756e-05 - accuracy: 1.0000\n","Epoch 286/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9974e-05 - accuracy: 1.0000\n","Epoch 287/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8974e-05 - accuracy: 1.0000\n","Epoch 288/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7620e-05 - accuracy: 1.0000\n","Epoch 289/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6085e-05 - accuracy: 1.0000\n","Epoch 290/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4777e-05 - accuracy: 1.0000\n","Epoch 291/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4129e-05 - accuracy: 1.0000\n","Epoch 292/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3384e-05 - accuracy: 1.0000\n","Epoch 293/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2569e-05 - accuracy: 1.0000\n","Epoch 294/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1722e-05 - accuracy: 1.0000\n","Epoch 295/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0660e-05 - accuracy: 1.0000\n","Epoch 296/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9886e-05 - accuracy: 1.0000\n","Epoch 297/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9517e-05 - accuracy: 1.0000\n","Epoch 298/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8837e-05 - accuracy: 1.0000\n","Epoch 299/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9440e-05 - accuracy: 1.0000\n","Epoch 300/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7887e-05 - accuracy: 1.0000\n","Epoch 301/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6212e-05 - accuracy: 1.0000\n","Epoch 302/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4781e-05 - accuracy: 1.0000\n","Epoch 303/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4370e-05 - accuracy: 1.0000\n","Epoch 304/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3795e-05 - accuracy: 1.0000\n","Epoch 305/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3025e-05 - accuracy: 1.0000\n","Epoch 306/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2703e-05 - accuracy: 1.0000\n","Epoch 307/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1978e-05 - accuracy: 1.0000\n","Epoch 308/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1753e-05 - accuracy: 1.0000\n","Epoch 309/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0398e-05 - accuracy: 1.0000\n","Epoch 310/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9816e-05 - accuracy: 1.0000\n","Epoch 311/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9526e-05 - accuracy: 1.0000\n","Epoch 312/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8352e-05 - accuracy: 1.0000\n","Epoch 313/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7757e-05 - accuracy: 1.0000\n","Epoch 314/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6532e-05 - accuracy: 1.0000\n","Epoch 315/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6553e-05 - accuracy: 1.0000\n","Epoch 316/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5896e-05 - accuracy: 1.0000\n","Epoch 317/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4532e-05 - accuracy: 1.0000\n","Epoch 318/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5210e-05 - accuracy: 1.0000\n","Epoch 319/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.4048e-05 - accuracy: 1.0000\n","Epoch 320/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3249e-05 - accuracy: 1.0000\n","Epoch 321/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2646e-05 - accuracy: 1.0000\n","Epoch 322/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2290e-05 - accuracy: 1.0000\n","Epoch 323/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1862e-05 - accuracy: 1.0000\n","Epoch 324/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1702e-05 - accuracy: 1.0000\n","Epoch 325/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1144e-05 - accuracy: 1.0000\n","Epoch 326/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0293e-05 - accuracy: 1.0000\n","Epoch 327/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9489e-05 - accuracy: 1.0000\n","Epoch 328/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9814e-05 - accuracy: 1.0000\n","Epoch 329/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9855e-05 - accuracy: 1.0000\n","Epoch 330/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8613e-05 - accuracy: 1.0000\n","Epoch 331/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.7841e-05 - accuracy: 1.0000\n","Epoch 332/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8082e-05 - accuracy: 1.0000\n","Epoch 333/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7802e-05 - accuracy: 1.0000\n","Epoch 334/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6220e-05 - accuracy: 1.0000\n","Epoch 335/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6665e-05 - accuracy: 1.0000\n","Epoch 336/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6681e-05 - accuracy: 1.0000\n","Epoch 337/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5772e-05 - accuracy: 1.0000\n","Epoch 338/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5525e-05 - accuracy: 1.0000\n","Epoch 339/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5208e-05 - accuracy: 1.0000\n","Epoch 340/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4273e-05 - accuracy: 1.0000\n","Epoch 341/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4758e-05 - accuracy: 1.0000\n","Epoch 342/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3913e-05 - accuracy: 1.0000\n","Epoch 343/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3313e-05 - accuracy: 1.0000\n","Epoch 344/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3969e-05 - accuracy: 1.0000\n","Epoch 345/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2920e-05 - accuracy: 1.0000\n","Epoch 346/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2730e-05 - accuracy: 1.0000\n","Epoch 347/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2545e-05 - accuracy: 1.0000\n","Epoch 348/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1710e-05 - accuracy: 1.0000\n","Epoch 349/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1181e-05 - accuracy: 1.0000\n","Epoch 350/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0841e-05 - accuracy: 1.0000\n","Epoch 351/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0538e-05 - accuracy: 1.0000\n","Epoch 352/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0067e-05 - accuracy: 1.0000\n","Epoch 353/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0106e-05 - accuracy: 1.0000\n","Epoch 354/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9999e-05 - accuracy: 1.0000\n","Epoch 355/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9537e-05 - accuracy: 1.0000\n","Epoch 356/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.9190e-05 - accuracy: 1.0000\n","Epoch 357/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8670e-05 - accuracy: 1.0000\n","Epoch 358/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8524e-05 - accuracy: 1.0000\n","Epoch 359/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8442e-05 - accuracy: 1.0000\n","Epoch 360/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7831e-05 - accuracy: 1.0000\n","Epoch 361/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7758e-05 - accuracy: 1.0000\n","Epoch 362/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7472e-05 - accuracy: 1.0000\n","Epoch 363/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6904e-05 - accuracy: 1.0000\n","Epoch 364/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7064e-05 - accuracy: 1.0000\n","Epoch 365/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6905e-05 - accuracy: 1.0000\n","Epoch 366/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6861e-05 - accuracy: 1.0000\n","Epoch 367/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6302e-05 - accuracy: 1.0000\n","Epoch 368/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6017e-05 - accuracy: 1.0000\n","Epoch 369/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5579e-05 - accuracy: 1.0000\n","Epoch 370/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5587e-05 - accuracy: 1.0000\n","Epoch 371/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5450e-05 - accuracy: 1.0000\n","Epoch 372/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5064e-05 - accuracy: 1.0000\n","Epoch 373/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5018e-05 - accuracy: 1.0000\n","Epoch 374/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4519e-05 - accuracy: 1.0000\n","Epoch 375/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4554e-05 - accuracy: 1.0000\n","Epoch 376/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4972e-05 - accuracy: 1.0000\n","Epoch 377/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5577e-05 - accuracy: 1.0000\n","Epoch 378/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 379/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.9378\n","Epoch 380/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9566\n","Epoch 381/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9812\n","Epoch 382/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9900\n","Epoch 383/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9950\n","Epoch 384/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9975\n","Epoch 385/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9966\n","Epoch 386/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9950\n","Epoch 387/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9981\n","Epoch 388/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9987\n","Epoch 389/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9994\n","Epoch 390/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9997\n","Epoch 391/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9997\n","Epoch 392/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 393/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997\n","Epoch 394/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 395/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 396/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 397/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 398/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 399/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.5021e-04 - accuracy: 1.0000\n","Epoch 400/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3077e-04 - accuracy: 1.0000\n","Epoch 401/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6794e-04 - accuracy: 1.0000\n","Epoch 402/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4971e-04 - accuracy: 1.0000\n","Epoch 403/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3475e-04 - accuracy: 1.0000\n","Epoch 404/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9541e-04 - accuracy: 1.0000\n","Epoch 405/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5716e-04 - accuracy: 1.0000\n","Epoch 406/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1448e-04 - accuracy: 1.0000\n","Epoch 407/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9334e-04 - accuracy: 1.0000\n","Epoch 408/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6562e-04 - accuracy: 1.0000\n","Epoch 409/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5861e-04 - accuracy: 1.0000\n","Epoch 410/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3464e-04 - accuracy: 1.0000\n","Epoch 411/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1723e-04 - accuracy: 1.0000\n","Epoch 412/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0288e-04 - accuracy: 1.0000\n","Epoch 413/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8675e-04 - accuracy: 1.0000\n","Epoch 414/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7710e-04 - accuracy: 1.0000\n","Epoch 415/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6784e-04 - accuracy: 1.0000\n","Epoch 416/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5381e-04 - accuracy: 1.0000\n","Epoch 417/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4099e-04 - accuracy: 1.0000\n","Epoch 418/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2730e-04 - accuracy: 1.0000\n","Epoch 419/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1786e-04 - accuracy: 1.0000\n","Epoch 420/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.0919e-04 - accuracy: 1.0000\n","Epoch 421/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9664e-04 - accuracy: 1.0000\n","Epoch 422/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8795e-04 - accuracy: 1.0000\n","Epoch 423/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7683e-04 - accuracy: 1.0000\n","Epoch 424/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6832e-04 - accuracy: 1.0000\n","Epoch 425/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5999e-04 - accuracy: 1.0000\n","Epoch 426/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5180e-04 - accuracy: 1.0000\n","Epoch 427/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4319e-04 - accuracy: 1.0000\n","Epoch 428/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3738e-04 - accuracy: 1.0000\n","Epoch 429/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3143e-04 - accuracy: 1.0000\n","Epoch 430/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2500e-04 - accuracy: 1.0000\n","Epoch 431/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2000e-04 - accuracy: 1.0000\n","Epoch 432/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1616e-04 - accuracy: 1.0000\n","Epoch 433/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1118e-04 - accuracy: 1.0000\n","Epoch 434/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0768e-04 - accuracy: 1.0000\n","Epoch 435/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0367e-04 - accuracy: 1.0000\n","Epoch 436/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0152e-04 - accuracy: 1.0000\n","Epoch 437/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7743e-05 - accuracy: 1.0000\n","Epoch 438/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6055e-05 - accuracy: 1.0000\n","Epoch 439/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3308e-05 - accuracy: 1.0000\n","Epoch 440/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0323e-05 - accuracy: 1.0000\n","Epoch 441/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7337e-05 - accuracy: 1.0000\n","Epoch 442/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6388e-05 - accuracy: 1.0000\n","Epoch 443/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4205e-05 - accuracy: 1.0000\n","Epoch 444/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0998e-05 - accuracy: 1.0000\n","Epoch 445/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9738e-05 - accuracy: 1.0000\n","Epoch 446/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8377e-05 - accuracy: 1.0000\n","Epoch 447/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.6172e-05 - accuracy: 1.0000\n","Epoch 448/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4256e-05 - accuracy: 1.0000\n","Epoch 449/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2568e-05 - accuracy: 1.0000\n","Epoch 450/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0833e-05 - accuracy: 1.0000\n","Epoch 451/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9813e-05 - accuracy: 1.0000\n","Epoch 452/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8197e-05 - accuracy: 1.0000\n","Epoch 453/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6730e-05 - accuracy: 1.0000\n","Epoch 454/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5684e-05 - accuracy: 1.0000\n","Epoch 455/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4071e-05 - accuracy: 1.0000\n","Epoch 456/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3213e-05 - accuracy: 1.0000\n","Epoch 457/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1489e-05 - accuracy: 1.0000\n","Epoch 458/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0158e-05 - accuracy: 1.0000\n","Epoch 459/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8919e-05 - accuracy: 1.0000\n","Epoch 460/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8194e-05 - accuracy: 1.0000\n","Epoch 461/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7045e-05 - accuracy: 1.0000\n","Epoch 462/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5859e-05 - accuracy: 1.0000\n","Epoch 463/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5070e-05 - accuracy: 1.0000\n","Epoch 464/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3175e-05 - accuracy: 1.0000\n","Epoch 465/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3009e-05 - accuracy: 1.0000\n","Epoch 466/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1785e-05 - accuracy: 1.0000\n","Epoch 467/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0898e-05 - accuracy: 1.0000\n","Epoch 468/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9702e-05 - accuracy: 1.0000\n","Epoch 469/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9420e-05 - accuracy: 1.0000\n","Epoch 470/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7680e-05 - accuracy: 1.0000\n","Epoch 471/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6975e-05 - accuracy: 1.0000\n","Epoch 472/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6051e-05 - accuracy: 1.0000\n","Epoch 473/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5317e-05 - accuracy: 1.0000\n","Epoch 474/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4564e-05 - accuracy: 1.0000\n","Epoch 475/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3878e-05 - accuracy: 1.0000\n","Epoch 476/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3211e-05 - accuracy: 1.0000\n","Epoch 477/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2395e-05 - accuracy: 1.0000\n","Epoch 478/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2224e-05 - accuracy: 1.0000\n","Epoch 479/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0818e-05 - accuracy: 1.0000\n","Epoch 480/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0186e-05 - accuracy: 1.0000\n","Epoch 481/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9437e-05 - accuracy: 1.0000\n","Epoch 482/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9344e-05 - accuracy: 1.0000\n","Epoch 483/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8103e-05 - accuracy: 1.0000\n","Epoch 484/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7807e-05 - accuracy: 1.0000\n","Epoch 485/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6995e-05 - accuracy: 1.0000\n","Epoch 486/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6408e-05 - accuracy: 1.0000\n","Epoch 487/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5633e-05 - accuracy: 1.0000\n","Epoch 488/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5102e-05 - accuracy: 1.0000\n","Epoch 489/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4477e-05 - accuracy: 1.0000\n","Epoch 490/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3904e-05 - accuracy: 1.0000\n","Epoch 491/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3793e-05 - accuracy: 1.0000\n","Epoch 492/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2646e-05 - accuracy: 1.0000\n","Epoch 493/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2266e-05 - accuracy: 1.0000\n","Epoch 494/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1934e-05 - accuracy: 1.0000\n","Epoch 495/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1568e-05 - accuracy: 1.0000\n","Epoch 496/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0909e-05 - accuracy: 1.0000\n","Epoch 497/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0854e-05 - accuracy: 1.0000\n","Epoch 498/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0115e-05 - accuracy: 1.0000\n","Epoch 499/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9507e-05 - accuracy: 1.0000\n","Epoch 500/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9224e-05 - accuracy: 1.0000\n","Epoch 501/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8848e-05 - accuracy: 1.0000\n","Epoch 502/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8149e-05 - accuracy: 1.0000\n","Epoch 503/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7739e-05 - accuracy: 1.0000\n","Epoch 504/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7353e-05 - accuracy: 1.0000\n","Epoch 505/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7079e-05 - accuracy: 1.0000\n","Epoch 506/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6343e-05 - accuracy: 1.0000\n","Epoch 507/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6176e-05 - accuracy: 1.0000\n","Epoch 508/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5745e-05 - accuracy: 1.0000\n","Epoch 509/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5589e-05 - accuracy: 1.0000\n","Epoch 510/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4970e-05 - accuracy: 1.0000\n","Epoch 511/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4721e-05 - accuracy: 1.0000\n","Epoch 512/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4058e-05 - accuracy: 1.0000\n","Epoch 513/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4125e-05 - accuracy: 1.0000\n","Epoch 514/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3850e-05 - accuracy: 1.0000\n","Epoch 515/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3351e-05 - accuracy: 1.0000\n","Epoch 516/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2885e-05 - accuracy: 1.0000\n","Epoch 517/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2442e-05 - accuracy: 1.0000\n","Epoch 518/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2002e-05 - accuracy: 1.0000\n","Epoch 519/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1760e-05 - accuracy: 1.0000\n","Epoch 520/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1469e-05 - accuracy: 1.0000\n","Epoch 521/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1202e-05 - accuracy: 1.0000\n","Epoch 522/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1170e-05 - accuracy: 1.0000\n","Epoch 523/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0940e-05 - accuracy: 1.0000\n","Epoch 524/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0051e-05 - accuracy: 1.0000\n","Epoch 525/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0163e-05 - accuracy: 1.0000\n","Epoch 526/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9708e-05 - accuracy: 1.0000\n","Epoch 527/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9409e-05 - accuracy: 1.0000\n","Epoch 528/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9223e-05 - accuracy: 1.0000\n","Epoch 529/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8741e-05 - accuracy: 1.0000\n","Epoch 530/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8590e-05 - accuracy: 1.0000\n","Epoch 531/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8277e-05 - accuracy: 1.0000\n","Epoch 532/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8263e-05 - accuracy: 1.0000\n","Epoch 533/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7872e-05 - accuracy: 1.0000\n","Epoch 534/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7600e-05 - accuracy: 1.0000\n","Epoch 535/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7245e-05 - accuracy: 1.0000\n","Epoch 536/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7006e-05 - accuracy: 1.0000\n","Epoch 537/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6715e-05 - accuracy: 1.0000\n","Epoch 538/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6512e-05 - accuracy: 1.0000\n","Epoch 539/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6282e-05 - accuracy: 1.0000\n","Epoch 540/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6130e-05 - accuracy: 1.0000\n","Epoch 541/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5856e-05 - accuracy: 1.0000\n","Epoch 542/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5500e-05 - accuracy: 1.0000\n","Epoch 543/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5458e-05 - accuracy: 1.0000\n","Epoch 544/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5161e-05 - accuracy: 1.0000\n","Epoch 545/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5011e-05 - accuracy: 1.0000\n","Epoch 546/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4685e-05 - accuracy: 1.0000\n","Epoch 547/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4560e-05 - accuracy: 1.0000\n","Epoch 548/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4319e-05 - accuracy: 1.0000\n","Epoch 549/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4473e-05 - accuracy: 1.0000\n","Epoch 550/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4071e-05 - accuracy: 1.0000\n","Epoch 551/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3762e-05 - accuracy: 1.0000\n","Epoch 552/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3542e-05 - accuracy: 1.0000\n","Epoch 553/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3499e-05 - accuracy: 1.0000\n","Epoch 554/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3408e-05 - accuracy: 1.0000\n","Epoch 555/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3055e-05 - accuracy: 1.0000\n","Epoch 556/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2925e-05 - accuracy: 1.0000\n","Epoch 557/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2561e-05 - accuracy: 1.0000\n","Epoch 558/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2421e-05 - accuracy: 1.0000\n","Epoch 559/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2253e-05 - accuracy: 1.0000\n","Epoch 560/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2207e-05 - accuracy: 1.0000\n","Epoch 561/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1937e-05 - accuracy: 1.0000\n","Epoch 562/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2008e-05 - accuracy: 1.0000\n","Epoch 563/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1695e-05 - accuracy: 1.0000\n","Epoch 564/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1463e-05 - accuracy: 1.0000\n","Epoch 565/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1263e-05 - accuracy: 1.0000\n","Epoch 566/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1097e-05 - accuracy: 1.0000\n","Epoch 567/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1056e-05 - accuracy: 1.0000\n","Epoch 568/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0909e-05 - accuracy: 1.0000\n","Epoch 569/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0566e-05 - accuracy: 1.0000\n","Epoch 570/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0579e-05 - accuracy: 1.0000\n","Epoch 571/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0389e-05 - accuracy: 1.0000\n","Epoch 572/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.0164e-05 - accuracy: 1.0000\n","Epoch 573/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0123e-05 - accuracy: 1.0000\n","Epoch 574/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9305e-06 - accuracy: 1.0000\n","Epoch 575/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7823e-06 - accuracy: 1.0000\n","Epoch 576/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.7574e-06 - accuracy: 1.0000\n","Epoch 577/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4467e-06 - accuracy: 1.0000\n","Epoch 578/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3140e-06 - accuracy: 1.0000\n","Epoch 579/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2020e-06 - accuracy: 1.0000\n","Epoch 580/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0908e-06 - accuracy: 1.0000\n","Epoch 581/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0011e-06 - accuracy: 1.0000\n","Epoch 582/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9034e-06 - accuracy: 1.0000\n","Epoch 583/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7065e-06 - accuracy: 1.0000\n","Epoch 584/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6447e-06 - accuracy: 1.0000\n","Epoch 585/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7114e-06 - accuracy: 1.0000\n","Epoch 586/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3038e-06 - accuracy: 1.0000\n","Epoch 587/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2820e-06 - accuracy: 1.0000\n","Epoch 588/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.0267e-06 - accuracy: 1.0000\n","Epoch 589/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1234e-06 - accuracy: 1.0000\n","Epoch 590/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8705e-06 - accuracy: 1.0000\n","Epoch 591/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7532e-06 - accuracy: 1.0000\n","Epoch 592/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7713e-06 - accuracy: 1.0000\n","Epoch 593/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5762e-06 - accuracy: 1.0000\n","Epoch 594/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3994e-06 - accuracy: 1.0000\n","Epoch 595/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.3176e-06 - accuracy: 1.0000\n","Epoch 596/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2192e-06 - accuracy: 1.0000\n","Epoch 597/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1361e-06 - accuracy: 1.0000\n","Epoch 598/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0683e-06 - accuracy: 1.0000\n","Epoch 599/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9069e-06 - accuracy: 1.0000\n","Epoch 600/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8040e-06 - accuracy: 1.0000\n","Epoch 601/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7354e-06 - accuracy: 1.0000\n","Epoch 602/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6011e-06 - accuracy: 1.0000\n","Epoch 603/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5261e-06 - accuracy: 1.0000\n","Epoch 604/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4728e-06 - accuracy: 1.0000\n","Epoch 605/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4505e-06 - accuracy: 1.0000\n","Epoch 606/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2151e-06 - accuracy: 1.0000\n","Epoch 607/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1608e-06 - accuracy: 1.0000\n","Epoch 608/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0598e-06 - accuracy: 1.0000\n","Epoch 609/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0069e-06 - accuracy: 1.0000\n","Epoch 610/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9000e-06 - accuracy: 1.0000\n","Epoch 611/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8506e-06 - accuracy: 1.0000\n","Epoch 612/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7721e-06 - accuracy: 1.0000\n","Epoch 613/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5986e-06 - accuracy: 1.0000\n","Epoch 614/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5188e-06 - accuracy: 1.0000\n","Epoch 615/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4653e-06 - accuracy: 1.0000\n","Epoch 616/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4328e-06 - accuracy: 1.0000\n","Epoch 617/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3184e-06 - accuracy: 1.0000\n","Epoch 618/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1948e-06 - accuracy: 1.0000\n","Epoch 619/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1890e-06 - accuracy: 1.0000\n","Epoch 620/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0790e-06 - accuracy: 1.0000\n","Epoch 621/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0076e-06 - accuracy: 1.0000\n","Epoch 622/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0815e-06 - accuracy: 1.0000\n","Epoch 623/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 4.8522e-06 - accuracy: 1.0000\n","Epoch 624/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8121e-06 - accuracy: 1.0000\n","Epoch 625/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7566e-06 - accuracy: 1.0000\n","Epoch 626/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6579e-06 - accuracy: 1.0000\n","Epoch 627/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6424e-06 - accuracy: 1.0000\n","Epoch 628/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6292e-06 - accuracy: 1.0000\n","Epoch 629/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5160e-06 - accuracy: 1.0000\n","Epoch 630/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3979e-06 - accuracy: 1.0000\n","Epoch 631/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3649e-06 - accuracy: 1.0000\n","Epoch 632/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2881e-06 - accuracy: 1.0000\n","Epoch 633/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2133e-06 - accuracy: 1.0000\n","Epoch 634/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1539e-06 - accuracy: 1.0000\n","Epoch 635/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0936e-06 - accuracy: 1.0000\n","Epoch 636/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0977e-06 - accuracy: 1.0000\n","Epoch 637/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0047e-06 - accuracy: 1.0000\n","Epoch 638/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9252e-06 - accuracy: 1.0000\n","Epoch 639/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9034e-06 - accuracy: 1.0000\n","Epoch 640/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8415e-06 - accuracy: 1.0000\n","Epoch 641/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8357e-06 - accuracy: 1.0000\n","Epoch 642/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7323e-06 - accuracy: 1.0000\n","Epoch 643/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6760e-06 - accuracy: 1.0000\n","Epoch 644/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6005e-06 - accuracy: 1.0000\n","Epoch 645/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6000e-06 - accuracy: 1.0000\n","Epoch 646/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5114e-06 - accuracy: 1.0000\n","Epoch 647/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5308e-06 - accuracy: 1.0000\n","Epoch 648/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4626e-06 - accuracy: 1.0000\n","Epoch 649/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4071e-06 - accuracy: 1.0000\n","Epoch 650/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3286e-06 - accuracy: 1.0000\n","Epoch 651/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2937e-06 - accuracy: 1.0000\n","Epoch 652/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2797e-06 - accuracy: 1.0000\n","Epoch 653/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1997e-06 - accuracy: 1.0000\n","Epoch 654/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1337e-06 - accuracy: 1.0000\n","Epoch 655/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1123e-06 - accuracy: 1.0000\n","Epoch 656/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0888e-06 - accuracy: 1.0000\n","Epoch 657/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0172e-06 - accuracy: 1.0000\n","Epoch 658/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9830e-06 - accuracy: 1.0000\n","Epoch 659/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9347e-06 - accuracy: 1.0000\n","Epoch 660/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.8972e-06 - accuracy: 1.0000\n","Epoch 661/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8558e-06 - accuracy: 1.0000\n","Epoch 662/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8314e-06 - accuracy: 1.0000\n","Epoch 663/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7822e-06 - accuracy: 1.0000\n","Epoch 664/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7728e-06 - accuracy: 1.0000\n","Epoch 665/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7485e-06 - accuracy: 1.0000\n","Epoch 666/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6633e-06 - accuracy: 1.0000\n","Epoch 667/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6211e-06 - accuracy: 1.0000\n","Epoch 668/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5944e-06 - accuracy: 1.0000\n","Epoch 669/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5433e-06 - accuracy: 1.0000\n","Epoch 670/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5209e-06 - accuracy: 1.0000\n","Epoch 671/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5336e-06 - accuracy: 1.0000\n","Epoch 672/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4858e-06 - accuracy: 1.0000\n","Epoch 673/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4296e-06 - accuracy: 1.0000\n","Epoch 674/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4061e-06 - accuracy: 1.0000\n","Epoch 675/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3373e-06 - accuracy: 1.0000\n","Epoch 676/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3201e-06 - accuracy: 1.0000\n","Epoch 677/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2842e-06 - accuracy: 1.0000\n","Epoch 678/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2552e-06 - accuracy: 1.0000\n","Epoch 679/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2435e-06 - accuracy: 1.0000\n","Epoch 680/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2450e-06 - accuracy: 1.0000\n","Epoch 681/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2292e-06 - accuracy: 1.0000\n","Epoch 682/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1694e-06 - accuracy: 1.0000\n","Epoch 683/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1488e-06 - accuracy: 1.0000\n","Epoch 684/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1149e-06 - accuracy: 1.0000\n","Epoch 685/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 2.0682e-06 - accuracy: 1.0000\n","Epoch 686/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0412e-06 - accuracy: 1.0000\n","Epoch 687/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0044e-06 - accuracy: 1.0000\n","Epoch 688/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9940e-06 - accuracy: 1.0000\n","Epoch 689/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9536e-06 - accuracy: 1.0000\n","Epoch 690/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9343e-06 - accuracy: 1.0000\n","Epoch 691/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9186e-06 - accuracy: 1.0000\n","Epoch 692/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8678e-06 - accuracy: 1.0000\n","Epoch 693/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8444e-06 - accuracy: 1.0000\n","Epoch 694/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8214e-06 - accuracy: 1.0000\n","Epoch 695/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8203e-06 - accuracy: 1.0000\n","Epoch 696/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7763e-06 - accuracy: 1.0000\n","Epoch 697/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7246e-06 - accuracy: 1.0000\n","Epoch 698/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7194e-06 - accuracy: 1.0000\n","Epoch 699/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7364e-06 - accuracy: 1.0000\n","Epoch 700/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6740e-06 - accuracy: 1.0000\n","Epoch 701/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6399e-06 - accuracy: 1.0000\n","Epoch 702/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6343e-06 - accuracy: 1.0000\n","Epoch 703/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5887e-06 - accuracy: 1.0000\n","Epoch 704/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5836e-06 - accuracy: 1.0000\n","Epoch 705/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5580e-06 - accuracy: 1.0000\n","Epoch 706/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5391e-06 - accuracy: 1.0000\n","Epoch 707/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5054e-06 - accuracy: 1.0000\n","Epoch 708/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4914e-06 - accuracy: 1.0000\n","Epoch 709/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4728e-06 - accuracy: 1.0000\n","Epoch 710/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4634e-06 - accuracy: 1.0000\n","Epoch 711/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4238e-06 - accuracy: 1.0000\n","Epoch 712/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4092e-06 - accuracy: 1.0000\n","Epoch 713/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3949e-06 - accuracy: 1.0000\n","Epoch 714/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3743e-06 - accuracy: 1.0000\n","Epoch 715/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3558e-06 - accuracy: 1.0000\n","Epoch 716/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3301e-06 - accuracy: 1.0000\n","Epoch 717/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3254e-06 - accuracy: 1.0000\n","Epoch 718/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3040e-06 - accuracy: 1.0000\n","Epoch 719/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2872e-06 - accuracy: 1.0000\n","Epoch 720/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2855e-06 - accuracy: 1.0000\n","Epoch 721/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2478e-06 - accuracy: 1.0000\n","Epoch 722/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2239e-06 - accuracy: 1.0000\n","Epoch 723/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 1.2179e-06 - accuracy: 1.0000\n","Epoch 724/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1989e-06 - accuracy: 1.0000\n","Epoch 725/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1948e-06 - accuracy: 1.0000\n","Epoch 726/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1926e-06 - accuracy: 1.0000\n","Epoch 727/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1543e-06 - accuracy: 1.0000\n","Epoch 728/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1439e-06 - accuracy: 1.0000\n","Epoch 729/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1171e-06 - accuracy: 1.0000\n","Epoch 730/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1121e-06 - accuracy: 1.0000\n","Epoch 731/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1036e-06 - accuracy: 1.0000\n","Epoch 732/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0664e-06 - accuracy: 1.0000\n","Epoch 733/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0620e-06 - accuracy: 1.0000\n","Epoch 734/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0480e-06 - accuracy: 1.0000\n","Epoch 735/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0312e-06 - accuracy: 1.0000\n","Epoch 736/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0179e-06 - accuracy: 1.0000\n","Epoch 737/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0004e-06 - accuracy: 1.0000\n","Epoch 738/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9553e-07 - accuracy: 1.0000\n","Epoch 739/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.8680e-07 - accuracy: 1.0000\n","Epoch 740/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6306e-07 - accuracy: 1.0000\n","Epoch 741/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.5695e-07 - accuracy: 1.0000\n","Epoch 742/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3331e-07 - accuracy: 1.0000\n","Epoch 743/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.2292e-07 - accuracy: 1.0000\n","Epoch 744/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1480e-07 - accuracy: 1.0000\n","Epoch 745/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9202e-07 - accuracy: 1.0000\n","Epoch 746/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9402e-07 - accuracy: 1.0000\n","Epoch 747/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8454e-07 - accuracy: 1.0000\n","Epoch 748/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7498e-07 - accuracy: 1.0000\n","Epoch 749/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.6029e-07 - accuracy: 1.0000\n","Epoch 750/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.8481e-07 - accuracy: 1.0000\n","Epoch 751/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4021e-07 - accuracy: 1.0000\n","Epoch 752/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1708e-07 - accuracy: 1.0000\n","Epoch 753/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1075e-07 - accuracy: 1.0000\n","Epoch 754/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1624e-07 - accuracy: 1.0000\n","Epoch 755/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8346e-07 - accuracy: 1.0000\n","Epoch 756/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8212e-07 - accuracy: 1.0000\n","Epoch 757/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5789e-07 - accuracy: 1.0000\n","Epoch 758/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4911e-07 - accuracy: 1.0000\n","Epoch 759/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4386e-07 - accuracy: 1.0000\n","Epoch 760/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4550e-07 - accuracy: 1.0000\n","Epoch 761/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2486e-07 - accuracy: 1.0000\n","Epoch 762/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.1961e-07 - accuracy: 1.0000\n","Epoch 763/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2317e-07 - accuracy: 1.0000\n","Epoch 764/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9987e-07 - accuracy: 1.0000\n","Epoch 765/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.9063e-07 - accuracy: 1.0000\n","Epoch 766/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7263e-07 - accuracy: 1.0000\n","Epoch 767/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7259e-07 - accuracy: 1.0000\n","Epoch 768/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5611e-07 - accuracy: 1.0000\n","Epoch 769/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5262e-07 - accuracy: 1.0000\n","Epoch 770/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3946e-07 - accuracy: 1.0000\n","Epoch 771/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3028e-07 - accuracy: 1.0000\n","Epoch 772/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2451e-07 - accuracy: 1.0000\n","Epoch 773/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1981e-07 - accuracy: 1.0000\n","Epoch 774/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 6.1475e-07 - accuracy: 1.0000\n","Epoch 775/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0361e-07 - accuracy: 1.0000\n","Epoch 776/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9132e-07 - accuracy: 1.0000\n","Epoch 777/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8500e-07 - accuracy: 1.0000\n","Epoch 778/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7149e-07 - accuracy: 1.0000\n","Epoch 779/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7174e-07 - accuracy: 1.0000\n","Epoch 780/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.6062e-07 - accuracy: 1.0000\n","Epoch 781/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5110e-07 - accuracy: 1.0000\n","Epoch 782/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3720e-07 - accuracy: 1.0000\n","Epoch 783/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4026e-07 - accuracy: 1.0000\n","Epoch 784/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3210e-07 - accuracy: 1.0000\n","Epoch 785/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2010e-07 - accuracy: 1.0000\n","Epoch 786/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 5.2547e-07 - accuracy: 1.0000\n","Epoch 787/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0503e-07 - accuracy: 1.0000\n","Epoch 788/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0416e-07 - accuracy: 1.0000\n","Epoch 789/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8971e-07 - accuracy: 1.0000\n","Epoch 790/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7948e-07 - accuracy: 1.0000\n","Epoch 791/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9330e-07 - accuracy: 1.0000\n","Epoch 792/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.8106e-07 - accuracy: 1.0000\n","Epoch 793/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6386e-07 - accuracy: 1.0000\n","Epoch 794/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5410e-07 - accuracy: 1.0000\n","Epoch 795/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5509e-07 - accuracy: 1.0000\n","Epoch 796/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5265e-07 - accuracy: 1.0000\n","Epoch 797/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4054e-07 - accuracy: 1.0000\n","Epoch 798/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2994e-07 - accuracy: 1.0000\n","Epoch 799/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2586e-07 - accuracy: 1.0000\n","Epoch 800/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1955e-07 - accuracy: 1.0000\n","Epoch 801/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1715e-07 - accuracy: 1.0000\n","Epoch 802/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1049e-07 - accuracy: 1.0000\n","Epoch 803/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0881e-07 - accuracy: 1.0000\n","Epoch 804/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0299e-07 - accuracy: 1.0000\n","Epoch 805/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9241e-07 - accuracy: 1.0000\n","Epoch 806/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8723e-07 - accuracy: 1.0000\n","Epoch 807/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8015e-07 - accuracy: 1.0000\n","Epoch 808/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7982e-07 - accuracy: 1.0000\n","Epoch 809/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7244e-07 - accuracy: 1.0000\n","Epoch 810/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7360e-07 - accuracy: 1.0000\n","Epoch 811/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 3.7284e-07 - accuracy: 1.0000\n","Epoch 812/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7038e-07 - accuracy: 1.0000\n","Epoch 813/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5012e-07 - accuracy: 1.0000\n","Epoch 814/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4888e-07 - accuracy: 1.0000\n","Epoch 815/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4378e-07 - accuracy: 1.0000\n","Epoch 816/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3469e-07 - accuracy: 1.0000\n","Epoch 817/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3249e-07 - accuracy: 1.0000\n","Epoch 818/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2809e-07 - accuracy: 1.0000\n","Epoch 819/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2174e-07 - accuracy: 1.0000\n","Epoch 820/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1836e-07 - accuracy: 1.0000\n","Epoch 821/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1967e-07 - accuracy: 1.0000\n","Epoch 822/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1627e-07 - accuracy: 1.0000\n","Epoch 823/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1033e-07 - accuracy: 1.0000\n","Epoch 824/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0064e-07 - accuracy: 1.0000\n","Epoch 825/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9841e-07 - accuracy: 1.0000\n","Epoch 826/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9468e-07 - accuracy: 1.0000\n","Epoch 827/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8627e-07 - accuracy: 1.0000\n","Epoch 828/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0049e-07 - accuracy: 1.0000\n","Epoch 829/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8473e-07 - accuracy: 1.0000\n","Epoch 830/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7989e-07 - accuracy: 1.0000\n","Epoch 831/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7652e-07 - accuracy: 1.0000\n","Epoch 832/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6738e-07 - accuracy: 1.0000\n","Epoch 833/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6953e-07 - accuracy: 1.0000\n","Epoch 834/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6202e-07 - accuracy: 1.0000\n","Epoch 835/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.6198e-07 - accuracy: 1.0000\n","Epoch 836/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5776e-07 - accuracy: 1.0000\n","Epoch 837/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.5054e-07 - accuracy: 1.0000\n","Epoch 838/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4857e-07 - accuracy: 1.0000\n","Epoch 839/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4256e-07 - accuracy: 1.0000\n","Epoch 840/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.4461e-07 - accuracy: 1.0000\n","Epoch 841/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3714e-07 - accuracy: 1.0000\n","Epoch 842/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3404e-07 - accuracy: 1.0000\n","Epoch 843/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.3357e-07 - accuracy: 1.0000\n","Epoch 844/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2912e-07 - accuracy: 1.0000\n","Epoch 845/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2388e-07 - accuracy: 1.0000\n","Epoch 846/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.2033e-07 - accuracy: 1.0000\n","Epoch 847/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1853e-07 - accuracy: 1.0000\n","Epoch 848/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1466e-07 - accuracy: 1.0000\n","Epoch 849/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1090e-07 - accuracy: 1.0000\n","Epoch 850/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.1008e-07 - accuracy: 1.0000\n","Epoch 851/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0598e-07 - accuracy: 1.0000\n","Epoch 852/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.0324e-07 - accuracy: 1.0000\n","Epoch 853/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9989e-07 - accuracy: 1.0000\n","Epoch 854/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9782e-07 - accuracy: 1.0000\n","Epoch 855/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9734e-07 - accuracy: 1.0000\n","Epoch 856/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9114e-07 - accuracy: 1.0000\n","Epoch 857/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.9130e-07 - accuracy: 1.0000\n","Epoch 858/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8698e-07 - accuracy: 1.0000\n","Epoch 859/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8982e-07 - accuracy: 1.0000\n","Epoch 860/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8520e-07 - accuracy: 1.0000\n","Epoch 861/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7936e-07 - accuracy: 1.0000\n","Epoch 862/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.8192e-07 - accuracy: 1.0000\n","Epoch 863/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7391e-07 - accuracy: 1.0000\n","Epoch 864/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.7322e-07 - accuracy: 1.0000\n","Epoch 865/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6846e-07 - accuracy: 1.0000\n","Epoch 866/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6799e-07 - accuracy: 1.0000\n","Epoch 867/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6609e-07 - accuracy: 1.0000\n","Epoch 868/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6459e-07 - accuracy: 1.0000\n","Epoch 869/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6553e-07 - accuracy: 1.0000\n","Epoch 870/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6151e-07 - accuracy: 1.0000\n","Epoch 871/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.6035e-07 - accuracy: 1.0000\n","Epoch 872/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5659e-07 - accuracy: 1.0000\n","Epoch 873/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5785e-07 - accuracy: 1.0000\n","Epoch 874/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.5061e-07 - accuracy: 1.0000\n","Epoch 875/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4782e-07 - accuracy: 1.0000\n","Epoch 876/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4767e-07 - accuracy: 1.0000\n","Epoch 877/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4382e-07 - accuracy: 1.0000\n","Epoch 878/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4177e-07 - accuracy: 1.0000\n","Epoch 879/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.4068e-07 - accuracy: 1.0000\n","Epoch 880/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3984e-07 - accuracy: 1.0000\n","Epoch 881/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3758e-07 - accuracy: 1.0000\n","Epoch 882/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3615e-07 - accuracy: 1.0000\n","Epoch 883/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3430e-07 - accuracy: 1.0000\n","Epoch 884/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3484e-07 - accuracy: 1.0000\n","Epoch 885/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.3273e-07 - accuracy: 1.0000\n","Epoch 886/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2984e-07 - accuracy: 1.0000\n","Epoch 887/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2814e-07 - accuracy: 1.0000\n","Epoch 888/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2536e-07 - accuracy: 1.0000\n","Epoch 889/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2208e-07 - accuracy: 1.0000\n","Epoch 890/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.2145e-07 - accuracy: 1.0000\n","Epoch 891/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1951e-07 - accuracy: 1.0000\n","Epoch 892/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1841e-07 - accuracy: 1.0000\n","Epoch 893/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1502e-07 - accuracy: 1.0000\n","Epoch 894/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1436e-07 - accuracy: 1.0000\n","Epoch 895/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1225e-07 - accuracy: 1.0000\n","Epoch 896/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.1154e-07 - accuracy: 1.0000\n","Epoch 897/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0938e-07 - accuracy: 1.0000\n","Epoch 898/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0830e-07 - accuracy: 1.0000\n","Epoch 899/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0756e-07 - accuracy: 1.0000\n","Epoch 900/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0649e-07 - accuracy: 1.0000\n","Epoch 901/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0526e-07 - accuracy: 1.0000\n","Epoch 902/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0430e-07 - accuracy: 1.0000\n","Epoch 903/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 1.0350e-07 - accuracy: 1.0000\n","Epoch 904/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9363e-08 - accuracy: 1.0000\n","Epoch 905/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.9550e-08 - accuracy: 1.0000\n","Epoch 906/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.6268e-08 - accuracy: 1.0000\n","Epoch 907/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.4869e-08 - accuracy: 1.0000\n","Epoch 908/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.3622e-08 - accuracy: 1.0000\n","Epoch 909/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1891e-08 - accuracy: 1.0000\n","Epoch 910/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1973e-08 - accuracy: 1.0000\n","Epoch 911/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0862e-08 - accuracy: 1.0000\n","Epoch 912/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.9755e-08 - accuracy: 1.0000\n","Epoch 913/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.0022e-08 - accuracy: 1.0000\n","Epoch 914/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 9.1431e-08 - accuracy: 1.0000\n","Epoch 915/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.7831e-08 - accuracy: 1.0000\n","Epoch 916/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.4133e-08 - accuracy: 1.0000\n","Epoch 917/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.3843e-08 - accuracy: 1.0000\n","Epoch 918/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.2465e-08 - accuracy: 1.0000\n","Epoch 919/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 8.1743e-08 - accuracy: 1.0000\n","Epoch 920/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.9509e-08 - accuracy: 1.0000\n","Epoch 921/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8786e-08 - accuracy: 1.0000\n","Epoch 922/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7168e-08 - accuracy: 1.0000\n","Epoch 923/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.8010e-08 - accuracy: 1.0000\n","Epoch 924/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.7077e-08 - accuracy: 1.0000\n","Epoch 925/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.5118e-08 - accuracy: 1.0000\n","Epoch 926/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.4917e-08 - accuracy: 1.0000\n","Epoch 927/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.2970e-08 - accuracy: 1.0000\n","Epoch 928/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0732e-08 - accuracy: 1.0000\n","Epoch 929/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0532e-08 - accuracy: 1.0000\n","Epoch 930/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 7.0263e-08 - accuracy: 1.0000\n","Epoch 931/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.8936e-08 - accuracy: 1.0000\n","Epoch 932/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7576e-08 - accuracy: 1.0000\n","Epoch 933/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.6183e-08 - accuracy: 1.0000\n","Epoch 934/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.7401e-08 - accuracy: 1.0000\n","Epoch 935/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.5327e-08 - accuracy: 1.0000\n","Epoch 936/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.4371e-08 - accuracy: 1.0000\n","Epoch 937/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.3634e-08 - accuracy: 1.0000\n","Epoch 938/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.2384e-08 - accuracy: 1.0000\n","Epoch 939/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.1852e-08 - accuracy: 1.0000\n","Epoch 940/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 6.0714e-08 - accuracy: 1.0000\n","Epoch 941/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9278e-08 - accuracy: 1.0000\n","Epoch 942/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.8471e-08 - accuracy: 1.0000\n","Epoch 943/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9392e-08 - accuracy: 1.0000\n","Epoch 944/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.9039e-08 - accuracy: 1.0000\n","Epoch 945/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7224e-08 - accuracy: 1.0000\n","Epoch 946/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.7086e-08 - accuracy: 1.0000\n","Epoch 947/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.5475e-08 - accuracy: 1.0000\n","Epoch 948/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.4999e-08 - accuracy: 1.0000\n","Epoch 949/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3275e-08 - accuracy: 1.0000\n","Epoch 950/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.3957e-08 - accuracy: 1.0000\n","Epoch 951/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2771e-08 - accuracy: 1.0000\n","Epoch 952/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.2418e-08 - accuracy: 1.0000\n","Epoch 953/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.1016e-08 - accuracy: 1.0000\n","Epoch 954/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 5.0387e-08 - accuracy: 1.0000\n","Epoch 955/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9281e-08 - accuracy: 1.0000\n","Epoch 956/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9282e-08 - accuracy: 1.0000\n","Epoch 957/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.9202e-08 - accuracy: 1.0000\n","Epoch 958/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.7714e-08 - accuracy: 1.0000\n","Epoch 959/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6377e-08 - accuracy: 1.0000\n","Epoch 960/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.6059e-08 - accuracy: 1.0000\n","Epoch 961/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.5641e-08 - accuracy: 1.0000\n","Epoch 962/1000\n","25/25 [==============================] - 0s 4ms/step - loss: 4.4398e-08 - accuracy: 1.0000\n","Epoch 963/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.4298e-08 - accuracy: 1.0000\n","Epoch 964/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3451e-08 - accuracy: 1.0000\n","Epoch 965/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.3028e-08 - accuracy: 1.0000\n","Epoch 966/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2599e-08 - accuracy: 1.0000\n","Epoch 967/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.2335e-08 - accuracy: 1.0000\n","Epoch 968/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1488e-08 - accuracy: 1.0000\n","Epoch 969/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.1768e-08 - accuracy: 1.0000\n","Epoch 970/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0413e-08 - accuracy: 1.0000\n","Epoch 971/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 4.0670e-08 - accuracy: 1.0000\n","Epoch 972/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.9430e-08 - accuracy: 1.0000\n","Epoch 973/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8502e-08 - accuracy: 1.0000\n","Epoch 974/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8272e-08 - accuracy: 1.0000\n","Epoch 975/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.8869e-08 - accuracy: 1.0000\n","Epoch 976/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.7483e-08 - accuracy: 1.0000\n","Epoch 977/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6578e-08 - accuracy: 1.0000\n","Epoch 978/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6609e-08 - accuracy: 1.0000\n","Epoch 979/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.6288e-08 - accuracy: 1.0000\n","Epoch 980/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5652e-08 - accuracy: 1.0000\n","Epoch 981/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.5131e-08 - accuracy: 1.0000\n","Epoch 982/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4912e-08 - accuracy: 1.0000\n","Epoch 983/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.4349e-08 - accuracy: 1.0000\n","Epoch 984/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3985e-08 - accuracy: 1.0000\n","Epoch 985/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.3474e-08 - accuracy: 1.0000\n","Epoch 986/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2920e-08 - accuracy: 1.0000\n","Epoch 987/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1975e-08 - accuracy: 1.0000\n","Epoch 988/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1800e-08 - accuracy: 1.0000\n","Epoch 989/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.1233e-08 - accuracy: 1.0000\n","Epoch 990/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.2021e-08 - accuracy: 1.0000\n","Epoch 991/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0827e-08 - accuracy: 1.0000\n","Epoch 992/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 3.0515e-08 - accuracy: 1.0000\n","Epoch 993/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9833e-08 - accuracy: 1.0000\n","Epoch 994/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9663e-08 - accuracy: 1.0000\n","Epoch 995/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.9556e-08 - accuracy: 1.0000\n","Epoch 996/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8737e-08 - accuracy: 1.0000\n","Epoch 997/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.8429e-08 - accuracy: 1.0000\n","Epoch 998/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7924e-08 - accuracy: 1.0000\n","Epoch 999/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7745e-08 - accuracy: 1.0000\n","Epoch 1000/1000\n","25/25 [==============================] - 0s 3ms/step - loss: 2.7694e-08 - accuracy: 1.0000\n"]}],"source":["#This part is called \"fuck it, I have compute units.\"\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Define a function to create the neural network model\n","def create_model():\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(128, input_dim = features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(256, input_dim = features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(8, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Initialize lists to store accuracy scores\n","accuracy_scores = []\n","\n","# Iterate through each fold of cross-validation\n","for train_index, test_index in skf.split(features, target):\n","    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n","    y_train, y_test = target[train_index], target[test_index]\n","\n","    # Create the neural network model\n","    model = create_model()\n","\n","    # Fit the model on the training data\n","    model.fit(X_train, y_train, epochs=1000, batch_size=128, verbose=1)\n","\n","    # Evaluate the model on the test data\n","    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","    # Store the accuracy score\n","    accuracy_scores.append(accuracy)\n","\n","\n","print(accuracy_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30621,"status":"ok","timestamp":1713789247213,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"Dq3v83JKwkvK","outputId":"d62b1222-7e21-4275-b608-e171bc33df3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble model accuracy: 0.9463\n"]}],"source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize the base MLP classifier\n","base_mlp = MLPClassifier(hidden_layer_sizes=(100), alpha=0.001, max_iter=2000,\n","                         activation='relu', solver='adam', random_state=42)\n","\n","# Initialize the Bagging classifier\n","bagging_clf = BaggingClassifier(base_estimator=base_mlp, n_estimators=10, max_samples=0.8,\n","                                max_features=1.0, bootstrap=True, n_jobs=-1, random_state=42)\n","\n","# Fit the bagging classifier\n","bagging_clf.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = bagging_clf.predict(X_test_scaled)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Ensemble model accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1713819201482,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"7idrzdTVhAYr","outputId":"9a18c7d4-bdc6-4042-b126-fa7fc86aea61"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9175000190734863\n"]}],"source":["print(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":3098,"status":"error","timestamp":1713866027751,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"FNNku29Dlw72","outputId":"8964c671-767d-49d5-bade-55a97e3e7f50"},"outputs":[{"ename":"NameError","evalue":"name 'create_model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-132ca7a77066>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Create the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Fit the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"]}],"source":["\n","#This part is called \"fuck it, I have compute units.\"\n","\n","from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Define a function to create the neural network model\n","def create_complex_model():\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(128, input_dim=features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dropout(0.5))\n","    model.add(tf.keras.layers.Dense(256, activation='relu'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dropout(0.5))\n","    model.add(tf.keras.layers.Dense(128, activation='relu'))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(8, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","\n","# Initialize lists to store accuracy scores\n","accuracy_scores = []\n","\n","# Iterate through each fold of cross-validation\n","for train_index, test_index in skf.split(features, target):\n","    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n","    y_train, y_test = target[train_index], target[test_index]\n","\n","    # Create the neural network model\n","    model = create_model()\n","\n","    # Fit the model on the training data\n","    model.fit(X_train, y_train, epochs=1500, batch_size=128, verbose=1)\n","\n","    # Evaluate the model on the test data\n","    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","    # Store the accuracy score\n","    accuracy_scores.append(accuracy)\n","\n","\n","print(accuracy_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48W2atbTJ_-E"},"outputs":[],"source":["#Let's grab that original data, without the buckets.\n","import pandas as pd\n","#Let's perform a super simple and easy Random Forest Classifier.\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/data/cleaned_data.csv\")\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53VDv2xk9xto"},"outputs":[],"source":["from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","import os\n","\n","# Set up a directory for TensorBoard logs\n","log_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5e8Kx6E0o7VS","outputId":"517cc52a-1481-4c47-f261-cc2779a3cccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","3/3 [==============================] - 0s 81ms/step - loss: 5.7895e-04 - accuracy: 0.9996 - val_loss: 0.9060 - val_accuracy: 0.9422 - lr: 0.0013\n","Epoch 3024/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 7.3354e-04 - accuracy: 0.9996 - val_loss: 0.9144 - val_accuracy: 0.9422 - lr: 0.0013\n","Epoch 3025/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.3570e-04 - accuracy: 0.9992 - val_loss: 0.9205 - val_accuracy: 0.9422 - lr: 0.0013\n","Epoch 3026/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.5876e-04 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3027/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 6.4775e-05 - accuracy: 1.0000 - val_loss: 0.9390 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3028/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6101e-04 - accuracy: 1.0000 - val_loss: 0.9507 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3029/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.9540e-04 - accuracy: 0.9996 - val_loss: 0.9612 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3030/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.5129e-05 - accuracy: 1.0000 - val_loss: 0.9725 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3031/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.3723e-04 - accuracy: 0.9996 - val_loss: 0.9814 - val_accuracy: 0.9422 - lr: 0.0013\n","Epoch 3032/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4816e-04 - accuracy: 0.9996 - val_loss: 0.9851 - val_accuracy: 0.9422 - lr: 0.0013\n","Epoch 3033/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.9591 - val_accuracy: 0.9375 - lr: 0.0013\n","Epoch 3034/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.8684e-04 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.9375 - lr: 0.0013\n","Epoch 3035/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.9304 - val_accuracy: 0.9375 - lr: 0.0013\n","Epoch 3036/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 4.3897e-04 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.9375 - lr: 0.0013\n","Epoch 3037/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 8.9716e-05 - accuracy: 1.0000 - val_loss: 0.9235 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3038/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6294e-04 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3039/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5227e-05 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3040/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5911e-04 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3041/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.9445 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3042/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6020e-04 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3043/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8194e-05 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3044/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.4917e-05 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3045/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6658e-04 - accuracy: 0.9996 - val_loss: 0.9891 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3046/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.0057e-04 - accuracy: 0.9996 - val_loss: 0.9955 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3047/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.6307e-04 - accuracy: 0.9996 - val_loss: 0.9997 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3048/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.8515e-05 - accuracy: 1.0000 - val_loss: 1.0052 - val_accuracy: 0.9391 - lr: 0.0013\n","Epoch 3049/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.9709e-04 - accuracy: 0.9996 - val_loss: 1.0056 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3050/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1271e-04 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3051/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.2941e-05 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3052/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.9263e-04 - accuracy: 0.9996 - val_loss: 1.0020 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3053/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6208e-04 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3054/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.3541e-04 - accuracy: 0.9996 - val_loss: 0.9977 - val_accuracy: 0.9406 - lr: 0.0013\n","Epoch 3055/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.6697e-04 - accuracy: 0.9996 - val_loss: 0.9924 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3056/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6186e-05 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3057/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5774e-04 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3058/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4640e-05 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3059/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9136e-05 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3060/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2164e-04 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3061/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3834e-04 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3062/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.0087 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3063/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.9975 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3064/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 4.7026e-05 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3065/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.9709 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3066/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 4.4473e-04 - accuracy: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3067/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9186e-04 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3068/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.3948e-05 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3069/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.8665e-05 - accuracy: 1.0000 - val_loss: 0.8903 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3070/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0790e-04 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3071/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.8680 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3072/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.3195e-05 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3073/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.7456e-04 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3074/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8375e-04 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3075/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2035e-04 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3076/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 5.8269e-04 - accuracy: 0.9996 - val_loss: 0.8177 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3077/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.2802e-04 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3078/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.8153 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3079/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8273e-04 - accuracy: 0.9996 - val_loss: 0.8102 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3080/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.8326e-05 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3081/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.9020e-04 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3082/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0682e-04 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3083/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5235e-04 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3084/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.4703e-05 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3085/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.8558 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3086/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.8455 - val_accuracy: 0.9453 - lr: 0.0012\n","Epoch 3087/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.1591e-04 - accuracy: 1.0000 - val_loss: 0.8180 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3088/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4889e-04 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.9469 - lr: 0.0012\n","Epoch 3089/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0311e-05 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3090/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.7776 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3091/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3516e-04 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3092/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.4123e-05 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3093/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4550e-04 - accuracy: 0.9996 - val_loss: 0.7593 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3094/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4332e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3095/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.8714e-05 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3096/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.7605 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3097/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.4996e-05 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3098/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.6984e-04 - accuracy: 0.9996 - val_loss: 0.7583 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3099/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.2986e-04 - accuracy: 0.9996 - val_loss: 0.7606 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3100/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.0394e-05 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3101/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.7629 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3102/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0853e-04 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3103/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8369e-04 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3104/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0716e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3105/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.7622 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3106/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.7231 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3107/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.6459e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3108/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.3039e-04 - accuracy: 0.9992 - val_loss: 0.6864 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3109/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.6799 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3110/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.6739 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3111/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.5156e-04 - accuracy: 0.9996 - val_loss: 0.6753 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3112/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.8550e-04 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3113/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5308e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3114/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8506e-04 - accuracy: 0.9996 - val_loss: 0.7093 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3115/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8887e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3116/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.7237 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3117/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.6581 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3118/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.3802e-04 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3119/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9600e-04 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3120/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.6092 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3121/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7404e-04 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3122/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5124e-04 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3123/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6321 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3124/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5143e-04 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3125/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1893e-04 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3126/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 5.0311e-04 - accuracy: 0.9996 - val_loss: 0.6549 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3127/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9536e-04 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.9422 - lr: 0.0012\n","Epoch 3128/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.6303e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.9453 - lr: 0.0012\n","Epoch 3129/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.6982 - val_accuracy: 0.9438 - lr: 0.0012\n","Epoch 3130/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5423e-04 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3131/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.6924 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3132/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.9741e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3133/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.6711e-04 - accuracy: 0.9996 - val_loss: 0.6794 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3134/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.6763 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3135/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1814e-04 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3136/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.6708 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3137/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.6723 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3138/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6896e-04 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3139/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.3856e-04 - accuracy: 0.9996 - val_loss: 0.6878 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3140/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.4845e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3141/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9460e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3142/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3143/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3426e-04 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3144/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.7279 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3145/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.2258e-04 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3146/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8213e-04 - accuracy: 0.9996 - val_loss: 0.6952 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3147/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.6994 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3148/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0956e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.9406 - lr: 0.0012\n","Epoch 3149/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.3148e-04 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.9391 - lr: 0.0012\n","Epoch 3150/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7440 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3151/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.4928e-04 - accuracy: 0.9996 - val_loss: 0.7543 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3152/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3868e-04 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.9375 - lr: 0.0012\n","Epoch 3153/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.9011e-04 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3154/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.8008 - val_accuracy: 0.9359 - lr: 0.0012\n","Epoch 3155/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.7963 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3156/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0765e-04 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3157/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3158/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8020e-04 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3159/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.7709 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3160/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.7680 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3161/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.3793e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3162/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0495e-04 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3163/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.4268e-05 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3164/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.9360e-04 - accuracy: 0.9996 - val_loss: 0.7704 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3165/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.4951e-05 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3166/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8327e-05 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3167/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.7379 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3168/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.4377e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3169/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0737e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3170/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.7792e-04 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3171/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3152e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3172/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.8712e-04 - accuracy: 0.9996 - val_loss: 0.7166 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3173/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.9266e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3174/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1593e-04 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3175/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.7480 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3176/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.3998e-04 - accuracy: 0.9992 - val_loss: 0.7280 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3177/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1631e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3178/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0551e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3179/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.5723e-04 - accuracy: 0.9996 - val_loss: 0.7101 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3180/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3001e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3181/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3182/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.2441e-04 - accuracy: 0.9996 - val_loss: 0.7337 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3183/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4802e-04 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3184/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5550e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3185/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2437e-05 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3186/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.7707 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3187/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 2.6707e-04 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3188/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.4103e-04 - accuracy: 0.9996 - val_loss: 0.7574 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3189/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.7487 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3190/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.7325e-04 - accuracy: 0.9996 - val_loss: 0.7453 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3191/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7584e-04 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3192/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.2205e-04 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3193/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.1940e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3194/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.3840e-05 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3195/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.7567 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3196/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.7098e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3197/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1213e-04 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3198/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.9915e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3199/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.8735e-05 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3200/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.7022 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3201/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.5107e-04 - accuracy: 0.9996 - val_loss: 0.6841 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3202/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.5461e-04 - accuracy: 0.9996 - val_loss: 0.6705 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3203/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7506e-04 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3204/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.6624 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3205/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0226e-04 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3206/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.6692 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3207/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.6674 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3208/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1863e-04 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3209/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.6446 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3210/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.6324 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3211/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3349e-04 - accuracy: 0.9996 - val_loss: 0.6278 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3212/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.6314 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3213/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.9413e-04 - accuracy: 1.0000 - val_loss: 0.6437 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3214/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0860e-04 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3215/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.6769 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3216/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.6895 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3217/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.7031e-04 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3218/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.0914e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3219/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0580e-04 - accuracy: 0.9996 - val_loss: 0.7078 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3220/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9831e-04 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3221/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.3096e-04 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3222/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.8966e-05 - accuracy: 1.0000 - val_loss: 0.7422 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3223/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.4722e-05 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3224/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.1412e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3225/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.7585 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3226/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.7575e-05 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3227/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.4284e-04 - accuracy: 0.9996 - val_loss: 0.7459 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3228/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.7508e-04 - accuracy: 0.9996 - val_loss: 0.7439 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3229/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.7261 - val_accuracy: 0.9359 - lr: 0.0011\n","Epoch 3230/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8474e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.9359 - lr: 0.0011\n","Epoch 3231/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0994e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.9359 - lr: 0.0011\n","Epoch 3232/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6987 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3233/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0954e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3234/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9922e-04 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3235/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.4769e-04 - accuracy: 0.9996 - val_loss: 0.6971 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3236/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7494e-04 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3237/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.7764e-04 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3238/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.5679e-04 - accuracy: 1.0000 - val_loss: 0.7307 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3239/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.7434 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3240/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3848e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3241/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.6399e-05 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3242/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8382e-04 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3243/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1797e-04 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3244/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.7499e-05 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3245/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0914e-04 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3246/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.0761e-05 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3247/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.4938e-04 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3248/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 6.1557e-04 - accuracy: 0.9996 - val_loss: 0.8228 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3249/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.6171e-06 - accuracy: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3250/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4979e-05 - accuracy: 1.0000 - val_loss: 0.8304 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3251/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9518e-05 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3252/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7047e-05 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3253/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2842e-04 - accuracy: 0.9996 - val_loss: 0.8434 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3254/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.1103e-05 - accuracy: 1.0000 - val_loss: 0.8481 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3255/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.8490 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3256/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.2268e-05 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3257/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.2080e-05 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3258/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.3069e-05 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3259/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.8573 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3260/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.9021e-05 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3261/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.4882e-05 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3262/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2399e-04 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3263/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 5.4778e-05 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3264/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.2081e-04 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3265/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.3757e-04 - accuracy: 0.9996 - val_loss: 0.8764 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3266/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8230e-04 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3267/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.8891 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3268/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.9592e-04 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.9469 - lr: 0.0011\n","Epoch 3269/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 5.4407e-05 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3270/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7528e-04 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3271/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9599e-04 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3272/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.8430 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3273/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6777e-04 - accuracy: 0.9996 - val_loss: 0.7865 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3274/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0010e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3275/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.7041 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3276/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.6884 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3277/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2498e-04 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3278/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0636e-04 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3279/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6711 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3280/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.6296e-04 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3281/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 5.1585e-04 - accuracy: 0.9996 - val_loss: 0.6706 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3282/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4600e-04 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3283/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.6962 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3284/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.1072e-04 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3285/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.7323 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3286/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1571e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.9359 - lr: 0.0011\n","Epoch 3287/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2581e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.9359 - lr: 0.0011\n","Epoch 3288/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8609e-04 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3289/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.9873e-04 - accuracy: 0.9996 - val_loss: 0.7756 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3290/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.7429 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 3291/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.7200 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3292/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.3387e-05 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3293/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.6497e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3294/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.5936e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3295/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8521e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3296/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6548e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3297/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.2844e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3298/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7396 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3299/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5209e-04 - accuracy: 0.9996 - val_loss: 0.7482 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3300/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.6970e-05 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3301/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5783e-04 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3302/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.9301e-04 - accuracy: 0.9996 - val_loss: 0.7703 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3303/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9903e-05 - accuracy: 1.0000 - val_loss: 0.7757 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3304/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.5265e-04 - accuracy: 1.0000 - val_loss: 0.7841 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3305/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.0260e-04 - accuracy: 0.9996 - val_loss: 0.7939 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3306/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7991e-04 - accuracy: 0.9996 - val_loss: 0.8017 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3307/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.1223e-05 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3308/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7860 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3309/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8547e-05 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3310/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0792e-04 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3311/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.8200e-04 - accuracy: 0.9996 - val_loss: 0.7577 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3312/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.6931e-05 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3313/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9649e-04 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3314/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.7455e-04 - accuracy: 0.9996 - val_loss: 0.7572 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3315/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9817e-04 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3316/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9219e-04 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3317/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0258e-04 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3318/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.5030e-05 - accuracy: 1.0000 - val_loss: 0.7877 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3319/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.5421e-04 - accuracy: 0.9996 - val_loss: 0.7956 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3320/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.4509e-05 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3321/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.0057e-04 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3322/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2092e-04 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3323/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3721e-04 - accuracy: 1.0000 - val_loss: 0.8268 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3324/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2681e-04 - accuracy: 1.0000 - val_loss: 0.8355 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3325/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3630e-04 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3326/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0136e-05 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3327/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.8370 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3328/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4810e-04 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3329/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5719e-05 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3330/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0410e-04 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3331/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.5442e-05 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3332/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4238e-04 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.9406 - lr: 0.0011\n","Epoch 3333/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8335e-05 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3334/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.7178e-05 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3335/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.7946 - val_accuracy: 0.9391 - lr: 0.0011\n","Epoch 3336/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7895 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3337/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.5344e-05 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3338/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1376e-04 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.9422 - lr: 0.0011\n","Epoch 3339/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7840 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3340/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.5692e-05 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3341/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.3307e-05 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3342/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.7834 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3343/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7544 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3344/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1037e-04 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3345/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3299e-04 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.9469 - lr: 0.0011\n","Epoch 3346/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6409e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3347/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1354e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3348/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9394e-04 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3349/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.8023e-04 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.9438 - lr: 0.0011\n","Epoch 3350/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.9421e-05 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3351/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6215e-04 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3352/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.1143e-05 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3353/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1419e-04 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3354/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.6307e-04 - accuracy: 0.9996 - val_loss: 0.7869 - val_accuracy: 0.9453 - lr: 0.0011\n","Epoch 3355/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9694e-04 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3356/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5551e-04 - accuracy: 1.0000 - val_loss: 0.7893 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3357/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.9571e-06 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3358/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8766e-04 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3359/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.2644e-05 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3360/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.8247e-05 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3361/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.6655e-05 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3362/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.1530e-04 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3363/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3878e-04 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3364/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.8067 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3365/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7896 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3366/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5531e-04 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3367/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.7411e-05 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3368/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.7658 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3369/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.7527 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3370/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0769e-04 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3371/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4135e-05 - accuracy: 1.0000 - val_loss: 0.7483 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3372/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.6192e-04 - accuracy: 0.9996 - val_loss: 0.7572 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3373/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.7607 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3374/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5025e-04 - accuracy: 0.9996 - val_loss: 0.7642 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3375/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7175e-04 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3376/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.0250e-04 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3377/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.9012e-04 - accuracy: 0.9996 - val_loss: 0.7808 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3378/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.7819 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3379/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6542e-04 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3380/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.3108e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3381/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.7702 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3382/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.7454e-05 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3383/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.3707e-05 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3384/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.7215e-05 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3385/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.9334e-04 - accuracy: 0.9996 - val_loss: 0.7473 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3386/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2503e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3387/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.6669e-05 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3388/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2230e-04 - accuracy: 0.9996 - val_loss: 0.7565 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3389/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.7610 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3390/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8097e-05 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3391/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.1158e-04 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3392/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.5477e-04 - accuracy: 0.9996 - val_loss: 0.7754 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3393/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.9494e-05 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3394/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9364e-05 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3395/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7911 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3396/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.2646e-05 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3397/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0082e-04 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.9484 - lr: 0.0010\n","Epoch 3398/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.8010e-05 - accuracy: 1.0000 - val_loss: 0.7862 - val_accuracy: 0.9484 - lr: 0.0010\n","Epoch 3399/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.6646e-04 - accuracy: 0.9996 - val_loss: 0.7891 - val_accuracy: 0.9484 - lr: 0.0010\n","Epoch 3400/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.3820e-05 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.9484 - lr: 0.0010\n","Epoch 3401/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2392e-04 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.9484 - lr: 0.0010\n","Epoch 3402/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.9953e-04 - accuracy: 0.9996 - val_loss: 0.7917 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3403/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.2263e-04 - accuracy: 1.0000 - val_loss: 0.7948 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3404/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.3802e-05 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3405/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0408e-05 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3406/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.2148e-05 - accuracy: 1.0000 - val_loss: 0.8125 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3407/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8900e-04 - accuracy: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3408/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3652e-05 - accuracy: 1.0000 - val_loss: 0.8253 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3409/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.9251e-05 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3410/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.7079e-04 - accuracy: 0.9996 - val_loss: 0.8363 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3411/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.2181e-04 - accuracy: 1.0000 - val_loss: 0.8422 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3412/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.9479e-04 - accuracy: 0.9996 - val_loss: 0.8469 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3413/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.8716e-05 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3414/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.1277e-06 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3415/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.8171 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3416/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.8790e-05 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3417/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.8059e-04 - accuracy: 0.9996 - val_loss: 0.7863 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3418/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.0860e-04 - accuracy: 0.9996 - val_loss: 0.7798 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3419/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8863e-04 - accuracy: 0.9996 - val_loss: 0.7778 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3420/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.7360e-05 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3421/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.8465e-04 - accuracy: 0.9996 - val_loss: 0.7854 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3422/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.7885 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3423/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.8951e-05 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3424/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.6991e-04 - accuracy: 0.9996 - val_loss: 0.7911 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3425/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7899 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3426/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.7990 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3427/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.0097e-04 - accuracy: 0.9996 - val_loss: 0.8001 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3428/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8459e-04 - accuracy: 0.9996 - val_loss: 0.8019 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3429/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.7653 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 3430/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.4401e-04 - accuracy: 0.9996 - val_loss: 0.7434 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3431/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.7345 - val_accuracy: 0.9438 - lr: 0.0010\n","Epoch 3432/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 8.4835e-04 - accuracy: 0.9996 - val_loss: 0.7290 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3433/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.3724e-04 - accuracy: 0.9996 - val_loss: 0.7261 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3434/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.5916e-04 - accuracy: 0.9996 - val_loss: 0.7302 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3435/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2630e-04 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3436/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.3848e-04 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3437/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.5798e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3438/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.6237e-05 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3439/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.7724e-05 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3440/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9524e-04 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3441/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.0470e-04 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3442/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8499e-05 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3443/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0749e-04 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3444/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3895e-05 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3445/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6175e-05 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3446/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7705e-05 - accuracy: 1.0000 - val_loss: 0.8441 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3447/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.8497 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3448/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4979e-05 - accuracy: 1.0000 - val_loss: 0.8536 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3449/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.1454e-05 - accuracy: 1.0000 - val_loss: 0.8575 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3450/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.8565 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3451/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8775e-04 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.9422 - lr: 0.0010\n","Epoch 3452/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.8616e-05 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.9406 - lr: 0.0010\n","Epoch 3453/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.8366 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3454/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9188e-04 - accuracy: 0.9996 - val_loss: 0.8270 - val_accuracy: 0.9469 - lr: 0.0010\n","Epoch 3455/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.8188 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3456/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6906e-04 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3457/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5768e-04 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3458/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.9056e-04 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3459/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.7980 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3460/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7454e-04 - accuracy: 0.9996 - val_loss: 0.7865 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3461/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.7705 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3462/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.7469 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3463/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8554e-05 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3464/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.3909e-04 - accuracy: 0.9996 - val_loss: 0.7220 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3465/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.2163e-04 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3466/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4190e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3467/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8768e-04 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3468/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.4501e-04 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3469/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.3750e-04 - accuracy: 0.9996 - val_loss: 0.7361 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3470/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.8362e-04 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3471/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.7514 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3472/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4437e-04 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3473/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7486 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3474/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.4763e-05 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3475/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.8535e-04 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3476/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8736e-04 - accuracy: 0.9996 - val_loss: 0.7593 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3477/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.2843e-04 - accuracy: 0.9996 - val_loss: 0.7648 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3478/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4728e-04 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3479/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.7817e-04 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3480/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5034e-04 - accuracy: 1.0000 - val_loss: 0.7885 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3481/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.7536e-05 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3482/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.7961 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3483/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8467e-05 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3484/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6852e-05 - accuracy: 1.0000 - val_loss: 0.7971 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3485/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9138e-04 - accuracy: 0.9996 - val_loss: 0.8000 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3486/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.1965e-05 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3487/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3056e-04 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3488/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.0314e-05 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3489/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.8018 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3490/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5022e-04 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3491/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.7659e-05 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3492/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4839e-05 - accuracy: 1.0000 - val_loss: 0.7849 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3493/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6410e-05 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3494/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1180e-04 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3495/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.8510e-04 - accuracy: 0.9996 - val_loss: 0.7924 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3496/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0937e-04 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3497/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.7948 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3498/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.6256e-04 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3499/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 6.7385e-04 - accuracy: 0.9996 - val_loss: 0.7950 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3500/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.8454e-04 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3501/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.7983 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3502/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6611e-04 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3503/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.7889 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3504/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2838e-04 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3505/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2355e-04 - accuracy: 0.9996 - val_loss: 0.7810 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3506/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7148e-04 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3507/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.7244e-04 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3508/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.1234e-05 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3509/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.5663e-04 - accuracy: 0.9996 - val_loss: 0.7829 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3510/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.5066e-04 - accuracy: 0.9996 - val_loss: 0.7873 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3511/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.8948e-04 - accuracy: 0.9996 - val_loss: 0.7906 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3512/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.1716e-04 - accuracy: 0.9996 - val_loss: 0.7983 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3513/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6634e-04 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3514/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 2.8425e-05 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3515/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1943e-04 - accuracy: 1.0000 - val_loss: 0.8253 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3516/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.3199e-04 - accuracy: 0.9996 - val_loss: 0.8287 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3517/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.3516e-04 - accuracy: 0.9996 - val_loss: 0.8314 - val_accuracy: 0.9469 - lr: 9.6856e-04\n","Epoch 3518/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.6181e-04 - accuracy: 0.9996 - val_loss: 0.8272 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3519/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.2652e-04 - accuracy: 0.9996 - val_loss: 0.8251 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3520/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.8240 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3521/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3885e-05 - accuracy: 1.0000 - val_loss: 0.8241 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3522/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.4400e-05 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3523/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5698e-05 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3524/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 6.5960e-05 - accuracy: 1.0000 - val_loss: 0.8319 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3525/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.8278 - val_accuracy: 0.9453 - lr: 9.6856e-04\n","Epoch 3526/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.1716e-04 - accuracy: 0.9996 - val_loss: 0.8103 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3527/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.2226e-04 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3528/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7954 - val_accuracy: 0.9438 - lr: 9.6856e-04\n","Epoch 3529/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.7806 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3530/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.1700e-04 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3531/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.2403e-04 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3532/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2409e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3533/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7249e-04 - accuracy: 1.0000 - val_loss: 0.7476 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3534/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.7544 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3535/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4594e-04 - accuracy: 0.9996 - val_loss: 0.7645 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3536/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.7718 - val_accuracy: 0.9422 - lr: 9.6856e-04\n","Epoch 3537/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.7392 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3538/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.7975e-04 - accuracy: 1.0000 - val_loss: 0.7084 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3539/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.7423e-04 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3540/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.1503e-04 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3541/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.6744 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3542/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 4.6801e-04 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.9375 - lr: 9.6856e-04\n","Epoch 3543/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6262e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3544/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.3799e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3545/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.6774 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3546/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3730e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3547/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9841e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3548/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.9607e-05 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3549/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.5228e-05 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3550/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.6934e-05 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.9406 - lr: 9.6856e-04\n","Epoch 3551/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2260e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3552/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2422e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3553/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.4070e-04 - accuracy: 0.9996 - val_loss: 0.7650 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3554/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3450e-04 - accuracy: 1.0000 - val_loss: 0.7772 - val_accuracy: 0.9391 - lr: 9.6856e-04\n","Epoch 3555/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9646e-04 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3556/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.6081e-05 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3557/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 9.6726e-05 - accuracy: 1.0000 - val_loss: 0.8180 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3558/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.5146e-04 - accuracy: 1.0000 - val_loss: 0.8299 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3559/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.5408e-04 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3560/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9041e-04 - accuracy: 1.0000 - val_loss: 0.8559 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3561/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.7814e-04 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3562/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.0557e-05 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3563/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1177e-04 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3564/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.9479e-04 - accuracy: 0.9996 - val_loss: 0.8891 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3565/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.6907e-05 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3566/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2075e-04 - accuracy: 1.0000 - val_loss: 0.8959 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3567/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.2067e-04 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3568/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.6086e-04 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3569/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2619e-05 - accuracy: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3570/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5440e-04 - accuracy: 1.0000 - val_loss: 0.9180 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3571/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.1815e-05 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3572/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.6984e-05 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3573/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 9.0664e-06 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3574/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0985e-04 - accuracy: 1.0000 - val_loss: 0.9395 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3575/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6404e-05 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3576/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.3279e-05 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3577/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3578/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.9892e-04 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3579/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0856e-04 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3580/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.9359 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3581/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.9096 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3582/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.0301e-04 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3583/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.8792 - val_accuracy: 0.9359 - lr: 9.2013e-04\n","Epoch 3584/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.9359 - lr: 9.2013e-04\n","Epoch 3585/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.7404e-05 - accuracy: 1.0000 - val_loss: 0.8495 - val_accuracy: 0.9359 - lr: 9.2013e-04\n","Epoch 3586/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8397 - val_accuracy: 0.9344 - lr: 9.2013e-04\n","Epoch 3587/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6190e-04 - accuracy: 0.9996 - val_loss: 0.8282 - val_accuracy: 0.9344 - lr: 9.2013e-04\n","Epoch 3588/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.8105 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3589/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8348e-04 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3590/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5879e-04 - accuracy: 1.0000 - val_loss: 0.8065 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3591/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0058e-04 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3592/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.7977 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3593/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8675e-05 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3594/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8726e-04 - accuracy: 0.9996 - val_loss: 0.7696 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3595/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9791e-04 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3596/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7102e-04 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3597/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.3934e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3598/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0074e-05 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3599/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.5258e-05 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3600/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.7310 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3601/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.5785e-04 - accuracy: 0.9996 - val_loss: 0.7055 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3602/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5622e-04 - accuracy: 0.9996 - val_loss: 0.6893 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3603/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 2.0547e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3604/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0170e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3605/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.0226e-04 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3606/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.4296e-05 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3607/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6457e-04 - accuracy: 0.9996 - val_loss: 0.7026 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3608/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.7069 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3609/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 5.3270e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3610/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.0245e-04 - accuracy: 0.9996 - val_loss: 0.7159 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3611/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.3060e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3612/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.8681e-05 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3613/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2164e-04 - accuracy: 0.9996 - val_loss: 0.7353 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3614/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.8861e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3615/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9102e-04 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3616/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 0.7691 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3617/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3959e-04 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3618/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7404e-04 - accuracy: 0.9996 - val_loss: 0.7910 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3619/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.4483e-05 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3620/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 6.1832e-04 - accuracy: 0.9996 - val_loss: 0.8130 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3621/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.5664e-05 - accuracy: 1.0000 - val_loss: 0.8209 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3622/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.9185e-05 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3623/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2163e-05 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3624/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.5983e-04 - accuracy: 0.9996 - val_loss: 0.8408 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3625/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8476e-04 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3626/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2078e-04 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3627/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.2293e-04 - accuracy: 0.9996 - val_loss: 0.8431 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3628/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.8422 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3629/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.9681e-05 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3630/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.3499e-04 - accuracy: 1.0000 - val_loss: 0.8371 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3631/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.3736e-04 - accuracy: 0.9996 - val_loss: 0.8399 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3632/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2237e-05 - accuracy: 1.0000 - val_loss: 0.8425 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3633/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 9.8481e-05 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3634/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 1.3960e-04 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3635/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.3964e-05 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3636/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.8584 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3637/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1709e-04 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3638/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 8.0372e-05 - accuracy: 1.0000 - val_loss: 0.8638 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3639/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.7496e-05 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3640/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.9343e-04 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3641/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.9535e-04 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3642/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.6443e-04 - accuracy: 0.9996 - val_loss: 0.8841 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3643/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.8791 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3644/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 4.4678e-04 - accuracy: 0.9996 - val_loss: 0.8810 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3645/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.1690e-05 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.9438 - lr: 9.2013e-04\n","Epoch 3646/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.8771 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3647/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2919e-04 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.9422 - lr: 9.2013e-04\n","Epoch 3648/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.3538e-05 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3649/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.5848e-05 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.9406 - lr: 9.2013e-04\n","Epoch 3650/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6706e-04 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3651/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3604e-04 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.9391 - lr: 9.2013e-04\n","Epoch 3652/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7241e-05 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3653/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0051e-05 - accuracy: 1.0000 - val_loss: 0.9431 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3654/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4575e-04 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.9375 - lr: 9.2013e-04\n","Epoch 3655/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1218e-05 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3656/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.8546e-05 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3657/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.9803 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3658/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.1952e-05 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3659/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.3216e-04 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3660/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0873e-04 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3661/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5160e-04 - accuracy: 0.9996 - val_loss: 1.0014 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3662/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6527e-04 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3663/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3266e-06 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3664/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 4.5563e-05 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3665/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 1.0222 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3666/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.7666e-06 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3667/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.1923e-04 - accuracy: 0.9996 - val_loss: 1.0065 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3668/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.6413e-04 - accuracy: 0.9996 - val_loss: 1.0006 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3669/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2416e-04 - accuracy: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3670/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.2038e-05 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3671/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.9510e-05 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3672/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8150e-05 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3673/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.6943e-04 - accuracy: 0.9996 - val_loss: 1.0012 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3674/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1363e-04 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3675/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.0099 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3676/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.3920e-06 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3677/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5435e-05 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3678/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4426e-04 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3679/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.3986e-04 - accuracy: 0.9996 - val_loss: 1.0537 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3680/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.1436e-05 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.9359 - lr: 8.7412e-04\n","Epoch 3681/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.2291e-04 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3682/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.7199e-04 - accuracy: 0.9996 - val_loss: 1.0965 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3683/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4463e-05 - accuracy: 1.0000 - val_loss: 1.1020 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3684/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.0509e-04 - accuracy: 0.9996 - val_loss: 1.1016 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3685/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.7184e-04 - accuracy: 0.9996 - val_loss: 1.1004 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3686/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.9263e-04 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3687/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.2454e-05 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3688/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 9.6457e-05 - accuracy: 1.0000 - val_loss: 1.1153 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3689/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.0785e-04 - accuracy: 0.9996 - val_loss: 1.0967 - val_accuracy: 0.9375 - lr: 8.7412e-04\n","Epoch 3690/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1119e-05 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3691/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0507e-04 - accuracy: 1.0000 - val_loss: 1.0858 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3692/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8279e-04 - accuracy: 0.9996 - val_loss: 1.0844 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3693/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 1.0715 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3694/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0195e-04 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3695/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.8623e-04 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3696/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.3830e-04 - accuracy: 0.9996 - val_loss: 1.0506 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3697/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 1.0280 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3698/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8484e-04 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3699/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.8130e-04 - accuracy: 0.9996 - val_loss: 1.0100 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3700/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.5111e-05 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3701/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.0098 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3702/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.2812e-05 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.9391 - lr: 8.7412e-04\n","Epoch 3703/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2182e-04 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3704/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.0124 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3705/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6499e-04 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3706/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3253e-05 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3707/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2676e-04 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3708/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.1021e-04 - accuracy: 0.9996 - val_loss: 1.0266 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3709/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.0112 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3710/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.9861 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3711/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7819e-04 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3712/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.0143e-05 - accuracy: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3713/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.2702e-05 - accuracy: 1.0000 - val_loss: 0.9308 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3714/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.1590e-04 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3715/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.4998e-04 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3716/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.9614e-04 - accuracy: 0.9996 - val_loss: 0.9303 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3717/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.0295e-05 - accuracy: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3718/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.9217 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3719/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.6673e-04 - accuracy: 0.9996 - val_loss: 0.9154 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3720/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0358e-04 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3721/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.8883 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3722/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.3896e-05 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3723/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0997e-04 - accuracy: 1.0000 - val_loss: 0.8503 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3724/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.5637e-05 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3725/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.1157e-05 - accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3726/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.9111e-05 - accuracy: 1.0000 - val_loss: 0.8396 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3727/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.8404 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3728/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.3340e-05 - accuracy: 1.0000 - val_loss: 0.8391 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3729/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.1537e-05 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3730/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3254e-04 - accuracy: 1.0000 - val_loss: 0.8424 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3731/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.8460e-05 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3732/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2232e-05 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3733/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.8424 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3734/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6581e-04 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3735/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4692e-04 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3736/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.9678e-04 - accuracy: 0.9996 - val_loss: 0.8448 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3737/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9427e-04 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.9453 - lr: 8.7412e-04\n","Epoch 3738/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.8043e-04 - accuracy: 0.9996 - val_loss: 0.8561 - val_accuracy: 0.9469 - lr: 8.7412e-04\n","Epoch 3739/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.5221e-04 - accuracy: 0.9996 - val_loss: 0.8604 - val_accuracy: 0.9469 - lr: 8.7412e-04\n","Epoch 3740/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.6547e-05 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.9469 - lr: 8.7412e-04\n","Epoch 3741/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9912e-05 - accuracy: 1.0000 - val_loss: 0.8727 - val_accuracy: 0.9469 - lr: 8.7412e-04\n","Epoch 3742/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.8717 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3743/30000\n","3/3 [==============================] - 0s 87ms/step - loss: 1.2602e-04 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3744/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.3943e-04 - accuracy: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3745/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.1889e-04 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3746/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 9.8630e-04 - accuracy: 0.9992 - val_loss: 0.8871 - val_accuracy: 0.9438 - lr: 8.7412e-04\n","Epoch 3747/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8837 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3748/30000\n","3/3 [==============================] - 0s 88ms/step - loss: 2.8928e-05 - accuracy: 1.0000 - val_loss: 0.8830 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3749/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.8815 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3750/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.0261e-04 - accuracy: 0.9996 - val_loss: 0.8792 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3751/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 4.5062e-05 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.9406 - lr: 8.7412e-04\n","Epoch 3752/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.0740e-04 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3753/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 2.4541e-04 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3754/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2952e-04 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.9422 - lr: 8.7412e-04\n","Epoch 3755/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.6211e-04 - accuracy: 0.9996 - val_loss: 0.8977 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3756/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.7616e-04 - accuracy: 0.9996 - val_loss: 0.9009 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3757/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 9.0193e-05 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3758/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.4593e-04 - accuracy: 0.9996 - val_loss: 0.9169 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3759/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.0635e-04 - accuracy: 0.9996 - val_loss: 0.9244 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3760/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.0924e-05 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3761/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.6033e-05 - accuracy: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3762/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.2076e-05 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3763/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.9456 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3764/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9371 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3765/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.5409e-05 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3766/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.9233 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3767/30000\n","3/3 [==============================] - 0s 87ms/step - loss: 1.1329e-04 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3768/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.3962e-04 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3769/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.6887e-05 - accuracy: 1.0000 - val_loss: 0.9255 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3770/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.4822e-04 - accuracy: 0.9996 - val_loss: 0.9295 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3771/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 5.7181e-05 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3772/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.6877e-05 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3773/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 8.0855e-04 - accuracy: 0.9996 - val_loss: 0.9493 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3774/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.1685e-05 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3775/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.4457e-04 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3776/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.2856e-04 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3777/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.4823e-05 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3778/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.3352e-05 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3779/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.9952 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3780/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.2808e-04 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3781/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 5.4052e-04 - accuracy: 0.9996 - val_loss: 1.0082 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3782/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.3964e-05 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3783/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.0792e-05 - accuracy: 1.0000 - val_loss: 1.0183 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3784/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.9588e-06 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3785/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.2840e-05 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3786/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.0063 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3787/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.4869e-05 - accuracy: 1.0000 - val_loss: 0.9834 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3788/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.8335e-06 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3789/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.4557e-05 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3790/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.2761e-05 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3791/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.6682e-05 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3792/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.5592e-04 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3793/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2051e-04 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3794/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.4761e-04 - accuracy: 0.9996 - val_loss: 0.9468 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3795/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.8142e-05 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3796/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0581e-04 - accuracy: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3797/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.9600e-04 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3798/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0802e-05 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3799/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.7287e-04 - accuracy: 0.9996 - val_loss: 0.9581 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3800/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.6926e-05 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3801/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0176e-04 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3802/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.7820e-04 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3803/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.6482e-05 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3804/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.1919e-05 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3805/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.5396e-05 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3806/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.3311e-04 - accuracy: 1.0000 - val_loss: 1.0340 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3807/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.0353e-05 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3808/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4786e-05 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3809/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.1060e-04 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3810/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 1.0711 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3811/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.1152e-04 - accuracy: 0.9996 - val_loss: 1.0536 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3812/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.3312e-04 - accuracy: 1.0000 - val_loss: 1.0399 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3813/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4754e-05 - accuracy: 1.0000 - val_loss: 1.0336 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3814/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8026e-05 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3815/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.0502e-05 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3816/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.7001e-05 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3817/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.9596e-05 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3818/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.9406e-04 - accuracy: 0.9996 - val_loss: 1.0452 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3819/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.6554e-05 - accuracy: 1.0000 - val_loss: 1.0491 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3820/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 2.8317e-04 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3821/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 6.0514e-06 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3822/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.2338e-04 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3823/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.9100e-05 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3824/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.6655e-04 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3825/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.7908e-04 - accuracy: 1.0000 - val_loss: 1.0761 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3826/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.4670e-06 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3827/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.0989e-05 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3828/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.1195e-05 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3829/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5233e-04 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3830/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9074e-05 - accuracy: 1.0000 - val_loss: 1.1096 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3831/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9238e-04 - accuracy: 0.9996 - val_loss: 1.1158 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3832/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 6.8096e-05 - accuracy: 1.0000 - val_loss: 1.1217 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3833/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.1140 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3834/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.0513e-06 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3835/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.1851e-04 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3836/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0281e-05 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3837/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4454e-04 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3838/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.6782e-05 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3839/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.5673e-05 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3840/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5197e-04 - accuracy: 1.0000 - val_loss: 1.0994 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3841/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0733e-05 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3842/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1012e-05 - accuracy: 1.0000 - val_loss: 1.1089 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3843/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0775e-06 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3844/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4328e-04 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3845/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1751e-05 - accuracy: 1.0000 - val_loss: 1.1240 - val_accuracy: 0.9375 - lr: 8.3042e-04\n","Epoch 3846/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.3840e-04 - accuracy: 0.9996 - val_loss: 1.1269 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3847/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5061e-05 - accuracy: 1.0000 - val_loss: 1.1275 - val_accuracy: 0.9391 - lr: 8.3042e-04\n","Epoch 3848/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6092e-05 - accuracy: 1.0000 - val_loss: 1.1296 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3849/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.6813e-05 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3850/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.8432e-04 - accuracy: 1.0000 - val_loss: 1.1387 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3851/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6104e-06 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3852/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6391e-04 - accuracy: 0.9996 - val_loss: 1.1405 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3853/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.8492e-05 - accuracy: 1.0000 - val_loss: 1.1384 - val_accuracy: 0.9406 - lr: 8.3042e-04\n","Epoch 3854/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6572e-05 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.9422 - lr: 8.3042e-04\n","Epoch 3855/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 1.1005 - val_accuracy: 0.9422 - lr: 7.8890e-04\n","Epoch 3856/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.2389e-04 - accuracy: 0.9996 - val_loss: 1.0594 - val_accuracy: 0.9422 - lr: 7.8890e-04\n","Epoch 3857/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.3408e-06 - accuracy: 1.0000 - val_loss: 1.0350 - val_accuracy: 0.9391 - lr: 7.8890e-04\n","Epoch 3858/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0169e-04 - accuracy: 1.0000 - val_loss: 1.0200 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3859/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.1612e-06 - accuracy: 1.0000 - val_loss: 1.0114 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3860/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.6774e-04 - accuracy: 0.9996 - val_loss: 0.9970 - val_accuracy: 0.9359 - lr: 7.8890e-04\n","Epoch 3861/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.9760 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3862/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7766e-05 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.9359 - lr: 7.8890e-04\n","Epoch 3863/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.2644e-04 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3864/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7976e-05 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3865/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.4383e-04 - accuracy: 0.9996 - val_loss: 0.9524 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3866/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7349e-04 - accuracy: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3867/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.4499e-04 - accuracy: 0.9996 - val_loss: 0.9587 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3868/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5415e-05 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3869/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.5042e-06 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3870/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.2417e-04 - accuracy: 0.9996 - val_loss: 0.9723 - val_accuracy: 0.9391 - lr: 7.8890e-04\n","Epoch 3871/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.9518e-05 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.9391 - lr: 7.8890e-04\n","Epoch 3872/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.6899e-05 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3873/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.8965e-05 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3874/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9726 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3875/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.2605e-05 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.9391 - lr: 7.8890e-04\n","Epoch 3876/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.9617 - val_accuracy: 0.9391 - lr: 7.8890e-04\n","Epoch 3877/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.2991e-05 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.9375 - lr: 7.8890e-04\n","Epoch 3878/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.9473 - val_accuracy: 0.9359 - lr: 7.8890e-04\n","Epoch 3879/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4614e-05 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.9359 - lr: 7.8890e-04\n","Epoch 3880/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1769e-05 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.9359 - lr: 7.8890e-04\n","Epoch 3881/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.9093e-04 - accuracy: 0.9996 - val_loss: 0.9322 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3882/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.7375e-05 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.9344 - lr: 7.8890e-04\n","Epoch 3883/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3051e-05 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3884/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.8103e-05 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3885/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.9798e-05 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3886/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.8066e-05 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3887/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0270e-04 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3888/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.8800e-04 - accuracy: 0.9996 - val_loss: 0.9378 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3889/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8514e-04 - accuracy: 0.9996 - val_loss: 0.9420 - val_accuracy: 0.9344 - lr: 7.8890e-04\n","Epoch 3890/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.6435e-04 - accuracy: 0.9996 - val_loss: 0.9483 - val_accuracy: 0.9344 - lr: 7.8890e-04\n","Epoch 3891/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.5904e-04 - accuracy: 0.9996 - val_loss: 0.9548 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3892/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.8437e-05 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3893/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6163e-04 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3894/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 6.8319e-05 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3895/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 6.9426e-05 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3896/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.7767e-05 - accuracy: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3897/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.0213e-05 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3898/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.8044e-05 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3899/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.3996e-05 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3900/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.1003e-04 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3901/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.3150e-05 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3902/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.4215e-06 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3903/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.2724e-05 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3904/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0314e-05 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3905/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1677e-05 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3906/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.8959e-05 - accuracy: 1.0000 - val_loss: 1.0746 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3907/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 1.0805 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3908/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.2383e-05 - accuracy: 1.0000 - val_loss: 1.0863 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3909/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.8678e-04 - accuracy: 0.9996 - val_loss: 1.0911 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3910/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2416e-04 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3911/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5240e-05 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3912/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0282e-05 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3913/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9640e-06 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3914/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.9215e-06 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3915/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2279e-05 - accuracy: 1.0000 - val_loss: 1.1195 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3916/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8313e-04 - accuracy: 0.9996 - val_loss: 1.1207 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3917/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 1.0890 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3918/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0514e-04 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3919/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6317e-05 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3920/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.5976e-04 - accuracy: 0.9996 - val_loss: 1.0383 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3921/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.2057e-05 - accuracy: 1.0000 - val_loss: 1.0275 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3922/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8176e-05 - accuracy: 1.0000 - val_loss: 1.0205 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3923/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.2859e-05 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3924/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.7273e-05 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3925/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5710e-05 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3926/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5003e-04 - accuracy: 1.0000 - val_loss: 1.0220 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3927/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1521e-05 - accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3928/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0724e-04 - accuracy: 0.9996 - val_loss: 1.0320 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3929/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.2019e-05 - accuracy: 1.0000 - val_loss: 1.0398 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3930/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.0372 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3931/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0979e-04 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.9297 - lr: 7.8890e-04\n","Epoch 3932/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.7992e-04 - accuracy: 0.9996 - val_loss: 1.0100 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3933/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.6234e-06 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3934/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.5323e-05 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3935/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0544e-05 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3936/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.1541e-04 - accuracy: 0.9996 - val_loss: 0.9822 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3937/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.1492e-04 - accuracy: 0.9996 - val_loss: 0.9840 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3938/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4568e-05 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3939/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.9840 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3940/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.7848e-04 - accuracy: 0.9996 - val_loss: 0.9815 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3941/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.8983e-04 - accuracy: 0.9996 - val_loss: 0.9820 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3942/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.1770e-05 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3943/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2309e-05 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3944/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.2391e-04 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3945/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2508e-04 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.9312 - lr: 7.8890e-04\n","Epoch 3946/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.1809e-05 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3947/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.6833e-05 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3948/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0423e-05 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3949/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8560e-06 - accuracy: 1.0000 - val_loss: 1.0295 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3950/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0727e-04 - accuracy: 1.0000 - val_loss: 1.0342 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3951/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3886e-05 - accuracy: 1.0000 - val_loss: 1.0385 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3952/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6708e-05 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3953/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.1567e-04 - accuracy: 0.9996 - val_loss: 1.0472 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3954/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5835e-04 - accuracy: 1.0000 - val_loss: 1.0528 - val_accuracy: 0.9328 - lr: 7.8890e-04\n","Epoch 3955/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.3980e-05 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 0.9328 - lr: 7.4945e-04\n","Epoch 3956/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.4394e-05 - accuracy: 1.0000 - val_loss: 1.0655 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 3957/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6966e-04 - accuracy: 0.9996 - val_loss: 1.0696 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 3958/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.0986e-06 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 3959/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6529e-06 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 3960/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.1776e-04 - accuracy: 0.9996 - val_loss: 1.0745 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 3961/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.9016e-06 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3962/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.6490e-04 - accuracy: 0.9996 - val_loss: 1.0712 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3963/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.8535e-04 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3964/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.8934e-05 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3965/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 8.5052e-05 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3966/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.5459e-05 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3967/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 1.0702 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3968/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 8.1089e-05 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3969/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.4668e-06 - accuracy: 1.0000 - val_loss: 1.0654 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3970/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3578e-05 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3971/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.8330e-04 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3972/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.1983e-05 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3973/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.6279e-05 - accuracy: 1.0000 - val_loss: 1.0745 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3974/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.3546e-04 - accuracy: 0.9996 - val_loss: 1.0779 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3975/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.0379e-05 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3976/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0608e-06 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3977/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.0903 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3978/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.0601e-04 - accuracy: 0.9996 - val_loss: 1.0923 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 3979/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.6837e-05 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3980/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.5348e-05 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3981/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6046e-05 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3982/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.3863e-05 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3983/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.7918e-05 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3984/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9406e-05 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3985/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.1013 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3986/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.9841e-05 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 3987/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9707e-05 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3988/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.0828 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3989/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.2817e-04 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3990/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6736e-05 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3991/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.0512 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3992/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.8940e-04 - accuracy: 0.9996 - val_loss: 1.0276 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 3993/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4908e-04 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 3994/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4991e-05 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3995/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8483e-04 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 3996/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2856e-04 - accuracy: 1.0000 - val_loss: 1.0063 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 3997/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9682e-04 - accuracy: 0.9996 - val_loss: 1.0061 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3998/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4737e-05 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 3999/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.8457e-04 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4000/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4986e-05 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4001/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.0137e-05 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4002/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9447e-05 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4003/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8049e-04 - accuracy: 1.0000 - val_loss: 1.0155 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4004/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1127e-04 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 4005/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0704e-05 - accuracy: 1.0000 - val_loss: 1.0241 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 4006/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.1993e-05 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 4007/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.9851e-04 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 4008/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.8100e-06 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.9344 - lr: 7.4945e-04\n","Epoch 4009/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.8818e-04 - accuracy: 1.0000 - val_loss: 1.0519 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4010/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3815e-04 - accuracy: 0.9996 - val_loss: 1.0624 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4011/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8598e-05 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4012/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 5.0031e-06 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4013/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.0612 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4014/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.2059e-06 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4015/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7801e-06 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4016/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7144e-04 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4017/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6366e-04 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4018/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.5565e-05 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4019/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.9202 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4020/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.0017e-05 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4021/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2005e-05 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4022/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.1950e-05 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4023/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3561e-05 - accuracy: 1.0000 - val_loss: 0.8940 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4024/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.8962e-04 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4025/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.2749e-04 - accuracy: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4026/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0696e-05 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4027/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.1035e-05 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4028/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.9113 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4029/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.1245e-05 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4030/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.9076e-04 - accuracy: 0.9996 - val_loss: 0.8986 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4031/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6675e-04 - accuracy: 1.0000 - val_loss: 0.8981 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4032/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6832e-05 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4033/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.7939e-05 - accuracy: 1.0000 - val_loss: 0.9067 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4034/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.1028e-05 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4035/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.1581e-05 - accuracy: 1.0000 - val_loss: 0.9183 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4036/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.5832e-04 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4037/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.3238e-04 - accuracy: 0.9996 - val_loss: 0.9277 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4038/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.0393e-05 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4039/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3719e-04 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.9391 - lr: 7.4945e-04\n","Epoch 4040/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 8.1328e-04 - accuracy: 0.9996 - val_loss: 0.9451 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4041/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 7.8486e-05 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4042/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.4776e-05 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4043/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.3272e-06 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4044/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7658e-05 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4045/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.9510 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4046/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 2.7788e-05 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4047/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0800e-05 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4048/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.8901 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4049/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5652e-05 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4050/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4051/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4346e-05 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4052/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.4276e-05 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.9375 - lr: 7.4945e-04\n","Epoch 4053/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.9880e-04 - accuracy: 0.9996 - val_loss: 0.8518 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4054/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9224e-05 - accuracy: 1.0000 - val_loss: 0.8559 - val_accuracy: 0.9359 - lr: 7.4945e-04\n","Epoch 4055/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.1283e-04 - accuracy: 1.0000 - val_loss: 0.8608 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4056/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.8667e-05 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4057/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.8670 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4058/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5375e-04 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4059/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8363e-05 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4060/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.7242e-05 - accuracy: 1.0000 - val_loss: 0.8824 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4061/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.5666e-04 - accuracy: 1.0000 - val_loss: 0.8908 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4062/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4780e-04 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4063/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1026e-04 - accuracy: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4064/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5838e-04 - accuracy: 1.0000 - val_loss: 0.9193 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4065/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0780e-04 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4066/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2177e-04 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4067/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 8.3987e-05 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4068/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4803e-05 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4069/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1252e-05 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4070/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6290e-05 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4071/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.5299e-05 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4072/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.9865 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4073/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.1793e-04 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4074/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.8982e-05 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4075/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.7929e-04 - accuracy: 0.9996 - val_loss: 0.9391 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4076/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1438e-04 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4077/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.8126e-04 - accuracy: 0.9996 - val_loss: 0.9324 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4078/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.7115e-05 - accuracy: 1.0000 - val_loss: 0.9332 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4079/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2906e-04 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4080/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.9379 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4081/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.3705e-05 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4082/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0757e-04 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4083/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.1784e-04 - accuracy: 0.9996 - val_loss: 0.9433 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4084/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.2895e-05 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4085/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1351e-04 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4086/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9017e-04 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4087/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.4893e-05 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4088/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9994e-05 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4089/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8050e-05 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4090/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0645e-05 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4091/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2754e-05 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4092/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.3024e-04 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4093/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.2624e-05 - accuracy: 1.0000 - val_loss: 1.0351 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4094/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.8628e-05 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4095/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1511e-05 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4096/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0544e-05 - accuracy: 1.0000 - val_loss: 1.0548 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4097/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.7921e-05 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4098/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.0066e-06 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4099/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.7764e-05 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4100/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2238e-04 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4101/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7143e-05 - accuracy: 1.0000 - val_loss: 1.0823 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4102/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9818e-05 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4103/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 9.3728e-05 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4104/30000\n","3/3 [==============================] - 0s 87ms/step - loss: 2.5780e-04 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4105/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0000e-04 - accuracy: 1.0000 - val_loss: 1.1004 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4106/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1148e-04 - accuracy: 1.0000 - val_loss: 1.1075 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4107/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.6734e-06 - accuracy: 1.0000 - val_loss: 1.1141 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4108/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.2532e-06 - accuracy: 1.0000 - val_loss: 1.1201 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4109/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.4115e-04 - accuracy: 0.9996 - val_loss: 1.1280 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4110/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5850e-06 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4111/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.7420e-05 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4112/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.7486e-04 - accuracy: 0.9996 - val_loss: 1.1462 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4113/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 1.1405 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4114/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.8672e-04 - accuracy: 0.9996 - val_loss: 1.1243 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4115/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6582e-04 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4116/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1584e-05 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4117/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 1.0498 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4118/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9994e-04 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4119/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.9565 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4120/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6144e-04 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4121/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.9004 - val_accuracy: 0.9406 - lr: 7.1198e-04\n","Epoch 4122/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6680e-04 - accuracy: 0.9992 - val_loss: 0.8813 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4123/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4124/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3993e-04 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4125/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6243e-05 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4126/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.0992e-05 - accuracy: 1.0000 - val_loss: 0.8695 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4127/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.0874e-05 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4128/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6561e-04 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4129/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.6574e-05 - accuracy: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4130/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5162e-04 - accuracy: 0.9996 - val_loss: 0.8860 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4131/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2249e-04 - accuracy: 0.9996 - val_loss: 0.8897 - val_accuracy: 0.9422 - lr: 7.1198e-04\n","Epoch 4132/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.7649e-04 - accuracy: 0.9996 - val_loss: 0.8879 - val_accuracy: 0.9406 - lr: 7.1198e-04\n","Epoch 4133/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.0039e-05 - accuracy: 1.0000 - val_loss: 0.8876 - val_accuracy: 0.9406 - lr: 7.1198e-04\n","Epoch 4134/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2322e-04 - accuracy: 1.0000 - val_loss: 0.8892 - val_accuracy: 0.9406 - lr: 7.1198e-04\n","Epoch 4135/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 9.0658e-04 - accuracy: 0.9996 - val_loss: 0.8933 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4136/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.8870 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4137/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.3678e-05 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4138/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5383e-05 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4139/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.9979e-05 - accuracy: 1.0000 - val_loss: 0.8442 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4140/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1989e-04 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.9344 - lr: 7.1198e-04\n","Epoch 4141/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.8296 - val_accuracy: 0.9359 - lr: 7.1198e-04\n","Epoch 4142/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.5093e-04 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4143/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3128e-04 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4144/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.9008e-05 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4145/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3569e-05 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.9406 - lr: 7.1198e-04\n","Epoch 4146/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6490e-04 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4147/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.3646e-05 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4148/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4278e-04 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4149/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4877e-05 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4150/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.8557e-05 - accuracy: 1.0000 - val_loss: 0.8447 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4151/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4624e-04 - accuracy: 0.9996 - val_loss: 0.8549 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4152/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.9867e-05 - accuracy: 1.0000 - val_loss: 0.8648 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4153/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.8317e-05 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.9391 - lr: 7.1198e-04\n","Epoch 4154/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5178e-04 - accuracy: 0.9996 - val_loss: 0.8804 - val_accuracy: 0.9375 - lr: 7.1198e-04\n","Epoch 4155/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.0714e-04 - accuracy: 0.9996 - val_loss: 0.8863 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4156/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.0236e-05 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4157/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4354e-04 - accuracy: 1.0000 - val_loss: 0.9013 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4158/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.7228e-05 - accuracy: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4159/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.9586e-04 - accuracy: 0.9996 - val_loss: 0.9114 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4160/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.0492e-05 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4161/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0168e-04 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4162/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.8721 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4163/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3260e-04 - accuracy: 1.0000 - val_loss: 0.8489 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4164/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6732e-05 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4165/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0102e-04 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4166/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.8154 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4167/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.7944 - val_accuracy: 0.9344 - lr: 6.7638e-04\n","Epoch 4168/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.7514 - val_accuracy: 0.9344 - lr: 6.7638e-04\n","Epoch 4169/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6327e-05 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4170/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.1768e-05 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4171/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0850e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4172/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.5366e-04 - accuracy: 0.9996 - val_loss: 0.6977 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4173/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5116e-04 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4174/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.6726e-05 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4175/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.6990e-04 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4176/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.9248e-05 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4177/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.9098e-04 - accuracy: 0.9996 - val_loss: 0.7268 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4178/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.0105e-04 - accuracy: 0.9996 - val_loss: 0.7338 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4179/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.1935e-05 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4180/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.4490e-05 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.9359 - lr: 6.7638e-04\n","Epoch 4181/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.2938e-05 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4182/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.6073e-05 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4183/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1652e-04 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4184/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9717e-04 - accuracy: 1.0000 - val_loss: 0.7843 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4185/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.3742e-05 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4186/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.7070e-05 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4187/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.1108e-04 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4188/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4564e-04 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4189/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.8333 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4190/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.6220e-05 - accuracy: 1.0000 - val_loss: 0.8388 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4191/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0335e-04 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4192/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6144e-04 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4193/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5828e-05 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4194/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3413e-05 - accuracy: 1.0000 - val_loss: 0.8645 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4195/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.1375e-05 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4196/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0039e-04 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4197/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.3908e-05 - accuracy: 1.0000 - val_loss: 0.8835 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4198/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2697e-05 - accuracy: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4199/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.7295e-04 - accuracy: 0.9996 - val_loss: 0.8951 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4200/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6031e-04 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4201/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7093e-05 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4202/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3749e-05 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4203/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.8991 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4204/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.9131e-05 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4205/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.4538e-04 - accuracy: 0.9996 - val_loss: 0.9000 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4206/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1049e-04 - accuracy: 1.0000 - val_loss: 0.9046 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4207/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.0688e-04 - accuracy: 0.9996 - val_loss: 0.9062 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4208/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.2851e-05 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4209/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 1.2265e-04 - accuracy: 1.0000 - val_loss: 0.9057 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4210/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0277e-04 - accuracy: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4211/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3455e-05 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4212/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.3146e-04 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4213/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4209e-05 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4214/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1335e-05 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4215/30000\n","3/3 [==============================] - 0s 87ms/step - loss: 2.4733e-05 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4216/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5623e-04 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4217/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3303e-04 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4218/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.2166e-06 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4219/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4265e-04 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4220/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.1895e-05 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4221/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.9340e-05 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4222/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5549e-05 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4223/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.8773e-04 - accuracy: 0.9996 - val_loss: 0.9854 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4224/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.1280e-06 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4225/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.8083e-04 - accuracy: 0.9996 - val_loss: 0.9880 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4226/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.8657e-06 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4227/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.1904e-05 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4228/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.3530e-05 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4229/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.5327e-04 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4230/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.5695e-05 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4231/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.2924e-05 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4232/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0852e-04 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4233/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.6408e-05 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4234/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5047e-05 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4235/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.3360e-04 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4236/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.6686e-06 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4237/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3184e-04 - accuracy: 1.0000 - val_loss: 1.0101 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4238/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0033e-04 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4239/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5519e-04 - accuracy: 0.9996 - val_loss: 1.0107 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4240/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 6.9927e-05 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4241/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1821e-04 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4242/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.6293e-05 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4243/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9115e-04 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4244/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.8009e-05 - accuracy: 1.0000 - val_loss: 1.0262 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4245/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.9173e-06 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 0.9406 - lr: 6.7638e-04\n","Epoch 4246/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 1.0356 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4247/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.4074e-06 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4248/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.2392e-05 - accuracy: 1.0000 - val_loss: 1.0480 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4249/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.1668e-06 - accuracy: 1.0000 - val_loss: 1.0526 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4250/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4674e-05 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4251/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.0297e-05 - accuracy: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.9422 - lr: 6.7638e-04\n","Epoch 4252/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.0500 - val_accuracy: 0.9391 - lr: 6.7638e-04\n","Epoch 4253/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.6972e-05 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4254/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8266e-04 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.9375 - lr: 6.7638e-04\n","Epoch 4255/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7035e-05 - accuracy: 1.0000 - val_loss: 1.0395 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4256/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.2256e-05 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4257/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4123e-05 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4258/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.1369e-05 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4259/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 4.4495e-05 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4260/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.3851e-06 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4261/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 1.0502 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4262/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4360e-04 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4263/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2077e-05 - accuracy: 1.0000 - val_loss: 1.0398 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4264/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.3783e-05 - accuracy: 1.0000 - val_loss: 1.0396 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4265/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.7032e-05 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4266/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6590e-05 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4267/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.1891e-04 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4268/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.8209e-04 - accuracy: 1.0000 - val_loss: 1.0462 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4269/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.6675e-05 - accuracy: 1.0000 - val_loss: 1.0487 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4270/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.2048e-04 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4271/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9988e-06 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4272/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.8118e-06 - accuracy: 1.0000 - val_loss: 1.0535 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4273/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.6594e-05 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4274/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.0246e-05 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4275/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6016e-05 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4276/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6483e-04 - accuracy: 0.9996 - val_loss: 1.0636 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4277/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.6202e-05 - accuracy: 1.0000 - val_loss: 1.0664 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4278/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.6637e-05 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4279/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.0761e-05 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4280/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7707e-05 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4281/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.9508e-06 - accuracy: 1.0000 - val_loss: 1.0823 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4282/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8397e-05 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4283/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 6.6042e-04 - accuracy: 0.9996 - val_loss: 1.0889 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4284/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.5804e-06 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4285/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.6598e-06 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4286/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.0924 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4287/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6903e-05 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4288/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.6927e-04 - accuracy: 0.9992 - val_loss: 1.0911 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4289/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.7264e-04 - accuracy: 0.9996 - val_loss: 1.0943 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4290/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.8610e-06 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4291/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4292/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 1.0840 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4293/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 1.0539 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4294/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.9106e-04 - accuracy: 0.9996 - val_loss: 1.0309 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4295/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.5524e-05 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4296/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.1601e-05 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4297/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.0981e-04 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4298/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1615e-05 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4299/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0534e-04 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4300/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9928 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4301/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.1292e-05 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4302/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.6636e-05 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4303/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4253e-05 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4304/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4305/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8791e-04 - accuracy: 0.9996 - val_loss: 0.9969 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4306/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4521e-04 - accuracy: 0.9996 - val_loss: 1.0057 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4307/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7130e-04 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4308/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 1.0183 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4309/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 1.0113 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4310/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.9831e-05 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9359 - lr: 6.4256e-04\n","Epoch 4311/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 5.1152e-05 - accuracy: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4312/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.5566e-06 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4313/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8644e-05 - accuracy: 1.0000 - val_loss: 1.0038 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4314/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.9920 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4315/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.4045e-04 - accuracy: 0.9992 - val_loss: 0.9636 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4316/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5672e-04 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4317/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0477e-04 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4318/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1930e-04 - accuracy: 1.0000 - val_loss: 0.9362 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4319/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7062e-05 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4320/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.9327 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4321/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9162 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4322/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2115e-04 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4323/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4055e-05 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4324/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4432e-05 - accuracy: 1.0000 - val_loss: 0.9172 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4325/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.1219e-04 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4326/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.8102e-05 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4327/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.5277e-04 - accuracy: 0.9996 - val_loss: 0.9308 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4328/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7797e-05 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4329/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6959e-05 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4330/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.8797e-04 - accuracy: 0.9996 - val_loss: 0.9444 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4331/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 9.8995e-04 - accuracy: 0.9996 - val_loss: 0.9446 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4332/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.7272e-04 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4333/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0115e-04 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4334/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8896e-05 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4335/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.8086e-05 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4336/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1729e-04 - accuracy: 0.9996 - val_loss: 0.9733 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4337/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1180e-04 - accuracy: 1.0000 - val_loss: 0.9805 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4338/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.2614e-04 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4339/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3200e-05 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4340/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.3793e-05 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4341/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5540e-04 - accuracy: 1.0000 - val_loss: 1.0039 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4342/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.3143e-05 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4343/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0258e-04 - accuracy: 0.9996 - val_loss: 1.0140 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4344/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.9581e-05 - accuracy: 1.0000 - val_loss: 1.0174 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4345/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.8068e-05 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4346/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.3971e-05 - accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4347/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.4526e-04 - accuracy: 1.0000 - val_loss: 1.0292 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4348/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1361e-04 - accuracy: 1.0000 - val_loss: 1.0335 - val_accuracy: 0.9375 - lr: 6.4256e-04\n","Epoch 4349/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8259e-04 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4350/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.8140e-06 - accuracy: 1.0000 - val_loss: 1.0433 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4351/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.5284e-05 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.9391 - lr: 6.4256e-04\n","Epoch 4352/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4098e-04 - accuracy: 0.9996 - val_loss: 1.0543 - val_accuracy: 0.9406 - lr: 6.4256e-04\n","Epoch 4353/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1338e-05 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9422 - lr: 6.4256e-04\n","Epoch 4354/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.2310e-04 - accuracy: 0.9996 - val_loss: 1.0621 - val_accuracy: 0.9422 - lr: 6.4256e-04\n","Epoch 4355/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3479e-05 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4356/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 8.8271e-06 - accuracy: 1.0000 - val_loss: 1.0578 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4357/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7464e-05 - accuracy: 1.0000 - val_loss: 1.0578 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4358/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.0036e-06 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4359/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3938e-04 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4360/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4808e-05 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4361/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.0898e-05 - accuracy: 1.0000 - val_loss: 1.0718 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4362/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.1228e-05 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4363/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.5375e-04 - accuracy: 0.9996 - val_loss: 1.0843 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4364/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 1.0485 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4365/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.4852e-06 - accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4366/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.0698e-05 - accuracy: 1.0000 - val_loss: 1.0104 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4367/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0702e-04 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4368/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0022e-05 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4369/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.7577e-04 - accuracy: 0.9996 - val_loss: 0.9892 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4370/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3902e-05 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4371/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.3265e-04 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.9359 - lr: 6.1043e-04\n","Epoch 4372/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.2819e-04 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4373/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.0858e-04 - accuracy: 0.9996 - val_loss: 0.9949 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4374/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2973e-05 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4375/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.3364e-05 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4376/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 9.7499e-05 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4377/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6087e-04 - accuracy: 0.9996 - val_loss: 1.0168 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4378/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0520e-04 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4379/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8697e-04 - accuracy: 0.9996 - val_loss: 1.0242 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4380/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.7278e-04 - accuracy: 0.9996 - val_loss: 1.0292 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4381/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.2624e-05 - accuracy: 1.0000 - val_loss: 1.0344 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4382/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.8587e-05 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4383/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1122e-04 - accuracy: 1.0000 - val_loss: 1.0478 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4384/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9788e-04 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4385/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3310e-04 - accuracy: 1.0000 - val_loss: 1.0727 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4386/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9835e-04 - accuracy: 1.0000 - val_loss: 1.0888 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4387/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6049e-05 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4388/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6887e-05 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4389/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4144e-05 - accuracy: 1.0000 - val_loss: 1.1229 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4390/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8634e-05 - accuracy: 1.0000 - val_loss: 1.1309 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4391/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.2670e-06 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4392/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7250e-05 - accuracy: 1.0000 - val_loss: 1.1425 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4393/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1174e-04 - accuracy: 0.9996 - val_loss: 1.1416 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4394/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.1701e-04 - accuracy: 1.0000 - val_loss: 1.1342 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4395/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.1241 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4396/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.8647e-04 - accuracy: 0.9992 - val_loss: 1.1157 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4397/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1133e-04 - accuracy: 0.9996 - val_loss: 1.1077 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4398/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.7510e-05 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4399/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2988e-05 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4400/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.3413e-04 - accuracy: 0.9996 - val_loss: 1.1069 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4401/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0404e-04 - accuracy: 1.0000 - val_loss: 1.1137 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4402/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1101e-06 - accuracy: 1.0000 - val_loss: 1.1198 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4403/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7928e-04 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4404/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.1615e-05 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4405/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.8861e-04 - accuracy: 0.9996 - val_loss: 1.1368 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4406/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2538e-04 - accuracy: 1.0000 - val_loss: 1.1421 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4407/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3662e-05 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4408/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 1.1537 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4409/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4410/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.9318e-05 - accuracy: 1.0000 - val_loss: 1.1665 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4411/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.7783e-05 - accuracy: 1.0000 - val_loss: 1.1729 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4412/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.4443e-06 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4413/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.7188e-06 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4414/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.3599e-04 - accuracy: 0.9996 - val_loss: 1.1874 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4415/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0670e-04 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4416/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.4837e-05 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4417/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5538e-05 - accuracy: 1.0000 - val_loss: 1.2080 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4418/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.2055 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4419/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.6879e-06 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4420/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.5964e-04 - accuracy: 1.0000 - val_loss: 1.2053 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4421/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 1.1873 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4422/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3082e-04 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4423/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8896e-04 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4424/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9687e-05 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4425/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1566e-05 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4426/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.1446 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4427/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.1249 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4428/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.7518e-05 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4429/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7059e-05 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4430/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.6040e-04 - accuracy: 0.9996 - val_loss: 1.0816 - val_accuracy: 0.9375 - lr: 6.1043e-04\n","Epoch 4431/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.5332e-04 - accuracy: 0.9996 - val_loss: 1.0716 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4432/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.0070e-05 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4433/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.3846e-05 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4434/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.0444e-05 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4435/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.8538e-05 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4436/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.0574 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4437/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.6055e-04 - accuracy: 0.9996 - val_loss: 1.0480 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4438/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1860e-05 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.9438 - lr: 6.1043e-04\n","Epoch 4439/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1453e-05 - accuracy: 1.0000 - val_loss: 1.0459 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4440/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.0387 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4441/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.2000e-05 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4442/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.9969e-04 - accuracy: 0.9996 - val_loss: 1.0231 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4443/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 3.9594e-05 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4444/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.1431e-04 - accuracy: 0.9996 - val_loss: 1.0095 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4445/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1296e-04 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4446/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.7205e-05 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.9422 - lr: 6.1043e-04\n","Epoch 4447/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5991e-04 - accuracy: 1.0000 - val_loss: 1.0019 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4448/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3172e-04 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4449/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.7649e-04 - accuracy: 0.9996 - val_loss: 1.0073 - val_accuracy: 0.9406 - lr: 6.1043e-04\n","Epoch 4450/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.7360e-04 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4451/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4919e-04 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4452/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.1986e-04 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4453/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0614e-04 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4454/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.5348e-04 - accuracy: 1.0000 - val_loss: 1.0295 - val_accuracy: 0.9391 - lr: 6.1043e-04\n","Epoch 4455/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.1620e-04 - accuracy: 1.0000 - val_loss: 1.0376 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4456/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7369e-05 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4457/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6062e-04 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4458/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1874e-04 - accuracy: 1.0000 - val_loss: 1.0593 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4459/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.0267e-05 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4460/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5595e-04 - accuracy: 0.9996 - val_loss: 1.0686 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4461/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0070e-04 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4462/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9353e-05 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4463/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.9611e-04 - accuracy: 0.9996 - val_loss: 1.0785 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4464/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.3323e-04 - accuracy: 1.0000 - val_loss: 1.0808 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4465/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.9325e-04 - accuracy: 0.9996 - val_loss: 1.0780 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4466/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.0660 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4467/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.0368 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4468/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.2684e-04 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4469/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0665e-05 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4470/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.2325e-05 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4471/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5508e-04 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4472/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3398e-05 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.9359 - lr: 5.7991e-04\n","Epoch 4473/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4068e-05 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.9359 - lr: 5.7991e-04\n","Epoch 4474/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 3.4422e-04 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.9359 - lr: 5.7991e-04\n","Epoch 4475/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.2928e-05 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4476/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 7.2456e-05 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4477/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.5356e-04 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4478/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5141e-05 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4479/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0717e-04 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4480/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.9972 - val_accuracy: 0.9359 - lr: 5.7991e-04\n","Epoch 4481/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8294e-05 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4482/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0716e-04 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4483/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0313e-04 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4484/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7397e-05 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.9375 - lr: 5.7991e-04\n","Epoch 4485/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3927e-05 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4486/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.1019e-04 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4487/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7120e-05 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4488/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.3839e-04 - accuracy: 0.9996 - val_loss: 0.9300 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4489/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0907e-05 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4490/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4829e-04 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4491/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0446e-04 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4492/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7084e-04 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4493/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2573e-05 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4494/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2639e-04 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4495/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8006e-06 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4496/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.8058e-04 - accuracy: 0.9996 - val_loss: 0.9647 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4497/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.7794e-05 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4498/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0181e-05 - accuracy: 1.0000 - val_loss: 0.9786 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4499/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.6089e-04 - accuracy: 0.9996 - val_loss: 0.9860 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4500/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.5533e-04 - accuracy: 0.9996 - val_loss: 0.9890 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4501/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0846e-04 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4502/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.1251e-04 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4503/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7045e-04 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4504/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.9976 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4505/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.0324e-04 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.9391 - lr: 5.7991e-04\n","Epoch 4506/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.6836e-05 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4507/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7411e-05 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4508/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6394e-06 - accuracy: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4509/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6662e-05 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4510/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.8278e-05 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4511/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.7527e-04 - accuracy: 0.9996 - val_loss: 1.0020 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4512/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.4268e-05 - accuracy: 1.0000 - val_loss: 1.0057 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4513/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.5799e-06 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4514/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1793e-06 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4515/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.3063e-05 - accuracy: 1.0000 - val_loss: 1.0186 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4516/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.5121e-04 - accuracy: 0.9996 - val_loss: 1.0231 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4517/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.1227e-04 - accuracy: 0.9996 - val_loss: 1.0327 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4518/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3422e-05 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4519/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.7475e-06 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4520/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2228e-05 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4521/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5617e-05 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4522/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.9422 - lr: 5.7991e-04\n","Epoch 4523/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0732e-04 - accuracy: 1.0000 - val_loss: 1.0741 - val_accuracy: 0.9422 - lr: 5.7991e-04\n","Epoch 4524/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5700e-04 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4525/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4530e-05 - accuracy: 1.0000 - val_loss: 1.0897 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4526/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6006e-05 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4527/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5146e-04 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4528/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5005e-05 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4529/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.6259e-05 - accuracy: 1.0000 - val_loss: 1.1151 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4530/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2313e-05 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4531/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.1589e-06 - accuracy: 1.0000 - val_loss: 1.1253 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4532/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6627e-06 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4533/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.1475e-06 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4534/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.1253e-06 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4535/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.2128e-04 - accuracy: 0.9996 - val_loss: 1.1385 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4536/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.9304e-06 - accuracy: 1.0000 - val_loss: 1.1418 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4537/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0815e-04 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4538/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2859e-05 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4539/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4840e-04 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4540/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.0509e-04 - accuracy: 1.0000 - val_loss: 1.1544 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4541/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.7397e-05 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4542/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 5.7339e-06 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4543/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.7630e-05 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4544/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3006e-05 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4545/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.4634e-05 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4546/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0563e-06 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4547/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.0177e-05 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4548/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 6.2339e-05 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4549/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.1479e-06 - accuracy: 1.0000 - val_loss: 1.1909 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4550/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 7.2359e-06 - accuracy: 1.0000 - val_loss: 1.1941 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4551/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2484e-06 - accuracy: 1.0000 - val_loss: 1.1968 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4552/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3220e-05 - accuracy: 1.0000 - val_loss: 1.1997 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4553/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.2367e-06 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4554/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 6.9113e-06 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.9406 - lr: 5.7991e-04\n","Epoch 4555/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 6.1200e-07 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4556/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 1.2000 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4557/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7052e-05 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4558/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4991e-06 - accuracy: 1.0000 - val_loss: 1.1956 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4559/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.3926e-05 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4560/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6034e-06 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4561/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.8849e-05 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4562/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1583e-05 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4563/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.0898e-06 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4564/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.5814e-05 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4565/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4360e-04 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4566/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.0087e-05 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4567/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.3923e-05 - accuracy: 1.0000 - val_loss: 1.2225 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4568/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.2161 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4569/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.6605e-06 - accuracy: 1.0000 - val_loss: 1.2128 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4570/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2009e-05 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4571/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.4334e-06 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4572/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8020e-04 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4573/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.6547e-04 - accuracy: 1.0000 - val_loss: 1.2119 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4574/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.6794e-06 - accuracy: 1.0000 - val_loss: 1.2128 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4575/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.4382e-06 - accuracy: 1.0000 - val_loss: 1.2139 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4576/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2889e-06 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4577/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7975e-06 - accuracy: 1.0000 - val_loss: 1.2159 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4578/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0203e-05 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4579/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.8641e-04 - accuracy: 1.0000 - val_loss: 1.2203 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4580/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6972e-05 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4581/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.9703e-06 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4582/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.1164e-04 - accuracy: 0.9996 - val_loss: 1.2271 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4583/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0341e-05 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4584/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0454e-05 - accuracy: 1.0000 - val_loss: 1.2265 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4585/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8524e-04 - accuracy: 0.9996 - val_loss: 1.2310 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4586/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.2968e-05 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4587/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.1722e-06 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4588/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.8170e-06 - accuracy: 1.0000 - val_loss: 1.2423 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4589/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6131e-04 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4590/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 1.2442 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4591/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3715e-04 - accuracy: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4592/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0484e-05 - accuracy: 1.0000 - val_loss: 1.2361 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4593/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3599e-04 - accuracy: 1.0000 - val_loss: 1.2351 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4594/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8918e-05 - accuracy: 1.0000 - val_loss: 1.2361 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4595/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3949e-04 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4596/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 1.2050 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4597/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6690e-05 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4598/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.6595e-06 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4599/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.1510e-06 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4600/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8044e-05 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4601/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.4946e-05 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4602/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7911e-04 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4603/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.1597e-06 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4604/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 8.3349e-05 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4605/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7452e-06 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4606/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 1.0839 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4607/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.7520e-04 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4608/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.8145e-05 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4609/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0072e-05 - accuracy: 1.0000 - val_loss: 1.0539 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4610/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.2076e-05 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4611/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8339e-05 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4612/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.4093e-04 - accuracy: 0.9996 - val_loss: 1.0484 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4613/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.9227e-04 - accuracy: 0.9996 - val_loss: 1.0387 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4614/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.6322e-04 - accuracy: 1.0000 - val_loss: 1.0342 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4615/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.8535e-04 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4616/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 9.5125e-04 - accuracy: 0.9996 - val_loss: 1.0309 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4617/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.6667e-06 - accuracy: 1.0000 - val_loss: 1.0292 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4618/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4619e-04 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4619/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9509e-04 - accuracy: 1.0000 - val_loss: 1.0319 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4620/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6148e-04 - accuracy: 0.9996 - val_loss: 1.0402 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4621/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.5356e-05 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4622/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 1.0578 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4623/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3027e-05 - accuracy: 1.0000 - val_loss: 1.0650 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4624/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7126e-04 - accuracy: 1.0000 - val_loss: 1.0721 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4625/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.0023e-04 - accuracy: 0.9996 - val_loss: 1.0793 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4626/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.5627e-06 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4627/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5701e-05 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4628/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.1660e-05 - accuracy: 1.0000 - val_loss: 1.0967 - val_accuracy: 0.9406 - lr: 5.5092e-04\n","Epoch 4629/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.2096e-06 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4630/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.0795e-04 - accuracy: 0.9996 - val_loss: 1.1059 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4631/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8267e-05 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4632/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 1.1009 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4633/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0817e-04 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.9391 - lr: 5.5092e-04\n","Epoch 4634/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0840e-04 - accuracy: 0.9996 - val_loss: 1.0724 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4635/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.1103e-04 - accuracy: 0.9996 - val_loss: 1.0645 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4636/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8006e-05 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4637/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1099e-04 - accuracy: 1.0000 - val_loss: 1.0587 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4638/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7810e-05 - accuracy: 1.0000 - val_loss: 1.0588 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4639/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4772e-05 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4640/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 6.4536e-05 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4641/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.3947e-05 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4642/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.0799e-06 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4643/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6596e-05 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4644/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.7677e-05 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4645/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.4824e-04 - accuracy: 0.9996 - val_loss: 1.0831 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4646/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1971e-04 - accuracy: 0.9996 - val_loss: 1.0855 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4647/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.0877e-06 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4648/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7244e-04 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4649/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.7229e-06 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9359 - lr: 5.5092e-04\n","Epoch 4650/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2751e-04 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4651/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9779e-04 - accuracy: 0.9996 - val_loss: 1.0993 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4652/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.5779e-06 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4653/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.1832e-05 - accuracy: 1.0000 - val_loss: 1.1047 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4654/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9605e-05 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.9375 - lr: 5.5092e-04\n","Epoch 4655/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.1858e-06 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4656/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.0205e-06 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4657/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.3689e-05 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4658/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.1169e-06 - accuracy: 1.0000 - val_loss: 1.1166 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4659/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1037e-05 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4660/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.5732e-04 - accuracy: 0.9996 - val_loss: 1.1209 - val_accuracy: 0.9375 - lr: 5.2337e-04\n","Epoch 4661/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 1.1024 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4662/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.0716e-04 - accuracy: 0.9996 - val_loss: 1.0874 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4663/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9630e-04 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4664/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5089e-05 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4665/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.9956e-05 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4666/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.0261e-05 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4667/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.5325e-05 - accuracy: 1.0000 - val_loss: 1.0717 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4668/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1434e-05 - accuracy: 1.0000 - val_loss: 1.0723 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4669/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.2415e-04 - accuracy: 0.9996 - val_loss: 1.0744 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4670/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.0677 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4671/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.2907e-05 - accuracy: 1.0000 - val_loss: 1.0479 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4672/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4094e-04 - accuracy: 0.9996 - val_loss: 1.0356 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4673/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.2657e-05 - accuracy: 1.0000 - val_loss: 1.0281 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4674/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 1.0177 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4675/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5534e-05 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4676/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.1859e-05 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4677/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1614e-04 - accuracy: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4678/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.9697e-04 - accuracy: 1.0000 - val_loss: 1.0043 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4679/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.7733e-04 - accuracy: 0.9996 - val_loss: 1.0109 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4680/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0947e-05 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4681/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5846e-04 - accuracy: 1.0000 - val_loss: 1.0245 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4682/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.9548e-05 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4683/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6333e-05 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4684/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.9568e-04 - accuracy: 0.9996 - val_loss: 1.0483 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4685/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4422e-05 - accuracy: 1.0000 - val_loss: 1.0523 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4686/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0782e-04 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4687/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.6083e-05 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4688/30000\n","3/3 [==============================] - 0s 87ms/step - loss: 9.8346e-05 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4689/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.2905e-05 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4690/30000\n","3/3 [==============================] - 0s 88ms/step - loss: 3.0782e-04 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4691/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7154e-05 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4692/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8146e-05 - accuracy: 1.0000 - val_loss: 1.1315 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4693/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.5776e-04 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4694/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.9152e-05 - accuracy: 1.0000 - val_loss: 1.1466 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4695/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.0310e-05 - accuracy: 1.0000 - val_loss: 1.1538 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4696/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8461e-05 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4697/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7884e-04 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4698/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4626e-04 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4699/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.9914e-04 - accuracy: 0.9996 - val_loss: 1.1780 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4700/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.7804e-04 - accuracy: 0.9996 - val_loss: 1.1895 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4701/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9879e-05 - accuracy: 1.0000 - val_loss: 1.2006 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4702/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.6500e-04 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4703/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.7027e-06 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4704/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3349e-04 - accuracy: 0.9996 - val_loss: 1.2239 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4705/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.4298e-05 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4706/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1341e-04 - accuracy: 0.9996 - val_loss: 1.2334 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4707/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2968e-04 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4708/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.0378e-04 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4709/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7129e-05 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4710/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2393e-04 - accuracy: 0.9996 - val_loss: 1.2498 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4711/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4682e-04 - accuracy: 1.0000 - val_loss: 1.2550 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4712/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1047e-05 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4713/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 6.6253e-05 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4714/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.9194e-04 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4715/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 5.1044e-05 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4716/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4717/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 8.3677e-04 - accuracy: 0.9996 - val_loss: 1.3004 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4718/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.7503e-05 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4719/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.3787e-05 - accuracy: 1.0000 - val_loss: 1.3019 - val_accuracy: 0.9406 - lr: 5.2337e-04\n","Epoch 4720/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.0919e-06 - accuracy: 1.0000 - val_loss: 1.3038 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4721/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0857e-04 - accuracy: 1.0000 - val_loss: 1.3071 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4722/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.7047e-05 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4723/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.5491e-05 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4724/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3497e-05 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4725/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4188e-05 - accuracy: 1.0000 - val_loss: 1.3312 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4726/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4380e-04 - accuracy: 1.0000 - val_loss: 1.3365 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4727/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6679e-05 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4728/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4196e-05 - accuracy: 1.0000 - val_loss: 1.3450 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4729/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.3469 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4730/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4508e-04 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4731/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.6077e-04 - accuracy: 0.9996 - val_loss: 1.3480 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4732/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7575e-04 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.9422 - lr: 5.2337e-04\n","Epoch 4733/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4514e-05 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4734/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8711e-04 - accuracy: 0.9996 - val_loss: 1.3450 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4735/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2350e-05 - accuracy: 1.0000 - val_loss: 1.3450 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4736/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0039e-04 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4737/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6187e-05 - accuracy: 1.0000 - val_loss: 1.3490 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4738/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.0017e-05 - accuracy: 1.0000 - val_loss: 1.3517 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4739/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.8033e-05 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4740/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.9044e-05 - accuracy: 1.0000 - val_loss: 1.3586 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4741/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.8889e-05 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4742/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0116e-05 - accuracy: 1.0000 - val_loss: 1.3680 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4743/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.3936e-05 - accuracy: 1.0000 - val_loss: 1.3725 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4744/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.3386 - val_accuracy: 0.9438 - lr: 5.2337e-04\n","Epoch 4745/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.3118 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4746/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2292e-05 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4747/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3706e-05 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4748/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4725e-05 - accuracy: 1.0000 - val_loss: 1.2695 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4749/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8653e-05 - accuracy: 1.0000 - val_loss: 1.2635 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4750/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7364e-04 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4751/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0596e-05 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4752/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.2411 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4753/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6034e-04 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4754/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0443e-05 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.9453 - lr: 5.2337e-04\n","Epoch 4755/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.6522e-05 - accuracy: 1.0000 - val_loss: 1.2096 - val_accuracy: 0.9469 - lr: 4.9720e-04\n","Epoch 4756/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.7754e-05 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4757/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.7007e-05 - accuracy: 1.0000 - val_loss: 1.2077 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4758/30000\n","3/3 [==============================] - 0s 89ms/step - loss: 3.4030e-05 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4759/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0014e-05 - accuracy: 1.0000 - val_loss: 1.2091 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4760/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.9201e-06 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4761/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.7504e-06 - accuracy: 1.0000 - val_loss: 1.2128 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4762/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3480e-05 - accuracy: 1.0000 - val_loss: 1.2159 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4763/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0140e-04 - accuracy: 1.0000 - val_loss: 1.2209 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4764/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4676e-06 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.9453 - lr: 4.9720e-04\n","Epoch 4765/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.3474e-05 - accuracy: 1.0000 - val_loss: 1.2279 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4766/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3036e-05 - accuracy: 1.0000 - val_loss: 1.2315 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4767/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.4327e-04 - accuracy: 1.0000 - val_loss: 1.2365 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4768/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.6049e-06 - accuracy: 1.0000 - val_loss: 1.2408 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4769/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.5489e-06 - accuracy: 1.0000 - val_loss: 1.2440 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4770/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.0487e-05 - accuracy: 1.0000 - val_loss: 1.2473 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4771/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.3317e-06 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4772/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1692e-05 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4773/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4886e-05 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4774/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1603e-04 - accuracy: 0.9996 - val_loss: 1.2608 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4775/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.3836e-05 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4776/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 1.2397 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4777/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.0619e-05 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4778/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8336e-04 - accuracy: 0.9996 - val_loss: 1.1981 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4779/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8946e-05 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4780/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6499e-05 - accuracy: 1.0000 - val_loss: 1.1804 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4781/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.2840e-04 - accuracy: 0.9996 - val_loss: 1.1738 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4782/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.8764e-05 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4783/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.7838e-05 - accuracy: 1.0000 - val_loss: 1.1677 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4784/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.5601e-05 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4785/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.2445e-05 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4786/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0271e-05 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4787/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 6.6541e-04 - accuracy: 0.9996 - val_loss: 1.1748 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4788/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.1773 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4789/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 1.1770 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4790/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3856e-05 - accuracy: 1.0000 - val_loss: 1.1734 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4791/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.6077e-04 - accuracy: 0.9996 - val_loss: 1.1668 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4792/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0678e-04 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4793/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.6916e-04 - accuracy: 0.9996 - val_loss: 1.1580 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4794/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0194e-05 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4795/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2958e-05 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4796/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.2498e-06 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4797/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.3856e-05 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4798/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.8404e-05 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4799/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.5562e-04 - accuracy: 0.9992 - val_loss: 1.1658 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4800/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.4140e-05 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4801/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3142e-04 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4802/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.5471e-05 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4803/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.6624e-05 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4804/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.1099e-05 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4805/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.2465e-06 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4806/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.8729e-06 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4807/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 3.3687e-04 - accuracy: 1.0000 - val_loss: 1.2062 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4808/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.2980e-05 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4809/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.2374e-04 - accuracy: 0.9996 - val_loss: 1.2142 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4810/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2767e-05 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4811/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.9891e-06 - accuracy: 1.0000 - val_loss: 1.2197 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4812/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.5783e-04 - accuracy: 0.9996 - val_loss: 1.2136 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4813/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.7983e-05 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4814/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0951e-04 - accuracy: 0.9996 - val_loss: 1.1846 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4815/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.9239e-05 - accuracy: 1.0000 - val_loss: 1.1797 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4816/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.7833e-05 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4817/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3247e-04 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4818/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 1.1701 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4819/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.5779e-05 - accuracy: 1.0000 - val_loss: 1.1656 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4820/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.8814e-05 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4821/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.1219e-04 - accuracy: 0.9996 - val_loss: 1.1610 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4822/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7154e-04 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4823/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.6830e-05 - accuracy: 1.0000 - val_loss: 1.1593 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4824/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0667e-05 - accuracy: 1.0000 - val_loss: 1.1600 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4825/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 1.0376e-04 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4826/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.5544e-06 - accuracy: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4827/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1632e-04 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.9438 - lr: 4.9720e-04\n","Epoch 4828/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.7996e-05 - accuracy: 1.0000 - val_loss: 1.1647 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4829/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0137e-05 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4830/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9176e-05 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4831/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.8124e-05 - accuracy: 1.0000 - val_loss: 1.1718 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4832/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.5318e-04 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4833/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.3721e-05 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4834/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.5307e-05 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4835/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.3821e-05 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4836/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.8828e-05 - accuracy: 1.0000 - val_loss: 1.1891 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4837/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 6.2507e-05 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4838/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 1.1979 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4839/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.5039e-05 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4840/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.1199e-05 - accuracy: 1.0000 - val_loss: 1.2069 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4841/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.1999e-06 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4842/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.1068e-04 - accuracy: 0.9996 - val_loss: 1.2066 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4843/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.5452e-06 - accuracy: 1.0000 - val_loss: 1.2016 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4844/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0181e-05 - accuracy: 1.0000 - val_loss: 1.1990 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4845/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.4010e-04 - accuracy: 0.9996 - val_loss: 1.1944 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4846/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.1885 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4847/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.8858e-06 - accuracy: 1.0000 - val_loss: 1.1847 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4848/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4341e-05 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4849/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.8455e-05 - accuracy: 1.0000 - val_loss: 1.1846 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4850/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6235e-04 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.9406 - lr: 4.9720e-04\n","Epoch 4851/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.2041e-05 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4852/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.0471e-04 - accuracy: 0.9996 - val_loss: 1.1813 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4853/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.3751e-05 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4854/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8134e-04 - accuracy: 1.0000 - val_loss: 1.1574 - val_accuracy: 0.9422 - lr: 4.9720e-04\n","Epoch 4855/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9312e-05 - accuracy: 1.0000 - val_loss: 1.1506 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4856/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.3494e-04 - accuracy: 0.9996 - val_loss: 1.1432 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4857/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0772e-04 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4858/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.5971e-04 - accuracy: 1.0000 - val_loss: 1.1347 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4859/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5154e-05 - accuracy: 1.0000 - val_loss: 1.1346 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4860/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.3219e-04 - accuracy: 0.9996 - val_loss: 1.1335 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4861/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7734e-05 - accuracy: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4862/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.0165e-05 - accuracy: 1.0000 - val_loss: 1.1348 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4863/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.7166e-04 - accuracy: 0.9996 - val_loss: 1.1379 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4864/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 1.6135e-05 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4865/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.1426 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4866/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4853e-05 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4867/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1378e-05 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4868/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8169e-05 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4869/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0650e-04 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4870/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4584e-04 - accuracy: 0.9996 - val_loss: 1.1586 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4871/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.6440e-05 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4872/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1931e-04 - accuracy: 0.9996 - val_loss: 1.1691 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4873/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7831e-05 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4874/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0058e-04 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4875/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.8663e-06 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4876/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.6613e-05 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4877/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.0866e-04 - accuracy: 0.9996 - val_loss: 1.1773 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4878/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9240e-04 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4879/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.9472e-06 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4880/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.1532e-05 - accuracy: 1.0000 - val_loss: 1.1917 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4881/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0423e-05 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4882/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1368e-05 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4883/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.7029e-06 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4884/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.1413e-05 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4885/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.7810e-04 - accuracy: 1.0000 - val_loss: 1.2103 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4886/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8566e-05 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4887/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.2239e-06 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4888/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.0987e-05 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4889/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.3432e-06 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4890/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0624e-05 - accuracy: 1.0000 - val_loss: 1.2413 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4891/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.3575e-04 - accuracy: 0.9996 - val_loss: 1.2440 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4892/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5814e-04 - accuracy: 1.0000 - val_loss: 1.2467 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4893/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.4346e-05 - accuracy: 1.0000 - val_loss: 1.2508 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4894/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.7907e-04 - accuracy: 0.9996 - val_loss: 1.2456 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4895/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.7388e-06 - accuracy: 1.0000 - val_loss: 1.2418 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4896/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 9.5379e-04 - accuracy: 0.9996 - val_loss: 1.2375 - val_accuracy: 0.9438 - lr: 4.7234e-04\n","Epoch 4897/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0179e-05 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.9438 - lr: 4.7234e-04\n","Epoch 4898/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 1.1974 - val_accuracy: 0.9438 - lr: 4.7234e-04\n","Epoch 4899/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0301e-04 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4900/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.0789e-05 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4901/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0225e-05 - accuracy: 1.0000 - val_loss: 1.1195 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4902/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4596e-05 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4903/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.2594e-06 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4904/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.0809e-06 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4905/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 8.1131e-04 - accuracy: 0.9996 - val_loss: 1.0899 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4906/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2258e-05 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4907/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0959e-04 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4908/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.6787e-05 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4909/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7393e-05 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4910/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.2265e-05 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4911/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.6535e-05 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4912/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.6720e-05 - accuracy: 1.0000 - val_loss: 1.0916 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4913/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.8420e-04 - accuracy: 0.9996 - val_loss: 1.0917 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4914/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4150e-04 - accuracy: 0.9996 - val_loss: 1.0873 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4915/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1817e-05 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4916/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.9916e-04 - accuracy: 0.9996 - val_loss: 1.0827 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4917/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 1.0702 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4918/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.5775e-06 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4919/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.9499e-06 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4920/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5268e-04 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4921/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.6279e-05 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4922/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7812e-04 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4923/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.8834e-06 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4924/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.0328 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4925/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.5205e-05 - accuracy: 1.0000 - val_loss: 1.0286 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4926/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7741e-05 - accuracy: 1.0000 - val_loss: 1.0278 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4927/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0595e-05 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4928/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2759e-05 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4929/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4277e-05 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4930/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.0377e-06 - accuracy: 1.0000 - val_loss: 1.0343 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4931/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0168e-05 - accuracy: 1.0000 - val_loss: 1.0363 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4932/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6818e-05 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4933/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3584e-05 - accuracy: 1.0000 - val_loss: 1.0418 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4934/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5048e-04 - accuracy: 1.0000 - val_loss: 1.0451 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4935/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9092e-05 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4936/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.5042e-04 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4937/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.6380e-05 - accuracy: 1.0000 - val_loss: 1.0534 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4938/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.2216e-05 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4939/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6067e-05 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4940/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0295e-06 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4941/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.9563e-05 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4942/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0227e-05 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4943/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.6306e-04 - accuracy: 0.9996 - val_loss: 1.0732 - val_accuracy: 0.9422 - lr: 4.7234e-04\n","Epoch 4944/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2406e-05 - accuracy: 1.0000 - val_loss: 1.0763 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4945/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3799e-05 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4946/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.3531e-06 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4947/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.4147e-06 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4948/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.1809e-05 - accuracy: 1.0000 - val_loss: 1.0855 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4949/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 2.2501e-04 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.9391 - lr: 4.7234e-04\n","Epoch 4950/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1934e-04 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4951/30000\n","3/3 [==============================] - 0s 74ms/step - loss: 3.1879e-06 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4952/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4553e-05 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4953/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.9665e-06 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4954/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5377e-04 - accuracy: 1.0000 - val_loss: 1.1173 - val_accuracy: 0.9406 - lr: 4.7234e-04\n","Epoch 4955/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 6.5727e-06 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4956/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4872e-05 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 4957/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.4973e-06 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4958/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0304e-04 - accuracy: 1.0000 - val_loss: 1.1398 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4959/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.6829e-04 - accuracy: 1.0000 - val_loss: 1.1458 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4960/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4166e-05 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4961/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 3.8807e-05 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4962/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9050e-06 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4963/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0459e-05 - accuracy: 1.0000 - val_loss: 1.1656 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4964/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2095e-05 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4965/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3599e-05 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4966/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.6665e-05 - accuracy: 1.0000 - val_loss: 1.1740 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4967/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6204e-04 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4968/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5743e-05 - accuracy: 1.0000 - val_loss: 1.1796 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4969/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.9132e-06 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4970/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4247e-05 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4971/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.4256e-05 - accuracy: 1.0000 - val_loss: 1.1864 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4972/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.3131e-04 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4973/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 6.5221e-06 - accuracy: 1.0000 - val_loss: 1.1930 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4974/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.9536e-06 - accuracy: 1.0000 - val_loss: 1.1960 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4975/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9428e-06 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4976/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.6124e-06 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4977/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.8993e-04 - accuracy: 0.9996 - val_loss: 1.1943 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4978/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0783e-05 - accuracy: 1.0000 - val_loss: 1.1904 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4979/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.0878e-04 - accuracy: 1.0000 - val_loss: 1.1882 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4980/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2746e-06 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4981/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8667e-05 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4982/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.6835e-06 - accuracy: 1.0000 - val_loss: 1.1888 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4983/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.1736e-05 - accuracy: 1.0000 - val_loss: 1.1898 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4984/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 7.8112e-05 - accuracy: 1.0000 - val_loss: 1.1916 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4985/30000\n","3/3 [==============================] - 0s 89ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.1898 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4986/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.2639e-05 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4987/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.6072e-05 - accuracy: 1.0000 - val_loss: 1.1877 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4988/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.7400e-06 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4989/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5268e-04 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4990/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.6975e-06 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4991/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4960e-06 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4992/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.8069e-06 - accuracy: 1.0000 - val_loss: 1.1997 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4993/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.3106e-05 - accuracy: 1.0000 - val_loss: 1.2016 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4994/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.8376e-05 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4995/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7992e-05 - accuracy: 1.0000 - val_loss: 1.2067 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4996/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2629e-06 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4997/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.1999 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 4998/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8226e-05 - accuracy: 1.0000 - val_loss: 1.1890 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 4999/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 1.1264 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5000/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.8422e-04 - accuracy: 0.9996 - val_loss: 1.0855 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5001/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.3920e-06 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5002/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.5064e-06 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5003/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.1421e-06 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5004/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0818e-05 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5005/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9949 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5006/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1523e-05 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5007/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.3007e-04 - accuracy: 0.9996 - val_loss: 0.9601 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5008/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.2820e-06 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5009/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.9319e-04 - accuracy: 0.9996 - val_loss: 0.9483 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5010/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.9362 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5011/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.9961e-04 - accuracy: 1.0000 - val_loss: 0.9289 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5012/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.9838e-05 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5013/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2518e-05 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5014/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.0542e-04 - accuracy: 1.0000 - val_loss: 0.9264 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5015/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.0387e-05 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5016/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.9235 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5017/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.9062e-05 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5018/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5833e-05 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5019/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7214e-05 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5020/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4132e-05 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5021/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0210e-04 - accuracy: 1.0000 - val_loss: 0.9333 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5022/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4722e-04 - accuracy: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5023/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.0827e-04 - accuracy: 0.9996 - val_loss: 0.9428 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5024/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.4768e-04 - accuracy: 0.9996 - val_loss: 0.9482 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5025/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1009e-05 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5026/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.2165e-06 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5027/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.7452e-04 - accuracy: 0.9992 - val_loss: 0.9658 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5028/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0413e-04 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5029/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.7806e-05 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5030/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.9838e-05 - accuracy: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5031/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0224e-04 - accuracy: 0.9996 - val_loss: 0.9779 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5032/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.3606e-05 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5033/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.4971e-06 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5034/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.1413e-06 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5035/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9262e-04 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5036/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.8031e-05 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5037/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2514e-05 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5038/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.8665e-05 - accuracy: 1.0000 - val_loss: 0.9948 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5039/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.9983e-05 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5040/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.0003 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5041/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.5547e-04 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.9375 - lr: 4.4872e-04\n","Epoch 5042/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.9805 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5043/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4299e-05 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.9391 - lr: 4.4872e-04\n","Epoch 5044/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.0005e-05 - accuracy: 1.0000 - val_loss: 0.9518 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5045/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.4157e-06 - accuracy: 1.0000 - val_loss: 0.9453 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5046/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.2747e-06 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5047/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 8.6146e-05 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5048/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.5107e-05 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5049/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.8855e-05 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5050/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9927e-05 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5051/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.7102e-04 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5052/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.2212e-05 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5053/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 3.1643e-06 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.9422 - lr: 4.4872e-04\n","Epoch 5054/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6163e-04 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.9406 - lr: 4.4872e-04\n","Epoch 5055/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7775e-05 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5056/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.7527e-06 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5057/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.3976e-05 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5058/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.5891e-06 - accuracy: 1.0000 - val_loss: 0.9841 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5059/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.7137e-05 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5060/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.9693e-04 - accuracy: 0.9996 - val_loss: 0.9898 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5061/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.8377e-04 - accuracy: 0.9996 - val_loss: 0.9926 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5062/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.0230e-05 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5063/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.3750e-04 - accuracy: 0.9996 - val_loss: 0.9962 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5064/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3830e-05 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5065/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.0776e-04 - accuracy: 0.9996 - val_loss: 0.9835 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5066/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5846e-06 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5067/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6196e-04 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5068/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.4222e-05 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5069/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.5313e-05 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5070/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.9851e-04 - accuracy: 0.9996 - val_loss: 0.9893 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5071/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.8181e-05 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5072/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 6.5348e-05 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5073/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6492e-05 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5074/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4295e-04 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5075/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.4862e-06 - accuracy: 1.0000 - val_loss: 0.9918 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5076/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.1391e-05 - accuracy: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5077/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6702e-05 - accuracy: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5078/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.4639e-05 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5079/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.8592e-04 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5080/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.1663e-05 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5081/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 7.0868e-05 - accuracy: 1.0000 - val_loss: 1.0140 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5082/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3666e-04 - accuracy: 1.0000 - val_loss: 1.0174 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5083/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.9111e-05 - accuracy: 1.0000 - val_loss: 1.0203 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5084/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.7121e-04 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5085/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.4147e-06 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5086/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.9870e-06 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5087/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 1.0257 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5088/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.6730e-06 - accuracy: 1.0000 - val_loss: 1.0273 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5089/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.0310e-05 - accuracy: 1.0000 - val_loss: 1.0295 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5090/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 1.3907e-05 - accuracy: 1.0000 - val_loss: 1.0323 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5091/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.4155e-05 - accuracy: 1.0000 - val_loss: 1.0352 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5092/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.3234e-06 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5093/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6254e-05 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5094/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 3.2012e-06 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5095/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 4.5862e-05 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5096/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 3.5405e-05 - accuracy: 1.0000 - val_loss: 1.0509 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5097/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2793e-05 - accuracy: 1.0000 - val_loss: 1.0551 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5098/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1572e-06 - accuracy: 1.0000 - val_loss: 1.0584 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5099/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7906e-05 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5100/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.7665e-06 - accuracy: 1.0000 - val_loss: 1.0668 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5101/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1424e-05 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5102/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5107e-05 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5103/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0398e-04 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.9391 - lr: 4.2629e-04\n","Epoch 5104/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1138e-06 - accuracy: 1.0000 - val_loss: 1.0860 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5105/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.0635e-05 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5106/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.6284e-05 - accuracy: 1.0000 - val_loss: 1.0945 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5107/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.3780e-04 - accuracy: 1.0000 - val_loss: 1.0976 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5108/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7532e-05 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5109/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.5739e-06 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5110/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.4541e-06 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5111/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.2533e-06 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5112/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.6083e-06 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5113/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.2007e-06 - accuracy: 1.0000 - val_loss: 1.1096 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5114/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.7063e-05 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5115/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.1599e-05 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5116/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.3133e-04 - accuracy: 0.9996 - val_loss: 1.1174 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5117/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3815e-06 - accuracy: 1.0000 - val_loss: 1.1103 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5118/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.4578e-06 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5119/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.6655e-06 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5120/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.5899e-04 - accuracy: 0.9996 - val_loss: 1.0948 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5121/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 4.8228e-04 - accuracy: 0.9996 - val_loss: 1.0894 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5122/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.2191e-04 - accuracy: 0.9996 - val_loss: 1.0859 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5123/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.1963e-06 - accuracy: 1.0000 - val_loss: 1.0839 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5124/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2933e-06 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5125/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.5010e-04 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5126/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 2.1208e-05 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5127/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1679e-05 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5128/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3630e-05 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5129/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 2.1707e-06 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5130/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 8.5098e-06 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5131/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.8809e-04 - accuracy: 0.9996 - val_loss: 1.0897 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5132/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7931e-05 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.9375 - lr: 4.2629e-04\n","Epoch 5133/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.4927e-05 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5134/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0073e-06 - accuracy: 1.0000 - val_loss: 1.0959 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5135/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.9313e-05 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5136/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.9747e-04 - accuracy: 0.9996 - val_loss: 1.1072 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5137/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.2131e-04 - accuracy: 0.9996 - val_loss: 1.1096 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5138/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.2771e-04 - accuracy: 0.9996 - val_loss: 1.1082 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5139/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.1134e-06 - accuracy: 1.0000 - val_loss: 1.1076 - val_accuracy: 0.9344 - lr: 4.2629e-04\n","Epoch 5140/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8758e-06 - accuracy: 1.0000 - val_loss: 1.1073 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5141/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.9306e-05 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5142/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.5621e-06 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5143/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2531e-04 - accuracy: 1.0000 - val_loss: 1.1115 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5144/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 7.0077e-05 - accuracy: 1.0000 - val_loss: 1.1150 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5145/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.1232e-06 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5146/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3816e-06 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5147/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.5362e-05 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5148/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3144e-05 - accuracy: 1.0000 - val_loss: 1.1268 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5149/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.7911e-05 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5150/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3993e-05 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5151/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.8448e-04 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5152/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.1312 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5153/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.9323e-06 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5154/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.9803e-05 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.9359 - lr: 4.2629e-04\n","Epoch 5155/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.6444e-04 - accuracy: 1.0000 - val_loss: 1.1161 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5156/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.5040e-06 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5157/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2365e-04 - accuracy: 0.9996 - val_loss: 1.1145 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5158/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 5.0734e-05 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5159/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.8627e-05 - accuracy: 1.0000 - val_loss: 1.1183 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5160/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 1.1210 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5161/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.5593e-06 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5162/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4134e-05 - accuracy: 1.0000 - val_loss: 1.1255 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5163/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3544e-04 - accuracy: 1.0000 - val_loss: 1.1268 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5164/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 4.6718e-05 - accuracy: 1.0000 - val_loss: 1.1294 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5165/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1488e-05 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5166/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.3731e-05 - accuracy: 1.0000 - val_loss: 1.1347 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5167/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.3060e-04 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5168/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.9090e-05 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5169/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.1027e-05 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5170/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.2439e-06 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5171/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.0316e-06 - accuracy: 1.0000 - val_loss: 1.1549 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5172/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.1600 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5173/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.4188e-04 - accuracy: 0.9996 - val_loss: 1.1659 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5174/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.2092e-06 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5175/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.2868e-05 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5176/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.5000e-05 - accuracy: 1.0000 - val_loss: 1.1797 - val_accuracy: 0.9391 - lr: 4.0497e-04\n","Epoch 5177/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1998e-05 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.9391 - lr: 4.0497e-04\n","Epoch 5178/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.2427e-04 - accuracy: 0.9996 - val_loss: 1.1851 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5179/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.4259e-06 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5180/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.9791e-06 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5181/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5182/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.4380e-05 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5183/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2077e-04 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5184/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7077e-06 - accuracy: 1.0000 - val_loss: 1.1973 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5185/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1070e-05 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5186/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.7853e-06 - accuracy: 1.0000 - val_loss: 1.2021 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5187/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.9413e-06 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5188/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8678e-06 - accuracy: 1.0000 - val_loss: 1.2056 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5189/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.6908e-06 - accuracy: 1.0000 - val_loss: 1.2069 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5190/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.4055e-06 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5191/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.4708e-04 - accuracy: 0.9996 - val_loss: 1.2087 - val_accuracy: 0.9391 - lr: 4.0497e-04\n","Epoch 5192/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 9.5183e-04 - accuracy: 0.9996 - val_loss: 1.2062 - val_accuracy: 0.9391 - lr: 4.0497e-04\n","Epoch 5193/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.6217e-04 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.9391 - lr: 4.0497e-04\n","Epoch 5194/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7943e-04 - accuracy: 1.0000 - val_loss: 1.2058 - val_accuracy: 0.9406 - lr: 4.0497e-04\n","Epoch 5195/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 1.1631 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5196/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2040e-05 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5197/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0539e-05 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5198/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.6264e-06 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5199/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.6619e-05 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5200/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.1795e-06 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5201/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5903e-05 - accuracy: 1.0000 - val_loss: 1.0805 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5202/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0867e-05 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5203/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.4255e-05 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5204/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.0796e-04 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5205/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6941e-05 - accuracy: 1.0000 - val_loss: 1.0774 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5206/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.5291e-06 - accuracy: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5207/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7952e-05 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5208/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.7537e-05 - accuracy: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5209/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.3436e-05 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5210/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.8089e-06 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5211/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.2262e-06 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5212/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.3245e-05 - accuracy: 1.0000 - val_loss: 1.0852 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5213/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 2.2134e-04 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5214/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.1642e-05 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5215/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.4719e-04 - accuracy: 0.9996 - val_loss: 1.0890 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5216/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0879e-05 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5217/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3248e-05 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5218/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.8993e-06 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5219/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.3907e-06 - accuracy: 1.0000 - val_loss: 1.1082 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5220/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.0943 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5221/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.7723e-05 - accuracy: 1.0000 - val_loss: 1.0854 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5222/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5749e-06 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5223/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 5.8971e-06 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5224/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.1165e-06 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5225/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 1.2862e-05 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5226/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1815e-04 - accuracy: 1.0000 - val_loss: 1.0741 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5227/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.6911e-05 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5228/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 1.0722 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5229/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.4874e-05 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5230/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6161e-04 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5231/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 8.4922e-06 - accuracy: 1.0000 - val_loss: 1.0719 - val_accuracy: 0.9375 - lr: 4.0497e-04\n","Epoch 5232/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.8848e-05 - accuracy: 1.0000 - val_loss: 1.0755 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5233/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7739e-06 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5234/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.2227e-05 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5235/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.4945e-04 - accuracy: 0.9996 - val_loss: 1.0826 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5236/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.9149e-04 - accuracy: 0.9996 - val_loss: 1.0803 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5237/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0305e-05 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5238/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.8320e-05 - accuracy: 1.0000 - val_loss: 1.0805 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5239/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.2880e-04 - accuracy: 1.0000 - val_loss: 1.0839 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5240/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 6.5872e-04 - accuracy: 0.9996 - val_loss: 1.0847 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5241/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.7595e-05 - accuracy: 1.0000 - val_loss: 1.0859 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5242/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1934e-04 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5243/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.4795e-04 - accuracy: 0.9996 - val_loss: 1.0914 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5244/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.5808e-06 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.9328 - lr: 4.0497e-04\n","Epoch 5245/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0116e-05 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.9328 - lr: 4.0497e-04\n","Epoch 5246/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2643e-04 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.9328 - lr: 4.0497e-04\n","Epoch 5247/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0106e-05 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.9328 - lr: 4.0497e-04\n","Epoch 5248/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 1.1081 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5249/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2262e-05 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5250/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 9.2592e-05 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5251/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.4821e-06 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5252/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3804e-06 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.9359 - lr: 4.0497e-04\n","Epoch 5253/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.3007e-04 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5254/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.7766e-06 - accuracy: 1.0000 - val_loss: 1.0990 - val_accuracy: 0.9344 - lr: 4.0497e-04\n","Epoch 5255/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.1383e-04 - accuracy: 0.9996 - val_loss: 1.0911 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5256/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.0072e-05 - accuracy: 1.0000 - val_loss: 1.0860 - val_accuracy: 0.9328 - lr: 3.8472e-04\n","Epoch 5257/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.0780 - val_accuracy: 0.9328 - lr: 3.8472e-04\n","Epoch 5258/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1177e-06 - accuracy: 1.0000 - val_loss: 1.0698 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5259/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.1342e-06 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5260/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6010e-05 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5261/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4327e-05 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5262/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.5104e-05 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5263/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2674e-05 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5264/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.8631e-05 - accuracy: 1.0000 - val_loss: 1.0661 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5265/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1386e-05 - accuracy: 1.0000 - val_loss: 1.0709 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5266/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.4220e-04 - accuracy: 0.9996 - val_loss: 1.0766 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5267/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.7603e-05 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5268/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 1.0683 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5269/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.2407e-04 - accuracy: 0.9996 - val_loss: 1.0168 - val_accuracy: 0.9328 - lr: 3.8472e-04\n","Epoch 5270/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6788e-05 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5271/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2076e-05 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5272/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4101e-05 - accuracy: 1.0000 - val_loss: 0.9404 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5273/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.6231e-04 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5274/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.0220e-04 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5275/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3468e-04 - accuracy: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5276/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.4843e-05 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5277/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.9656e-05 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5278/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.3056e-06 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5279/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6187e-05 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5280/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1627e-05 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5281/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.0784e-05 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5282/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.7036e-06 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5283/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.0943e-04 - accuracy: 0.9996 - val_loss: 1.0142 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5284/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1706e-05 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5285/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.6634e-06 - accuracy: 1.0000 - val_loss: 1.0329 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5286/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.2546e-04 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5287/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 2.1872e-05 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5288/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1427e-05 - accuracy: 1.0000 - val_loss: 1.0801 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5289/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.5412e-05 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5290/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9913e-05 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5291/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.9549e-04 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5292/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 3.8508e-05 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5293/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3725e-05 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5294/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.1163e-05 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5295/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.5193e-04 - accuracy: 1.0000 - val_loss: 1.1643 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5296/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.9821e-05 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5297/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.3945e-05 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5298/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.4933e-05 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5299/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.2439e-05 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5300/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8779e-06 - accuracy: 1.0000 - val_loss: 1.2021 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5301/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.5767e-04 - accuracy: 1.0000 - val_loss: 1.2085 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5302/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.5167e-06 - accuracy: 1.0000 - val_loss: 1.2142 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5303/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6330e-04 - accuracy: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5304/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.1091e-06 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5305/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5454e-04 - accuracy: 1.0000 - val_loss: 1.2514 - val_accuracy: 0.9344 - lr: 3.8472e-04\n","Epoch 5306/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.7199e-06 - accuracy: 1.0000 - val_loss: 1.2644 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5307/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 4.9808e-06 - accuracy: 1.0000 - val_loss: 1.2745 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5308/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6713e-06 - accuracy: 1.0000 - val_loss: 1.2826 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5309/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1918e-05 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5310/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.4832e-05 - accuracy: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5311/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.5406e-07 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5312/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4668e-06 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5313/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.7407e-06 - accuracy: 1.0000 - val_loss: 1.3097 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5314/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3540e-06 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5315/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9836e-05 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5316/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1023e-04 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5317/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 7.4641e-07 - accuracy: 1.0000 - val_loss: 1.3391 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5318/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.9798e-06 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5319/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0856e-06 - accuracy: 1.0000 - val_loss: 1.3519 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5320/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.2407e-05 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5321/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.8494e-06 - accuracy: 1.0000 - val_loss: 1.3594 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5322/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 1.3269 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5323/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.4276e-05 - accuracy: 1.0000 - val_loss: 1.2487 - val_accuracy: 0.9391 - lr: 3.8472e-04\n","Epoch 5324/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.0257e-06 - accuracy: 1.0000 - val_loss: 1.1965 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5325/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.0166e-06 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5326/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.7056e-04 - accuracy: 0.9996 - val_loss: 1.1363 - val_accuracy: 0.9391 - lr: 3.8472e-04\n","Epoch 5327/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.1002e-04 - accuracy: 1.0000 - val_loss: 1.1159 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5328/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.9565e-06 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5329/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5074e-04 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5330/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 1.0802 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5331/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.5175e-06 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5332/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6923e-04 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5333/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.0414e-05 - accuracy: 1.0000 - val_loss: 1.0581 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5334/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.2746e-04 - accuracy: 1.0000 - val_loss: 1.0580 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5335/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.2304e-06 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5336/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.5570e-05 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5337/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.2741e-05 - accuracy: 1.0000 - val_loss: 1.0650 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5338/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.0617 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5339/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 9.2294e-05 - accuracy: 1.0000 - val_loss: 1.0523 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5340/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.5170e-05 - accuracy: 1.0000 - val_loss: 1.0478 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5341/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.2815e-05 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.9359 - lr: 3.8472e-04\n","Epoch 5342/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.2782e-05 - accuracy: 1.0000 - val_loss: 1.0483 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5343/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.8146e-05 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5344/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.2446e-05 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5345/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.9784e-05 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5346/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 5.4795e-04 - accuracy: 0.9996 - val_loss: 1.0581 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5347/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.6758e-06 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5348/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.0883e-04 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.9375 - lr: 3.8472e-04\n","Epoch 5349/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.1629e-05 - accuracy: 1.0000 - val_loss: 1.0686 - val_accuracy: 0.9391 - lr: 3.8472e-04\n","Epoch 5350/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.1449e-04 - accuracy: 1.0000 - val_loss: 1.0735 - val_accuracy: 0.9422 - lr: 3.8472e-04\n","Epoch 5351/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.2601e-05 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.9422 - lr: 3.8472e-04\n","Epoch 5352/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.0615e-05 - accuracy: 1.0000 - val_loss: 1.0839 - val_accuracy: 0.9422 - lr: 3.8472e-04\n","Epoch 5353/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1239e-05 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.9422 - lr: 3.8472e-04\n","Epoch 5354/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 2.4556e-04 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.9422 - lr: 3.8472e-04\n","Epoch 5355/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.8352e-04 - accuracy: 0.9996 - val_loss: 1.0942 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5356/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.9208e-05 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5357/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6224e-05 - accuracy: 1.0000 - val_loss: 1.0982 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5358/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.5791e-05 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5359/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.5803e-05 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5360/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 3.3524e-06 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.9438 - lr: 3.6549e-04\n","Epoch 5361/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 9.9529e-04 - accuracy: 0.9996 - val_loss: 1.0948 - val_accuracy: 0.9422 - lr: 3.6549e-04\n","Epoch 5362/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.3483e-05 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5363/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.4095e-05 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5364/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.6987e-04 - accuracy: 0.9996 - val_loss: 1.0663 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5365/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 6.5933e-06 - accuracy: 1.0000 - val_loss: 1.0583 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5366/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 1.7386e-05 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5367/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.2671e-04 - accuracy: 1.0000 - val_loss: 1.0519 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5368/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.7545e-06 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5369/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 9.8278e-05 - accuracy: 1.0000 - val_loss: 1.0526 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5370/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.7828e-06 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5371/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 7.3622e-04 - accuracy: 0.9996 - val_loss: 1.0544 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5372/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.2322e-06 - accuracy: 1.0000 - val_loss: 1.0531 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5373/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.2941e-05 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5374/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.6269e-06 - accuracy: 1.0000 - val_loss: 1.0539 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5375/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.2313e-04 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5376/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.2840e-05 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5377/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9901e-05 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5378/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.2276e-06 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5379/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.8311e-06 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5380/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5797e-04 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5381/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.1501e-05 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5382/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.0775e-04 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5383/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1144e-05 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5384/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 8.8981e-06 - accuracy: 1.0000 - val_loss: 1.0862 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5385/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.6889e-04 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5386/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9928e-05 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5387/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.4524e-04 - accuracy: 0.9996 - val_loss: 1.0926 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5388/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.6897e-05 - accuracy: 1.0000 - val_loss: 1.0954 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5389/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.2648e-05 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5390/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 6.4784e-04 - accuracy: 0.9996 - val_loss: 1.1007 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5391/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.6323e-05 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5392/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.4267e-06 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5393/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.7272e-05 - accuracy: 1.0000 - val_loss: 1.1015 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5394/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.0973e-04 - accuracy: 0.9996 - val_loss: 1.1046 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5395/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0263e-05 - accuracy: 1.0000 - val_loss: 1.1076 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5396/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6952e-04 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.9359 - lr: 3.6549e-04\n","Epoch 5397/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6167e-05 - accuracy: 1.0000 - val_loss: 1.1164 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5398/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 7.3786e-05 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5399/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5707e-05 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5400/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2168e-04 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5401/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.0164e-06 - accuracy: 1.0000 - val_loss: 1.1341 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5402/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.1702e-05 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5403/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.3693e-05 - accuracy: 1.0000 - val_loss: 1.1425 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5404/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.9033e-05 - accuracy: 1.0000 - val_loss: 1.1466 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5405/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.4408e-04 - accuracy: 0.9996 - val_loss: 1.1479 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5406/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.8992e-04 - accuracy: 0.9996 - val_loss: 1.1469 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5407/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.0283e-05 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5408/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0248e-05 - accuracy: 1.0000 - val_loss: 1.1468 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5409/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.1594e-06 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5410/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.6563e-06 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5411/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.1294e-05 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5412/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.2495e-04 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5413/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.7361e-05 - accuracy: 1.0000 - val_loss: 1.1527 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5414/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.1753e-06 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5415/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 4.2238e-06 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5416/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.4558e-06 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5417/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 6.5517e-05 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5418/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 2.2976e-06 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5419/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.5488e-06 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5420/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0774e-04 - accuracy: 1.0000 - val_loss: 1.1660 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5421/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 1.7256e-05 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5422/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.2908e-04 - accuracy: 0.9996 - val_loss: 1.1719 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5423/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 8.9978e-05 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.9375 - lr: 3.6549e-04\n","Epoch 5424/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.7452e-04 - accuracy: 0.9996 - val_loss: 1.1743 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5425/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.7642e-06 - accuracy: 1.0000 - val_loss: 1.1726 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5426/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.5969e-06 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5427/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.9310e-05 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5428/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.5928e-06 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5429/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.7838e-05 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5430/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.6062e-06 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5431/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 1.0698e-05 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5432/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 5.9070e-06 - accuracy: 1.0000 - val_loss: 1.1770 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5433/30000\n","3/3 [==============================] - 0s 85ms/step - loss: 2.1372e-06 - accuracy: 1.0000 - val_loss: 1.1785 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5434/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 5.5108e-05 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5435/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 9.7795e-07 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5436/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 3.2711e-04 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5437/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7249e-06 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5438/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.6278e-04 - accuracy: 0.9996 - val_loss: 1.1888 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5439/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9893e-04 - accuracy: 1.0000 - val_loss: 1.1913 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5440/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 9.8466e-06 - accuracy: 1.0000 - val_loss: 1.1961 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5441/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.9050e-06 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5442/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 8.7679e-04 - accuracy: 0.9996 - val_loss: 1.1974 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5443/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 2.6246e-05 - accuracy: 1.0000 - val_loss: 1.1961 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5444/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0990e-05 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5445/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 4.5236e-06 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.9406 - lr: 3.6549e-04\n","Epoch 5446/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.3496e-04 - accuracy: 0.9996 - val_loss: 1.1939 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5447/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.8571e-06 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5448/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 6.0633e-05 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5449/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2607e-05 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5450/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.3878e-06 - accuracy: 1.0000 - val_loss: 1.1965 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5451/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 9.0007e-06 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5452/30000\n","3/3 [==============================] - 0s 83ms/step - loss: 2.7760e-06 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5453/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.3492e-06 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5454/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6034e-06 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.9391 - lr: 3.6549e-04\n","Epoch 5455/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 3.9941e-05 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5456/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2357e-04 - accuracy: 1.0000 - val_loss: 1.2057 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5457/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.4843e-04 - accuracy: 0.9996 - val_loss: 1.2080 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5458/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 4.0163e-06 - accuracy: 1.0000 - val_loss: 1.2103 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5459/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 5.4299e-07 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5460/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.3251e-06 - accuracy: 1.0000 - val_loss: 1.2135 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5461/30000\n","3/3 [==============================] - 0s 81ms/step - loss: 5.2217e-07 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5462/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3363e-06 - accuracy: 1.0000 - val_loss: 1.2157 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5463/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0083e-06 - accuracy: 1.0000 - val_loss: 1.2165 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5464/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 2.6072e-04 - accuracy: 1.0000 - val_loss: 1.2174 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5465/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.8601e-05 - accuracy: 1.0000 - val_loss: 1.2186 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5466/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.1727e-05 - accuracy: 1.0000 - val_loss: 1.2205 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5467/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4229e-04 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5468/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.4572e-06 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5469/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 2.6617e-04 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5470/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 4.5631e-06 - accuracy: 1.0000 - val_loss: 1.2290 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5471/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 8.1645e-05 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5472/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.2430e-04 - accuracy: 1.0000 - val_loss: 1.2345 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5473/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 6.0270e-06 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5474/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.6692e-06 - accuracy: 1.0000 - val_loss: 1.2385 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5475/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 7.4404e-05 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5476/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 6.9078e-07 - accuracy: 1.0000 - val_loss: 1.2417 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5477/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6268e-04 - accuracy: 1.0000 - val_loss: 1.2454 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5478/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 8.1219e-07 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5479/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.4923e-06 - accuracy: 1.0000 - val_loss: 1.2563 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5480/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.6617e-07 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5481/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.2025e-06 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5482/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 5.7029e-07 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5483/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 4.0765e-06 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5484/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 2.3596e-05 - accuracy: 1.0000 - val_loss: 1.2683 - val_accuracy: 0.9328 - lr: 3.4721e-04\n","Epoch 5485/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 4.6202e-07 - accuracy: 1.0000 - val_loss: 1.2696 - val_accuracy: 0.9328 - lr: 3.4721e-04\n","Epoch 5486/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 1.2413 - val_accuracy: 0.9328 - lr: 3.4721e-04\n","Epoch 5487/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1405e-06 - accuracy: 1.0000 - val_loss: 1.2217 - val_accuracy: 0.9328 - lr: 3.4721e-04\n","Epoch 5488/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5489/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 2.3205e-06 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5490/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.5409e-05 - accuracy: 1.0000 - val_loss: 1.1942 - val_accuracy: 0.9344 - lr: 3.4721e-04\n","Epoch 5491/30000\n","3/3 [==============================] - 0s 79ms/step - loss: 3.0487e-06 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5492/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.0592e-05 - accuracy: 1.0000 - val_loss: 1.1876 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5493/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.7527e-05 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5494/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 3.1253e-06 - accuracy: 1.0000 - val_loss: 1.1869 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5495/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.2288e-05 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5496/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.6607e-05 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5497/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 9.0181e-06 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5498/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1378e-04 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5499/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 2.1978e-06 - accuracy: 1.0000 - val_loss: 1.1942 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5500/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.0385e-05 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5501/30000\n","3/3 [==============================] - 0s 84ms/step - loss: 1.9248e-04 - accuracy: 1.0000 - val_loss: 1.2001 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5502/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.0507e-04 - accuracy: 1.0000 - val_loss: 1.2070 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5503/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.1372e-06 - accuracy: 1.0000 - val_loss: 1.2125 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5504/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 1.2090e-05 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5505/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 2.9765e-05 - accuracy: 1.0000 - val_loss: 1.2210 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5506/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.6288e-05 - accuracy: 1.0000 - val_loss: 1.2245 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5507/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 8.1455e-04 - accuracy: 0.9996 - val_loss: 1.2247 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5508/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 3.5135e-04 - accuracy: 0.9996 - val_loss: 1.2215 - val_accuracy: 0.9359 - lr: 3.4721e-04\n","Epoch 5509/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.0321e-05 - accuracy: 1.0000 - val_loss: 1.2207 - val_accuracy: 0.9375 - lr: 3.4721e-04\n","Epoch 5510/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 1.5671e-05 - accuracy: 1.0000 - val_loss: 1.2212 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5511/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 1.8314e-04 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5512/30000\n","3/3 [==============================] - 0s 75ms/step - loss: 1.1832e-05 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5513/30000\n","3/3 [==============================] - 0s 86ms/step - loss: 2.6062e-06 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5514/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 3.5333e-06 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5515/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.6840e-06 - accuracy: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5516/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 7.3259e-05 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5517/30000\n","3/3 [==============================] - 0s 78ms/step - loss: 5.7505e-04 - accuracy: 0.9996 - val_loss: 1.2257 - val_accuracy: 0.9422 - lr: 3.4721e-04\n","Epoch 5518/30000\n","3/3 [==============================] - 0s 76ms/step - loss: 1.4381e-04 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5519/30000\n","3/3 [==============================] - 0s 82ms/step - loss: 1.8328e-04 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5520/30000\n","3/3 [==============================] - 0s 77ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.2167 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5521/30000\n","3/3 [==============================] - 0s 80ms/step - loss: 8.5129e-06 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.9391 - lr: 3.4721e-04\n","Epoch 5522/30000\n","1/3 [=========>....................] - ETA: 0s - loss: 9.8155e-07 - accuracy: 1.0000"]}],"source":["from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras import regularizers\n","#Let's grab that original data, without the buckets.\n","import pandas as pd\n","#Let's perform a super simple and easy Random Forest Classifier.\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import math\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","import os\n","from tensorflow.keras.callbacks import LambdaCallback\n","\n","\n","# Set up a directory for TensorBoard logs\n","log_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","'''log_epoch_callback = LambdaCallback(\n","    on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch + 1}: {logs}\") if (epoch + 1) % 500 == 0 else None\n",")'''\n","\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/data/cleaned_data.csv\")\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","# Initialize the StratifiedKFold object\n","\n","\n","# Assume the rest of your imports and data preparation is done above this line\n","\n","def create_complex_model(input_dim):\n","    model = tf.keras.Sequential([\n","      tf.keras.layers.Dense(128, input_dim=input_dim, activation='relu'),\n","      tf.keras.layers.Dropout(0.1),\n","      tf.keras.layers.Dense(256, activation='relu'),\n","      tf.keras.layers.Dropout(0.1),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dropout(0.1),\n","      tf.keras.layers.Dense(8, activation='relu'),\n","      tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)  # Specific optimizer with learning rate\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# Create the model\n","model = create_complex_model(X_train_scaled.shape[1])\n","\n","# Callbacks\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8, patience=100, min_lr=0.0001)\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=3000)\n","\n","# Fit the model on the scaled training data\n","history = model.fit(\n","    X_train_scaled, y_train,\n","    epochs=10000,\n","    batch_size=128,\n","    verbose=1,\n","    validation_split=0.2,  # Use 20% of the training data as validation data\n","    callbacks=[tensorboard_callback, reduce_lr, early_stopping]\n",")\n","\n","# Assuming create_casting_model is defined to cast outputs\n","casting_model = create_casting_model(model)\n","predictions = casting_model.predict(X_test_scaled)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, predictions)\n","print(f\"Test Accuracy: {accuracy}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03373QJTfBeb"},"outputs":[],"source":["import tensorflow as tf\n","\n","def create_casting_model(base_model):\n","    # Input with the same shape as the base model's input\n","    inputs = tf.keras.Input(shape=(base_model.input_shape[1],))\n","\n","    # Reuse the base model, make sure it's not trainable\n","    base_model.trainable = False\n","    x = base_model(inputs)\n","\n","    # Add a Lambda layer to convert probabilities to binary values\n","    outputs = tf.keras.layers.Lambda(lambda x: tf.cast(x > 0.5, tf.int32))(x)\n","\n","    # Create the new model\n","    casting_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","    return casting_model\n","\n","# Example usage\n","casting_model = create_casting_model(model)\n","\n","# Now, casting_model.predict(...) will output integer class labels directly\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1714040618013,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"3bIt5rBxUzc9","outputId":"6bc18388-2093-4239-89c3-647fb5d951a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 0s 2ms/step\n","0.9525\n"]}],"source":["predictions = casting_model.predict(X_test_scaled)\n","\n","    # Calculate accuracy\n","accuracy = accuracy_score(y_test, predictions)\n","print(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5qE5dWBkELd"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Assuming X_train is your training feature data\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","# Now retrieve and save the mean and standard deviation\n","feature_mean = scaler.mean_\n","feature_variance = scaler.var_  # Note: Scikit-learn uses variance, but TensorFlow expects variance for weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713870417278,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"Mu-1UeJ3omVJ","outputId":"371630e7-2df8-4fd0-91ef-0334257921c8"},"outputs":[{"data":{"text/plain":["array([3.82267338, 2.58986136, 3.76284056, 2.00559243, 3.77297666,\n","       3.49999644, 4.49198254])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["feature_variance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1713870518677,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"GgMnSUeDo92Y","outputId":"d505a118-bdae-447c-e8ce-27b633d79b09"},"outputs":[{"data":{"text/plain":["array([3.82267338, 2.58986136, 3.76284056, 2.00559243, 3.77297666,\n","       3.49999644, 4.49198254])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["feature_variance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":321,"status":"error","timestamp":1713870445166,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"FOsRN_FEkHOo","outputId":"ae7890e1-dd2c-4558-e24c-f6f9a390bee3"},"outputs":[{"ename":"ValueError","evalue":"Layer normalization_5 weight shape () is not compatible with provided weight shape (1,).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-30cd1e284e4f>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Assuming 'loaded_model' is your trained and loaded Keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mcasting_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_casting_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-30cd1e284e4f>\u001b[0m in \u001b[0;36mcreate_casting_model\u001b[0;34m(base_model, feature_mean, feature_variance)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Set the weights with mean, variance, and a large count value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Apply normalization to the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mref_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1823\u001b[0m                         \u001b[0;34mf\"Layer {self.name} weight shape {ref_shape} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m                         \u001b[0;34m\"is not compatible with provided weight \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Layer normalization_5 weight shape () is not compatible with provided weight shape (1,)."]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","def create_casting_model(base_model, feature_mean, feature_variance):\n","    # Define the input shape based on the base model's input\n","    inputs = tf.keras.Input(shape=(base_model.input_shape[1],))\n","\n","    # Create a Normalization layer\n","    normalizer = tf.keras.layers.Normalization(axis=-1)\n","\n","    # Correctly prepare the arrays with shapes matching the expected input dimensions\n","    feature_mean = np.array(feature_mean).reshape(-1)  # Ensuring it's a flat array\n","    feature_variance = np.array(feature_variance).reshape(-1)  # Ensuring it's a flat array\n","    count = np.array([1e5])  # Single scalar inside an array\n","\n","    # Initialize the layer on some dummy data to properly build it\n","    normalizer.adapt(np.zeros((1, base_model.input_shape[1])))\n","\n","    # Set the weights with mean, variance, and a large count value\n","    normalizer.set_weights([feature_mean, feature_variance, count])\n","\n","    # Apply normalization to the inputs\n","    normalized_inputs = normalizer(inputs)\n","\n","    # Reuse the base model, make sure it's not trainable\n","    base_model.trainable = False\n","    x = base_model(normalized_inputs)\n","\n","    # Add a Lambda layer to convert probabilities to binary values\n","    outputs = tf.keras.layers.Lambda(lambda x: tf.cast(x > 0.5, tf.int32))(x)\n","\n","    # Create the new model\n","    casting_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","    return casting_model\n","\n","\n","# Assuming 'loaded_model' is your trained and loaded Keras model\n","casting_model = create_casting_model(model, feature_mean, feature_variance)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":989,"status":"error","timestamp":1713891358692,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"MPfNzzS-pjRU","outputId":"5c7b97e0-f21d-4cfc-aac2-6e986b89ca75"},"outputs":[{"ename":"ValueError","evalue":"Layer normalization weight shape () is not compatible with provided weight shape (1,).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a01e469ed1a2>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Assuming 'loaded_model' is your trained and loaded Keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcasting_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_casting_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-a01e469ed1a2>\u001b[0m in \u001b[0;36mcreate_casting_model\u001b[0;34m(base_model, feature_mean, feature_variance)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Set the weights with mean, variance, and count (setting count to a large number)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure count is a float array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Apply normalization to the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mref_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1823\u001b[0m                         \u001b[0;34mf\"Layer {self.name} weight shape {ref_shape} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m                         \u001b[0;34m\"is not compatible with provided weight \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Layer normalization weight shape () is not compatible with provided weight shape (1,)."]}],"source":["import tensorflow as tf\n","\n","def create_model_with_normalization(train_data):\n","    # Create a Normalization layer\n","    normalizer = tf.keras.layers.Normalization(axis=-1)\n","    # Adapt it to the training data\n","    normalizer.adapt(train_data)\n","\n","    # Build the model including the normalization layer\n","    model = tf.keras.Sequential([\n","        normalizer,\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dense(256, activation='relu'),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dense(8, activation='relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def create_casting_model(base_model):\n","    # Input with the same shape as the base model's input\n","    inputs = tf.keras.Input(shape=(base_model.input_shape[1],))\n","\n","    # Reuse the base model, make sure it's not trainable\n","    base_model.trainable = False\n","    x = base_model(inputs)\n","\n","    # Add a Lambda layer to convert probabilities to binary values\n","    outputs = tf.keras.layers.Lambda(lambda x: tf.cast(x > 0.5, tf.int32))(x)\n","\n","    # Create the new model\n","    casting_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","    return casting_model\n","\n","# Assume train_data is your training feature data already loaded\n","train_data = ...  # Load or specify your training data here\n","\n","# Create the base model with normalization\n","base_model = create_model_with_normalization(train_data)\n","\n","# Use the base model to create the casting model\n","casting_model = create_casting_model(base_model)\n","\n","# Now, you can use casting_model.predict(...) with raw data directly\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1824,"status":"ok","timestamp":1713867999932,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"3qSCWfNujV62","outputId":"3e1b963f-57bc-4b1a-8fa9-e909fcdb125d"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}],"source":["casting_model.save(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/99 accuracy model with correct outputs\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A_7GkbZwnkB"},"outputs":[],"source":["import tensorflow as tf\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/99 accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":16397,"status":"error","timestamp":1714040340724,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"aWAucrWVqXPr","outputId":"d7dbda19-c050-4538-89fe-04006cf97d18"},"outputs":[{"name":"stdout","output_type":"stream","text":["[  12   15   19   29   31   36   37   52   54   58   64   65   72   77\n","   79   82   83   86   96  100  106  117  120  123  126  128  137  140\n","  144  158  168  169  170  171  176  178  182  186  191  197  199  204\n","  208  212  227  228  235  237  241  268  275  284  289  292  306  320\n","  328  331  340  344  345  347  348  359  364  369  371  373  376  377\n","  378  387  393  399  400  402  407  410  419  422  425  427  430  436\n","  442  444  451  456  459  466  469  474  489  490  497  504  508  512\n","  515  519  520  521  522  526  530  533  534  535  538  541  547  552\n","  554  559  563  567  570  572  575  576  580  582  587  590  592  597\n","  601  606  612  619  621  622  623  643  648  649  650  651  661  664\n","  666  667  669  675  676  681  685  692  694  704  713  714  718  721\n","  722  729  732  734  736  737  742  745  749  753  754  757  772  783\n","  789  791  801  802  805  811  817  821  826  828  829  830  833  856\n","  859  860  861  862  867  873  876  877  878  880  882  883  885  892\n","  893  895  898  902  910  911  914  918  920  923  924  925  933  937\n","  941  946  948  952  954  955  962  968  978  980  991  998 1007 1008\n"," 1010 1012 1016 1021 1026 1028 1034 1036 1040 1047 1059 1060 1062 1064\n"," 1066 1073 1084 1091 1094 1100 1108 1109 1112 1118 1124 1126 1132 1141\n"," 1142 1146 1155 1161 1170 1173 1174 1175 1183 1184 1192 1204 1210 1225\n"," 1230 1234 1238 1256 1267 1279 1283 1286 1288 1289 1292 1297 1304 1315\n"," 1319 1324 1340 1347 1349 1350 1355 1356 1362 1365 1368 1369 1384 1392\n"," 1400 1406 1408 1420 1426 1429 1439 1442 1444 1451 1452 1453 1455 1459\n"," 1464 1468 1478 1483 1485 1490 1491 1497 1502 1506 1509 1510 1511 1512\n"," 1514 1519 1524 1529 1536 1541 1550 1561 1563 1568 1575 1578 1582 1600\n"," 1606 1607 1610 1612 1614 1616 1617 1629 1638 1640 1652 1656 1662 1664\n"," 1667 1671 1672 1681 1685 1691 1693 1695 1696 1706 1710 1716 1720 1731\n"," 1739 1744 1747 1749 1760 1761 1773 1774 1783 1795 1796 1806 1813 1820\n"," 1821 1822 1827 1828 1841 1843 1854 1856 1871 1874 1877 1879 1882 1886\n"," 1890 1908 1909 1911 1912 1918 1919 1921 1926 1931 1935 1939 1945 1946\n"," 1950 1954 1957 1959 1964 1965 1969 1981 1982 1984 1985 1989 1993 2008\n"," 2010 2013 2021 2023 2025 2030 2031 2034 2041 2043 2047 2049 2050 2053\n"," 2056 2061 2065 2066 2074 2079 2083 2091 2092 2093 2096 2100 2104 2105\n"," 2111 2119 2128 2138 2140 2141 2142 2145 2153 2154 2156 2159 2161 2167\n"," 2168 2172 2174 2175 2176 2180 2182 2194 2211 2212 2216 2224 2226 2228\n"," 2234 2244 2245 2247 2248 2251 2252 2254 2257 2261 2266 2269 2273 2280\n"," 2282 2293 2295 2300 2302 2303 2311 2318 2320 2335 2337 2341 2342 2345\n"," 2346 2348 2350 2353 2354 2360 2369 2372 2382 2384 2393 2399 2407 2408\n"," 2415 2416 2422 2426 2429 2437 2438 2442 2443 2447 2449 2453 2463 2467\n"," 2474 2486 2490 2508 2511 2518 2519 2520 2525 2527 2536 2539 2550 2554\n"," 2556 2558 2559 2561 2581 2586 2588 2591 2597 2599 2605 2614 2622 2627\n"," 2630 2635 2639 2658 2659 2661 2662 2687 2691 2694 2700 2701 2702 2706\n"," 2715 2720 2725 2727 2728 2737 2739 2741 2743 2748 2764 2767 2780 2781\n"," 2783 2791 2792 2796 2803 2804 2805 2810 2813 2823 2827 2830 2832 2846\n"," 2854 2857 2863 2865 2868 2877 2884 2894 2896 2906 2922 2930 2940 2942\n"," 2949 2958 2964 2965 2975 2977 2985 2987 2991 2993 2998 2999 3004 3014\n"," 3025 3026 3031 3032 3036 3040 3051 3061 3066 3067 3070 3073 3100 3102\n"," 3103 3115 3117 3121 3133 3135 3136 3145 3153 3156 3158 3173 3176 3180\n"," 3181 3197 3200 3201 3205 3209 3210 3211 3215 3216 3224 3226 3243 3245\n"," 3252 3264 3275 3282 3285 3297 3309 3311 3317 3325 3333 3345 3354 3358\n"," 3364 3365 3382 3383 3392 3396 3402 3409 3416 3421 3422 3425 3426 3434\n"," 3436 3439 3441 3446 3451 3458 3466 3467 3469 3473 3474 3476 3485 3501\n"," 3517 3522 3523 3525 3527 3534 3540 3547 3552 3559 3574 3578 3597 3600\n"," 3613 3620 3623 3634 3641 3642 3649 3671 3676 3677 3697 3698 3700 3704\n"," 3711 3712 3718 3733 3736 3740 3750 3751 3752 3756 3760 3765 3770 3777\n"," 3785 3786 3790 3791 3795 3811 3814 3821 3826 3827 3830 3831 3844 3854\n"," 3855 3858 3859 3863 3865 3867 3868 3870 3874 3889 3891 3894 3905 3911\n"," 3928 3930 3931 3937 3938 3942 3946 3953 3959 3960 3970 3972 3973 3980\n"," 3987 3995]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-fab9aec8ae32>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   '''\n\u001b[1;32m     43\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.model_selection import StratifiedKFold\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras import regularizers\n","#Let's grab that original data, without the buckets.\n","import pandas as pd\n","#Let's perform a super simple and easy Random Forest Classifier.\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import math\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","def create_model():\n","\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(128, input_dim=features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(256, input_dim=features.shape[1], activation='relu'))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(8, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Initialize lists to store accuracy scores\n","\n","\n","\n","accuracy_scores = []\n","\n","for train_index, test_index in skf.split(features, target):\n","  X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n","  y_train, y_test = target[train_index], target[test_index]\n","  print(test_index)\n","\n","  model = create_model()\n","  model.fit(X_train, y_train, epochs=1000, batch_size=128, verbose=0)\n","  '''\n","  _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","  print(\"Train Index: \" + str(train_index))\n","  print(accuracy)\n","\n","  casting_model = create_casting_model(model)\n","  predictions = casting_model.predict(X_test_big)\n","\n","\n","    # Calculate accuracy\n","  accuracy = accuracy_score(y_test_big, predictions)\n","  print(accuracy)'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1714039313425,"user":{"displayName":"Adam Bartlett","userId":"00634061720591342419"},"user_tz":240},"id":"b7KUdHehrw96","outputId":"63393778-7096-4096-c20b-5b399ac38263"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.949999988079071, 0.9549999833106995, 0.9387500286102295, 0.9225000143051147, 0.9175000190734863]\n"]}],"source":["print(accuracy_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPTLbdoirSAb"},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IBM Advanced Data Science Cap/data/cleaned_data.csv\")\n","features = data[['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']]\n","target = data['Good']\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","scaler = StandardScaler()\n","X_test_big = X_test\n","y_test_big = y_test\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"10BJBk8OqhmOk2OAJ6aWPxhbsgpq018xW","authorship_tag":"ABX9TyOhvRhht0v4y7uUDJ6hk591"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}